UNCALIBRATED ROBOTIC VISUAL SERVO
TRACKING FOR LARGE RESIDUAL PROBLEMS
A Thesis
Presented to
The Academic Faculty
by
Jomkwun Munnae
In Partial Fulﬁllment
of the Requirements for the Degree
Doctor of Philosophy in the
The George W. Woodruﬀ School of Mechanical Engineering
Georgia Institute of Technology
December 2010
Copyright (cid:13)c 2010 by Jomkwun Munnae
UNCALIBRATED ROBOTIC VISUAL SERVO
TRACKING FOR LARGE RESIDUAL PROBLEMS
Approved by:
Professor Harvey Lipkin, Professor Ayanna MacCalla Howard
Committee Chair School of Electrical and Computer
The George W. Woodruﬀ School of Engineering
Mechanical Engineering Georgia Institute of Technology
Georgia Institute of Technology
Professor Nadar Sadegh Dr. Wayne Daley
The George W. Woodruﬀ School of Georgia Tech Research Institute
Mechanical Engineering Georgia Institute of Technology
Georgia Institute of Technology
Professor Aldo A. Ferri Date Approved: 12 November 2010
The George W. Woodruﬀ School of
Mechanical Engineering
Georgia Institute of Technology
To my parents,
Mingkwun and Sinothai Munnae
iii
ACKNOWLEDGEMENTS
My foremost gratitude goes to my adviser, Prof. Harvey Lipkin, for his considerable
eﬀort in constructing me piece by piece to become a ﬁne researcher. Through these
years, he has shown me what it is, and how to be an extraordinary teacher. He is
one of the most intellectual and knowledgeable persons I have ever met yet he is
respectful to everyone, including his students. I truly appreciate him for never once
making me feel uncomfortable in asking trivial questions and repeatedly explaining
the answers until I absolutely understand. I am also profoundly grateful for those
hours of editing and proofreading my thesis. Thank you for being hard on me and
guiding me from the beginning until the end. Without your help this thesis would
not have be possible. It is my privilege having you as my teacher and advisor.
I also owe my deepest gratitude to my FPTD division chief Gary McMurray, who
never lost faith in me, even though in the toughest days I almost gave up myself. His
trust and ﬂexibility in relying on my inner strength and personality to complete the
work make him an exceptional supervisor. I am grateful for his eﬀort in ﬁnding me
ﬁnancial support till the completion of my study. Without his help, my work would
have not been successful. Thank you for always being there. Your leadership, vision,
and personality makes you the best boss an employee can ask for and it is my honor
to have worked with you.
IwouldliketothankProf. NaderSadegh, Prof. AldoA.Ferri, Prof. AyannaMac-
Calla Howard, and Dr. Wayne Daley for serving as committee members, reviewing
my dissertation, and providing valuable feedback.
I am also grateful to all my Georgia Tech academic professors, researchers, and
staﬀ for teaching and helping me to earn valuable knowledge in completion of this
iv
work.
I truly appreciate the Georgia Tech Research Institute (GTRI) for providing me
ﬁnancial support and work opportunities through the Shackelford fellowship. My
heartfelt thanks go to our director of GTRI’s Aerospace, Transportation & Advanced
Systems Laboratory (ATAS), Mr. Rusty Roberts, and all GTRI board members,
especially Dr. Dennis Folds and Dr. Lora Weiss, for their generosity and encourage-
ment. Being a part of GTRI is a once in a lifetime experience that allowed me to
fully focus on my graduate study yet provided me the opportunity to work closely
with industry.
I am also indebted to all of my colleagues at FPTD building in supporting me
intellectually, physically, and mentally. Without their help my experience at Tech
would not have been as memorable. Finally, I cannot thank enough all my family
members, dearest friends, and all signiﬁcant people in my life helping me get through
good and bad times in the United States. Thank you for always believing in me.
Each of you has signiﬁcantly contributed in my success.
Jomkwun Munnae
v
TABLE OF CONTENTS
DEDICATION . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . iii
ACKNOWLEDGEMENTS . . . . . . . . . . . . . . . . . . . . . . . . . . . . iv
LIST OF TABLES . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . x
LIST OF FIGURES . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . xv
LIST OF SYMBOLS OR ABBREVIATIONS . . . . . . . . . . . . . . . . . . xxv
SUMMARY . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .xxviii
I INTRODUCTION . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1
1.1 Motivation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1
1.2 Literature Review . . . . . . . . . . . . . . . . . . . . . . . . . . . 2
1.2.1 Visual Servoing Background . . . . . . . . . . . . . . . . . . 2
1.2.2 Literature Review of Uncalibrated Visual Servoing . . . . . 4
1.2.3 Summary . . . . . . . . . . . . . . . . . . . . . . . . . . . . 7
1.3 Contribution . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 7
1.4 Organization . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 8
II NEWTON’SMETHODANDQUASI-NEWTONMETHODSBACKGROUND 11
2.1 Newton’s Method . . . . . . . . . . . . . . . . . . . . . . . . . . . . 11
2.1.1 Newton’s Method for a One-Variable Scalar Function . . . . 11
2.1.2 Newton’s Method for a Multiple-Variable Function . . . . . 13
2.2 Quasi-Newton Methods . . . . . . . . . . . . . . . . . . . . . . . . 17
2.2.1 Broyden’s method . . . . . . . . . . . . . . . . . . . . . . . 17
2.2.2 Hessian Approximation . . . . . . . . . . . . . . . . . . . . 18
2.3 Damped Hessian . . . . . . . . . . . . . . . . . . . . . . . . . . . . 20
2.4 Line Search . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 22
2.5 Trust-Region Methods . . . . . . . . . . . . . . . . . . . . . . . . . 27
2.6 Summary . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 30
vi
III DYNAMICBROYDEN’SMETHODWITHRECURSIVE-LEAST-SQUARES
(RLS) UPDATE . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 33
3.1 Overview . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 34
3.2 Previous Work in Nonlinear Visual Servoing Optimization . . . . . 37
3.3 Dynamic Quasi-Newton Method via Recursive Least Squares Esti-
mation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 40
3.3.1 Theoretical Fundamental . . . . . . . . . . . . . . . . . . . 40
3.3.2 Simulation and Experimental Results . . . . . . . . . . . . . 43
3.4 Limitations . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 46
3.4.1 Large Initial Error . . . . . . . . . . . . . . . . . . . . . . . 46
3.4.2 Selection of Optimal Forgetting Factor . . . . . . . . . . . . 47
3.4.3 Ill-conditioned Hessian Matrix . . . . . . . . . . . . . . . . 49
3.5 Summary . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 50
IV MODIFIEDMETHODS FOR THELARGE-RESIDUAL VISUAL SERVO-
ING PROBLEM . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 52
4.1 Introduction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 53
4.2 Approximation of the Hessian for Large-Residual Problems Back-
ground . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 54
4.2.1 Approximation of the Whole Hessian . . . . . . . . . . . . . 55
4.2.2 Approximation of the Residual S . . . . . . . . . . . . . . . 57
4.2.3 The Gill-Murray Method . . . . . . . . . . . . . . . . . . . 60
4.3 Review of Large-Residual Visual Servoing Problems . . . . . . . . . 61
4.3.1 Kim et al. Studies . . . . . . . . . . . . . . . . . . . . . . . 62
4.3.2 Fu et al. Studies . . . . . . . . . . . . . . . . . . . . . . . . 63
4.4 Modiﬁed Hessian Approximations for the Large-Residual Visual Ser-
voing Problem . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 68
4.4.1 Approximation of the whole Hessian H using the DBFGS
k
update . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 69
4.4.2 Approximation of the residual S using the BFGS method . 75
k
4.4.3 Approximation of the residual S using the MBFGS update 76
k
4.5 Convergence Analysis of the MBFGS Method . . . . . . . . . . . . 80
vii
4.5.1 Convergence Analysis of the BFGS method . . . . . . . . . 84
4.5.2 Convergence Analysis of the MBFGS method . . . . . . . . 90
4.5.3 Proofs of Lemmas . . . . . . . . . . . . . . . . . . . . . . . 97
4.6 Rate of Convergence of the MBFGS method . . . . . . . . . . . . . 112
4.7 Switching MBFGS-DB Algorithm . . . . . . . . . . . . . . . . . . . 115
4.8 Summary . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 119
V DYNAMIC ADAPTIVE FORGETTING FACTOR ALGORITHM . . . 123
5.1 Introduction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 124
5.2 RLS Adaptive Filters Overview . . . . . . . . . . . . . . . . . . . . 125
5.3 Variable Forgetting Factor (VFF) Algorithms in Adaptive Filtering 129
5.3.1 RLS Algorithm with Adaptive Memory . . . . . . . . . . . 130
5.3.2 Gradient-Based VFF RLS Algorithm (GVFF-RLS) . . . . . 131
5.3.3 Gauss-Newton VFF RLS Algorithm (GN-VFF-RLS) . . . . 135
5.4 Dynamic Adaptive Forgetting Factor (DAFF) Algorithms for Visual
Guide Control . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 139
5.4.1 Previous Work on a VFF Algorithm for Uncalibrated Visual
Servoing . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 140
5.4.2 DAFF Method . . . . . . . . . . . . . . . . . . . . . . . . . 141
5.5 Summary . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 148
VI SIMULATION . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 149
6.1 Overview . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 150
6.2 System Description . . . . . . . . . . . . . . . . . . . . . . . . . . . 152
6.2.1 Robot System . . . . . . . . . . . . . . . . . . . . . . . . . . 152
6.2.2 Camera System . . . . . . . . . . . . . . . . . . . . . . . . . 152
6.2.3 Target Trajectories . . . . . . . . . . . . . . . . . . . . . . . 154
6.2.4 Assumptions . . . . . . . . . . . . . . . . . . . . . . . . . . 155
6.3 PerformanceEvaluationoftheSwitchingAlgorithmsforLargeResid-
ual Tracking . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 155
6.3.1 The RRR robot with a circular trajectory . . . . . . . . . . 158
viii
6.3.2 The Eﬀect of Partitioned and Non-Partitioned Broyden’s Es-
timator for Approximating the Jacobian . . . . . . . . . . . 161
6.3.3 The Eﬀect of Switching Criterion . . . . . . . . . . . . . . . 167
6.3.4 The PUMA 560 Robot . . . . . . . . . . . . . . . . . . . . . 173
6.3.5 Conclusion . . . . . . . . . . . . . . . . . . . . . . . . . . . 196
6.4 Performance Evaluation of the switching MBFGS-DB Algorithm
with LMA . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 201
6.4.1 RRR Robot . . . . . . . . . . . . . . . . . . . . . . . . . . . 203
6.4.2 PUMA 560 robot . . . . . . . . . . . . . . . . . . . . . . . . 208
6.4.3 Conclusion . . . . . . . . . . . . . . . . . . . . . . . . . . . 219
6.5 Performance Evaluations of the DAFF Method versus the Existing
VFF Algorithms . . . . . . . . . . . . . . . . . . . . . . . . . . . . 220
6.5.1 Eﬀect of Parameter Values on Each VFF Algorithm . . . . 221
6.5.2 Performance Evaluation of Various VFF Algorithms . . . . 228
6.5.3 Comparison between the settling time t vs. the cycle time t 265
s cyc
6.5.4 Conclusion . . . . . . . . . . . . . . . . . . . . . . . . . . . 266
6.6 Performance Evaluation of the Switching MBFGS-DB with various
VFF algorithm and with/without LMA . . . . . . . . . . . . . . . 268
6.6.1 Conclusion . . . . . . . . . . . . . . . . . . . . . . . . . . . 277
6.7 Summary . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 277
6.7.1 Conclusion . . . . . . . . . . . . . . . . . . . . . . . . . . . 279
VII CONCLUDING REMARKS . . . . . . . . . . . . . . . . . . . . . . . . 281
7.1 Contributions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 282
7.2 Summary . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 284
7.3 Future Work . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 289
REFERENCES . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 291
VITA . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 298
ix
LIST OF TABLES
5.1 The RLS and the DGN-PBM Parameter Equivalencies [29]. . . . . . . 140
6.1 A summary of methods to improve the dynamic quasi-Gauss Newton
algorithms. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 151
6.2 The DH parameters of a RRR robot. . . . . . . . . . . . . . . . . . . 152
6.3 Camera parameters. . . . . . . . . . . . . . . . . . . . . . . . . . . . 154
ˆ
6.4 A summary of methods for estimating residual S : Dynamic BFGS,
k
DFN-BFGS, MBFGS, and Fu’s Method . . . . . . . . . . . . . . . . 157
ˆ
6.5 The RMS error and the settling time comparison of various residual S
k
approximation schemes for θ = [60◦,70◦,50◦]T, λ = 0.5, and υ = 0.3
0
for all algorithms. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 159
6.6 The RMS error and the settling time comparison of various resid-
ˆ
ual S approximation schemes using NP-Jacobian estimation for θ =
k 0
[60◦,70◦,50◦]T, ω = 0.45 rad/s, λ = 0.5, and υ = 0.3 for all algorithms
except the Fu-DB algorithm where υ = 0.5 is used. . . . . . . . . . . 166
6.7 The RMS error and the settling time comparison of various resid-
ˆ
ual S approximation schemes using NP-Jacobian estimation for θ =
k 0
[60◦,70◦,50◦]T, ω = 0.9 rad/s, λ = 0.5, and υ = 0.3 for all algorithms. 166
6.8 A summary of the MBFGS algorithm varying in Jacobian approxi-
ˆ
mation and strategies for S inclusion using the RRR robot with two
k
eye-to-hand cameras starting at θ = [60◦,70◦,50◦]T with λ = 0.5. . . 172
0
6.9 The RMS error and the settling time comparison between the switch-
ing, Scheme 1, and Scheme 2 MBFGS-DB algorithms with/without
partitioned Broyden’s method. . . . . . . . . . . . . . . . . . . . . . . 173
6.10 The RMS error and the settling time comparison of various residual
ˆ
S approximation schemes for tracking the circular trajectory using a
k
ﬁxed forgetting factor λ = 0.5. . . . . . . . . . . . . . . . . . . . . . . 180
6.11 The RMS error and the settling time comparison of various residual
ˆ
S approximation schemes with ALT Scheme 1 and 2. . . . . . . . . . 185
k
6.12 The RMS error and the settling time comparison of various residual
ˆ
S approximation schemes for tracking four feature points of a circular
k
trajectory moving at ω = 0.9 rad/s using a ﬁxed λ = 0.5 and υ selected
to ensure convergence. . . . . . . . . . . . . . . . . . . . . . . . . . . 186
x
6.13 The RMS error and the settling time comparison of various residual
ˆ
S approximation schemes for tracking the cycloidal trajectory using
k
a ﬁxed forgetting factor λ = 0.5 and υ selected to ensure convergence. 193
6.14 The RMS error and the settling time comparison of various residual
ˆ
S approximation schemes for tracking the cycloidal trajectory using
k
a ﬁxed forgetting factor λ = 0.5 and υ selected to ensure convergence. 195
6.15 The RMS error and the settling time comparison of various residual
ˆ
S approximation schemes for tracking the helical trajectory using a
k
ﬁxed forgetting factor λ = 0.5, v = 5 mm/s, and υ selected to ensure
x
convergence. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 196
6.16 The RMS error and the settling time comparison of various residual
ˆ
S approximation schemes for tracking the helical trajectory using a
k
ﬁxed forgetting factor λ = 0.5, v = 10 mm/s, and υ selected to ensure
x
convergence. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 201
6.17 The RMS error and the settling time comparison of the RRR robot for
ˆ
various residual S approximation schemes with/without the LMA for
k
θ = [60◦,70◦,50◦]T, λ = 0.5, and υ = 0.3. The partitioned Broyden’s
0
ˆ
estimator is used for Jacobian J approximation. . . . . . . . . . . . . 204
k
6.18 The RMS error and the settling time comparison of the RRR robot
ˆ
for various residual S approximation schemes with/without the LMA
k
for θ = [60◦,70◦,50◦]T, λ = 0.5, and υ = 0.3. The NP Broyden’s
0
ˆ
estimator is used for Jacobian J approximation. . . . . . . . . . . . . 205
k
6.19 Various starting RRR robot conﬁgurations. . . . . . . . . . . . . . . . 205
6.20 The RMS error and the settling time comparison of the switching
MBFGS-DB algorithm with/without the LMA using υ = 0.3 and
λ = 0.5 at various starting RRR robot conﬁgurations. . . . . . . . . . 208
ˆ
6.21 The RMS error and the settling time comparison of various residual S
k
approximation schemes using the PUMA 560 robot to track a circular
trajectory using λ = 0.5 and υ = 0.3. . . . . . . . . . . . . . . . . . . 212
6.22 Various starting PUMA 560 robot conﬁgurations. . . . . . . . . . . . 213
6.23 The RMS error and the settling time comparison for the switching
MBFGS-DB algorithm with/without the LMA approach using υ =
0.3 and λ = 0.5 at various starting PUMA 560 robot conﬁgurations
tracking a circular trajectory. . . . . . . . . . . . . . . . . . . . . . . 213
6.24 The RMS error and the settling time comparison for the switching
MBFGS-DB algorithm with/without the LMA using υ = 0.3 and
λ = 0.5 at various starting PUMA 560 robot conﬁgurations tracking a
cycloidal trajectory. . . . . . . . . . . . . . . . . . . . . . . . . . . . . 219
xi
6.25 RMS error and t and settling time t for λ values in the FFF strategy. 222
s s
6.26 RMS error and t comparison of the VS-ARLS algorithm for diﬀerent
s
values of η with λ ∈ [0.60,0.95]. . . . . . . . . . . . . . . . . . . . . 223
1 k
6.27 RMSerrorandt comparisonoftheVS-ARLSalgorithmwithη = 0.05
s 1
for various ranges of [λ ,λ ]. . . . . . . . . . . . . . . . . . . . . 224
min max
6.28 RMS error and t comparison of the GN-VFF-RLS algorithm for vari-
s
ous values of η with λ ∈ [0.85,0.95]. . . . . . . . . . . . . . . . . . . 224
2 k
6.29 RMS error and t comparison of the GN-VFF-RLS algorithm for vari-
s
ous ranges of [λ ,λ ] with η = 0.01. . . . . . . . . . . . . . . . . 225
min max 2
6.30 RMS error and t comparison of the DAFF method for various values
s
of τ with λ ∈ [0.2,0.95]. . . . . . . . . . . . . . . . . . . . . . . . . . 225
k
6.31 The RMS error and t comparison of the DAFF method with various
s
values of τ with λ ∈ [0.20,0.90]. . . . . . . . . . . . . . . . . . . . . 226
k
6.32 RMS error and t comparison of the DAFF method for various values
s
of τ with λ ∈ [0.50,0.90]. . . . . . . . . . . . . . . . . . . . . . . . . 226
k
6.33 RMS error and t comparison of the DAFF method for various values
s
of τ with λ ∈ [0.50,0.95]. . . . . . . . . . . . . . . . . . . . . . . . . 226
k
6.34 RMS error and t for the Alt scheme between λ and λ . . . . . . 227
s low high
6.35 Selected parameters values for each forgetting factor scheme. . . . . . 228
6.36 The RMS error and the settling time comparison for VFF schemes us-
ing the RRR robot with two eye-to-hand cameras tracking one feature
point of a circular target moving at ω = 0.9 rad/s and υ = 0.3 for the
no additional noise scenario. . . . . . . . . . . . . . . . . . . . . . . . 229
6.37 The RMS error and the settling time comparison for VFF schemes us-
ing the RRR robot with two eye-to-hand cameras tracking one feature
point of a circular target moving at ω = 0.9 rad/s. The switching
criterion υ = 0.5 is used when ±1 pixel uniform quantization noise is
2
added to the target and EE feature points. . . . . . . . . . . . . . . . 233
6.38 RMSerrorandthesettlingtimecomparisonforVFFschemesusingthe
RRR robot with two eye-to-hand cameras perpendicularly arranged.
The target moves in a circular trajectory with an angular speed of
ω = 0.9 rad/s. ±1 pixel uniform quantization noise is added to the
2
target and EE feature points. . . . . . . . . . . . . . . . . . . . . . . 239
xii
6.39 The RMS error and the settling time comparison for VFF schemes us-
ing the RRR robot with two eye-to-hand cameras tracking one feature
point of a circular target moving at ω = 0.9 rad/s. The switching cri-
terion υ = 0.5 is used when ±1 mm noise is added to the EE location
in addition to ±1 pixel uniform quantization noise added to the target
2
and EE feature points. . . . . . . . . . . . . . . . . . . . . . . . . . . 244
6.40 The RMS error and the settling time comparison for VFF schemes us-
ing the RRR robot with two eye-to-hand cameras tracking one feature
point of a circular target moving at ω = 0.9 rad/s. The switching cri-
terion υ = 0.5 is used when ±1 mm noise is added to the EE location
in addition to ±1 pixel uniform quantization noise added to the target
2
and EE feature points. . . . . . . . . . . . . . . . . . . . . . . . . . . 245
6.41 The RMS error and the settling time comparison for VFF schemes
using the PUMA 560 robot with an eye-in-hand camera tracking four
feature points of a circular target moving at ω = 0.45 rad/s. The
switching criterion is υ = 0.3 and no additional noise is added. . . . . 249
6.42 The RMS error and the settling time comparison for VFF schemes
using the PUMA 560 robot with an eye-in-hand camera tracking four
feature points of a circular target moving at a faster angular speed
ω = 0.9 rad/s. The switching criterion is υ = 0.3 and no additional
noise is added. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 249
6.43 The RMS error and the settling time comparison for VFF schemes
using the PUMA 560 robot with an eye-in-hand camera tracking four
featurepointsofacirculartargetmovingattheangularspeedω = 0.45
rad/s. The switching criterion is υ = 0.5. Uniform quantization noise
of ±1 pixel is added to the target feature points. . . . . . . . . . . . . 250
6.44 The RMS error and the settling time comparison for VFF schemes
using the PUMA 560 robot with two eye-in-hand cameras, each track-
ing four feature points of a circular target moving at the angular speed
ω = 0.45 rad/s. The switching criterion υ = 0.5. Uniform quantization
noise of ±1 pixel is added to the target feature points. . . . . . . . . 257
6.45 The RMS error and the settling time comparison for various VFF
schemes using the PUMA 560 robot with an eye-in-hand camera track-
ingfour feature points of a square targetmoving at thespeed 50mm/s.
The switching criterion υ = 0.3. No additional noise is added. . . . . 263
6.46 TheRMSerrorandthesettlingtimecomparisonofvariousVFFschemes
using the PUMA 560 robot with an eye-in-hand camera tracking four
feature points of a square target moving at the speed 50 mm/s. The
switching criterion υ = 0.3 is used with ±1 mm uniform quantization
noise added to the EE location in addition to uniform quantization
noise of ±1 pixel added to the target feature points. . . . . . . . . . . 265
xiii
6.47 The RMS error and the settling time comparison of the DAFF and the
Alt schemes using the PUMA 560 robot with two eye-in-hand cameras,
eachtrackingfourfeaturepointsofasquaretargetmovingataspeed50
mm/s. Theswitchingcriterionisυ = 0.3.Uniformquantization±1mm
noise is added to the EE location in addition to uniform quantization
noise of ±1 pixel added to the target feature points. . . . . . . . . . . 266
6.48 The cycle time (t ) and the settling time (t ) comparison of the
cyc s
switching MBFGS-DB with DAFF method for tracking various trajec-
tories with varying target speed using υ selected to ensure convergence. 267
6.49 The RMS error and the settling time comparison of the switching
MBFGS-DB algorithm with/without LMA and a variety of the VFF
algorithms. The PUMA 560 robot with an eye-in-hand camera is used
for tracking four feature points of a cycloidal target. The switching
criterion υ = 0.3 is used with uniform quantization noise of ±1 pixel
added to the target feature points. . . . . . . . . . . . . . . . . . . . 269
6.50 The RMS error and the settling time comparison of the DGN-PBM
algorithm with/without LMA and a variety of the VFF algorithms.
The PUMA 560 robot with an eye-in-hand camera is used for tracking
fourfeaturepointsofacycloidaltarget. Theswitchingcriterionυ = 0.3
is used with uniform quantization noise of ±1 pixel added to the target
feature points. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 276
xiv
LIST OF FIGURES
2.1 A geometrical representation of an aﬃne model. . . . . . . . . . . . 12
2.2 Pseudo-code of Newton’s method for solving unconstrained optimiza-
tion problems . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 15
2.3 An example of an exact line search [1] starting from x to reach the
0
solution x∗ along the steepest-descent direction at each iteration. . . 24
2.4 Pseudo-code for backtracking line search with Newton’s method . . . 25
2.5 Pseudo-code for the BFGS algorithm with the backtracking line-search
method . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 26
2.6 An example of a trust region [76] with a radius δ centered at x where
k k
the next update x is restricted to be inside the trust region. . . . 28
k+1
3.1 For an eye-to-hand system the camera is remote from the robot and
the target. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 35
3.2 For an eye-in-hand system the camera is attached to the robot EE. . 36
3.3 A pseudo-code for the DBM-RLS . . . . . . . . . . . . . . . . . . . . 42
3.4 A pseudo-code for the DGN-PBM method . . . . . . . . . . . . . . . 44
3.5 A simulation result of a six DOF robot with an eye-in-hand system
using the DGN-PBM method when an initial error is signiﬁcant shown
in the task space view. . . . . . . . . . . . . . . . . . . . . . . . . . 48
3.6 A simulation result of an eye-in-hand, six DOF robot using the DGN-
PBM method with a constant λ shown in the task space view. . . . 49
4.1 Pseudo-code for the algorithm in [25] . . . . . . . . . . . . . . . . . . 67
4.2 A pseudo-code for the DBFGS update . . . . . . . . . . . . . . . . . 74
4.3 Pseudo-code for the DFN-BFGS approach . . . . . . . . . . . . . . . 77
4.4 Pseudo-code for the MBFGS approach . . . . . . . . . . . . . . . . . 81
4.5 Pseudo-code for the switching MBFGS-DB algorithm . . . . . . . . . 120
5.1 Transversal ﬁlter [32]. . . . . . . . . . . . . . . . . . . . . . . . . . . 127
5.2 A pseudo-code for the RLS algorithm [32]. . . . . . . . . . . . . . . . 129
5.3 A pseudo-code for the RLS algorithm with adaptive memory [32]. . . 132
5.4 A pseudo-code for the GVFF-RLS algorithm [41]. . . . . . . . . . . . 136
5.5 A pseudo-code for the GN-VFF-RLS algorithm [71]. . . . . . . . . . . 139
xv
5.6 A pseudo-code for the VS-ARLS algorithm [29] . . . . . . . . . . . . 142
5.7 The expected (cid:107)f (cid:107) values for ideal tracking performance and the hy-
k
pothesized λ values in corresponding to (cid:107)f (cid:107) with respect to time
k k
(s). . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 145
5.8 Pseudo-code for the DAFF method with the switching MBFGS-DB
algorithm . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 147
6.1 (a)The RRR robot, (b) The PUMA 560 robot. . . . . . . . . . . . . 153
6.2 Pseudo-code for the switching DBFGS-DB, DFN-BFGS-DB, MBFGS-
DB, and Fu-DB algorithms . . . . . . . . . . . . . . . . . . . . . . . . 160
6.3 The camera space of the RRR manipulator with two eye-to-hand cam-
era conﬁgurations tracks a circular target trajectory moving at ω =
0.45 rad/s. The forgetting factor is λ = 0.5 and υ = 0.3 for all algo-
rithms except the switching Fu-DB where υ = 0.5 is used. . . . . . . 162
6.4 The task space view showing one camera and one target point for clar-
ity (the others are similar) for the RRR manipulator with two eye-to-
hand cameras tracking a circular target trajectory moving at ω = 0.45
rad/s. The forgetting factor is λ = 0.5 and υ = 0.3 for all algorithms
except the switching Fu-DB where υ = 0.5 is used. . . . . . . . . . . . 163
6.5 The error norm of the RRR manipulator with two eye-to-hand camera
conﬁgurations tracks a circular target trajectory moving at ω = 0.45
rad/s. The forgetting factor is λ = 0.5 and υ = 0.3 for all algorithms
except the switching Fu-DB where υ = 0.5 is used. . . . . . . . . . . . 164
6.6 The performance comparison between the switching MBFGS-DB and
NP-MBFGS-DB algorithms (a)-(b) the image plane, (c)-(d) the task
space view, and (e)-(f) error norm of the RRR manipulator using two
eye-to-hand cameras tracking a circular target trajectory moving at
ω = 0.45 rad/s. The forgetting factor is λ = 0.5 and υ = 0.3 . . . . . 165
6.7 Pseudo-code for the MBFGS-DB Scheme 1 using a similar scaling
method presented in [17, 19] . . . . . . . . . . . . . . . . . . . . . . . 169
6.8 Pseudo-code for the MBFGS-DB Scheme 2 using a hybrid method
similar to [49] . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 171
6.9 The camera space of the RRR manipulator with two eye-to-hand cam-
eras using (a) P-Switching (υ = 0.3), (b) NP-Switching (υ = 0.3), (c)
P-Scheme 1, (d) NP-Scheme 1, (e) P-Scheme 2, and (f) NP-Scheme
2. A circular target trajectory is moving at ω = 0.45 rad/s. The
forgetting factor is λ = 0.5. . . . . . . . . . . . . . . . . . . . . . . . . 174
xvi
6.10 The task space view showing one camera and one target point using
(a) P-Switching (υ = 0.3), (b) NP-Switching (υ = 0.3), (c) P-Scheme
1, (d) NP-Scheme 1, (e) P-Scheme 2, and (f) NP-Scheme 2. A circular
target trajectory is moving at ω = 0.45 rad/s. The forgetting factor is
λ = 0.5 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 175
6.11 The camera space of the PUMA 560 manipulator with an eye-in-hand
camera conﬁguration tracking four feature points of a circular target
trajectory moving at ω = 0.45 rad/s. The forgetting factor is λ = 0.5
and υ = 0.3 (except the DBFGS-DB υ=0.55). . . . . . . . . . . . . . 177
6.12 The task space view showing camera and one target point for clarity
(the others are similar) for the PUMA 560 manipulator with an eye-
in-hand camera conﬁguration tracking four feature points of a circular
target trajectory moving at ω = 0.45 rad/s. The forgetting factor is
λ = 0.5 and υ = 0.3 (except the DBFGS-DB υ=0.55). . . . . . . . . . 178
6.13 The error norm of the PUMA 560 manipulator with an eye-in-hand
camera conﬁguration tracking four feature points of a circular target
trajectory moving at ω = 0.45 rad/s. The forgetting factor is λ = 0.5
and υ = 0.3 (except the DBFGS-DB υ=0.55). . . . . . . . . . . . . . 179
6.14 The camera space (left column) and the task space (right column)
views of the PUMA 560 robot tracking four feature points of a circular
trajectory using the DBFGS-DB with Scheme 1 and 2. . . . . . . . . 181
6.15 The camera space (left column) and the task space (right column)
views of the PUMA 560 robot tracking four feature points of a circular
trajectory using the DFN-BFGS-DB with Scheme 1 and 2. . . . . . . 182
6.16 The camera space (left column) and the task space (right column)
views of the PUMA 560 robot tracking four feature points of a circular
trajectory using the MBFGS-DB with Scheme 1 and 2. . . . . . . . . 183
6.17 The camera space (left column) and the task space (right column)
views of the PUMA 560 robot tracking four feature points of a circular
trajectory using the Fu-DB with Scheme 1 and 2. . . . . . . . . . . . 184
6.18 The task space view showing camera and one target point for clarity
(the others are similar) for the PUMA 560 manipulator with an eye-
in-hand camera conﬁguration tracking four feature points of a circular
target trajectory moving at ω = 0.90 rad/s. The forgetting factor is
λ = 0.5 and υ is selected to ensure convergence. . . . . . . . . . . . . 187
6.19 The error norm of the PUMA 560 manipulator with an eye-in-hand
camera conﬁguration tracking four feature points of a circular target
trajectory moving at ω = 0.90 rad/s. The forgetting factor is λ = 0.5
and υ is selected to ensure convergence. . . . . . . . . . . . . . . . . . 188
xvii
6.20 The camera space of the PUMA 560 manipulator with an eye-in-hand
camera conﬁguration tracks four feature points of a cycloid target tra-
jectory. The forgetting factor is λ = 0.5 and υ is selected to ensure
convergence. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 190
6.21 The task space view showing camera and one target point for clarity
(the others are similar) for the PUMA 560 manipulator with an eye-
in-hand camera conﬁguration tracking four feature points of a cycloid
target trajectory. The forgetting factor is λ = 0.5 and υ is selected to
ensure convergence. . . . . . . . . . . . . . . . . . . . . . . . . . . . . 191
6.22 The error norm of the PUMA 560 manipulator with an eye-in-hand
camera conﬁguration tracks four feature points of a cycloid target tra-
jectory. The forgetting factor is λ = 0.5 and υ is selected to ensure
convergence. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 192
6.23 The camera space (left column) and the task space (right column)
views of the PUMA 560 robot tracking four feature points of a fast
cycloidal trajectory. . . . . . . . . . . . . . . . . . . . . . . . . . . . . 194
6.24 The camera space of the PUMA 560 manipulator with an eye-in-hand
camera conﬁguration tracks four feature points of a helical target tra-
jectory. Theforgettingfactorisλ = 0.5, v = 5mm/s, andυ isselected
x
to ensure convergence. . . . . . . . . . . . . . . . . . . . . . . . . . . 197
6.25 The task space view showing camera and one target point for clarity
(the others are similar) for the PUMA 560 manipulator with an eye-
in-hand camera conﬁguration tracking four feature points of a helical
target trajectory. The forgetting factor is λ = 0.5, v = 5 mm/s, and
x
υ is selected to ensure convergence. . . . . . . . . . . . . . . . . . . . 198
6.26 The error norm of the PUMA 560 manipulator with an eye-in-hand
camera conﬁguration tracks four feature points of a helical target tra-
jectory. Theforgettingfactorisλ = 0.5, v = 5mm/s, andυ isselected
x
to ensure convergence. . . . . . . . . . . . . . . . . . . . . . . . . . . 199
6.27 The task space view showing one target point for clarity (the others are
similar) for the PUMA 560 manipulator with an eye-in-hand camera
conﬁguration tracking four feature points of a helical target trajectory
moving with a faster speed in x direction. The forgetting factor is
λ = 0.5, v = 10 mm/s, and υ is selected to ensure convergence. . . . 200
x
6.28 The camera space comparison of implementing the switching MBFGS-
DBalgorithmwiththeLMA(leftcolumn)andwithouttheLMA(right
column) at various starting RRR robot conﬁgurations. . . . . . . . . 206
xviii
6.29 The camera space comparison of implementing the switching MBFGS-
DBalgorithmwiththeLMA(leftcolumn)andwithouttheLMA(right
column) at various starting RRR robot conﬁgurations. . . . . . . . . 207
6.30 The camera space of the PUMA 560 manipulator with the eye-in-hand
camera conﬁguration using various switching algorithms implemented
with the LMA to track four feature points of the circular target tra-
jectory moving at ω = 0.45 rad/s and υ = 0.3. The forgetting factor
is λ = 0.5. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 209
6.31 The task space view showing one target point for clarity (the others
are similar) for the PUMA 560 manipulator with an eye-in-hand cam-
era conﬁguration using various switching algorithms with the LMA
tracking four feature points of a circular target trajectory moving at
ω = 0.45 rad/s. The forgetting factor is λ = 0.5 and υ = 0.3. . . . . . 210
6.32 The error norm of the PUMA 560 manipulator with an eye-in-hand
camera conﬁguration using various switching algorithms implemented
withtheLMAtotrackfourfeaturepointsofacirculartargettrajectory
moving at ω = 0.45 rad/s. The forgetting factor is λ = 0.5 and υ = 0.3.211
6.33 The camera space comparison of the switching MBFGS-DB algorithm
with the LMA (left column) and without the LMA (right column) at
various starting PUMA 560 robot conﬁgurations tracking four feature
pointsofacirculartargettrajectorymovingatω = 0.45rad/s, υ = 0.3,
and λ = 0.5. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 214
6.34 The task space view showing one camera and one target point for clar-
ity for the switching MBFGS-DB algorithm with the LMA (left col-
umn) and without the LMA (right column) at various starting PUMA
560robotconﬁgurationstrackingfourfeaturepointsofacirculartarget
trajectory moving at ω = 0.45 rad/s, υ = 0.3, and λ = 0.5. . . . . . . 215
6.35 The camera space comparison of the switching MBFGS-DB algorithm
with the LMA (left column) and without the LMA (right column) at
various starting PUMA 560 robot conﬁgurations tracking four feature
points of a cycloidal target trajectory using υ = 0.3 and λ = 0.5. . . . 216
6.36 The task space of the EE motion using the switching MBFGS-DB
algorithm with the LMA (left column) and without the LMA (right
column) at various starting PUMA 560 robot conﬁgurations tracking
four feature points of a cycloidal target trajectory using υ = 0.3 and
λ = 0.5. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 217
xix
6.37 The RMS tracking error comparison of the switching MBFGS-DB al-
gorithm with the LMA (left column) and without the LMA (right
column) at various starting PUMA 560 robot conﬁgurations tracking
four feature points of a cycloidal target trajectory using υ = 0.3 and
λ = 0.5. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 218
6.38 The camera space of the RRR manipulator with two eye-to-hand cam-
eras tracking one feature point of the circular target trajectory moving
at ω = 0.90 rad/s. Various VFF algorithms for λ are implemented
k
with the switching MBFGS-DB with υ = 0.3. . . . . . . . . . . . . . 230
6.39 The task space view showing one target point for clarity (the other
views are similar) for the RRR manipulator with two eye-to-hand cam-
eras using the switching MBFGS-DB with various VFF algorithms for
λ and υ = 0.3. The robot is tracking one feature point of a circular
k
target trajectory moving at ω = 0.90 rad/s. . . . . . . . . . . . . . . 231
6.40 The error norm (top) and the forgetting factor λ (bottom) for the
k
RRR manipulator with two eye-to-hand cameras using the switching
MBFGS-DB with various VFF algorithms for λ and υ = 0.3. The
k
forgettingfactorλ Therobotistrackingonefeaturepointofacircular
k
target trajectory moving at ω = 0.90 rad/s. . . . . . . . . . . . . . . 232
6.41 The camera space of the RRR manipulator with two eye-to-hand cam-
eras tracking one feature point of a circular target trajectory moving at
ω = 0.90 rad/s. Various VFF algorithms for λ are implemented with
k
the switching MBFGS-DB with υ = 0.5 for which ±1 pixel uniform
2
quantization noise is added to the target and EE feature points. . . . 234
6.42 The task space view showing one camera and one target point for clar-
ity (the other view is similar) for the RRR manipulator with two eye-
to-hand cameras using the switching MBFGS-DB with various VFF
algorithms for λ and υ = 0.5. The robot is tracking one feature point
k
of a circular target trajectory moving at ω = 0.90 rad/s for which ±1
2
pixel uniform quantization noise is added to the target and EE feature
points. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 235
6.43 The camera space of the RRR manipulator with two eye-to-hand cam-
eras perpendicularly arranged tracking one feature point of the circular
target trajectory moving at ω = 0.90 rad/s. Various VFF algorithms
for λ are implemented into the switching MBFGS-DB with υ = 0.5
k
for which ±1 pixel uniform quantization noise is added to the target
2
and EE feature points. . . . . . . . . . . . . . . . . . . . . . . . . . . 237
xx
6.44 The task space view showing one camera and one target point for
clarity (the camera view is similar) for the RRR manipulator with
two eye-to-hand cameras perpendicularly arranged using the switching
MBFGS-DB with various VFF algorithms for λ and υ = 0.5. The
k
robotistrackingonefeaturepointofacirculartargettrajectorymoving
at ω = 0.90 rad/s for which ±1 pixel uniform quantization noise is
2
added to the target and EE feature points. . . . . . . . . . . . . . . . 238
6.45 A perpendicular camera arrangement where one camera is pointed in
the z direction while the other camera is pointed into the −x direction
is used with the RRR robot for noise compensation. . . . . . . . . . 240
6.46 The camera space of the RRR manipulator with two eye-to-hand cam-
eras tracking one feature point of a circular target trajectory moving
at ω = 0.90 rad/s. Various VFF algorithms for λ are implemented
k
with the switching MBFGS-DB with υ = 0.5 for which ±1 mm noise is
added to the EE location in addition to ±1 pixel uniform quantization
2
noise added to the target and EE feature points . . . . . . . . . . . . 241
6.47 The task space view showing one camera and one target point for clar-
ity (the other view is similar) for the RRR manipulator with two eye-
to-hand cameras using the switching MBFGS-DB with various VFF
algorithms for λ and υ = 0.5. The robot is tracking one feature point
k
of a circular target trajectory moving at ω = 0.90 rad/s for which ±1
mm noise is added to the EE location in addition to ±1 pixel uniform
2
quantization noise added to the target and EE feature points. . . . . 242
6.48 The task space view showing one camera and one target point for
clarity (the camera views are similar) for the RRR manipulator with
two eye-to-hand cameras perpendicularly arranged using the switching
MBFGS-DB with various VFF algorithms for λ and υ = 0.5. The
k
robotistrackingonefeaturepointofacirculartargettrajectorymoving
at ω = 0.90 rad/s for which ±1 mm noise is added to the EE location
in addition to ±1 pixel uniform quantization noise added to the target
2
and EE feature points. . . . . . . . . . . . . . . . . . . . . . . . . . . 243
6.49 The camera space of the PUMA 560 manipulator with the eye-in-hand
camera tracking four feature points of the circular target trajectory
moving at ω = 0.45 rad/s. VFF algorithms for λ calculation are im-
k
plemented into the switching MBFGS-DB with υ = 0.3. No additional
noise is added. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 246
xxi
6.50 The task space view showing one camera and one target point for
clarity (the other views are similar) of the PUMA 560 manipulator
with the eye-in-hand camera tracking four feature points of the circular
target trajectory moving at ω = 0.45 rad/s. VFF algorithms for λ
k
calculation are implemented into the switching MBFGS-DB with υ =
0.3. No additional noise is added. . . . . . . . . . . . . . . . . . . . . 247
6.51 The error norm of the PUMA 560 manipulator with an eye-in-hand
camera tracking four feature points of the circular target trajectory
moving at ω = 0.45 rad/s. VFF algorithms for λ calculation are im-
k
plemented into the switching MBFGS-DB with υ = 0.3. No additional
noise is added. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 248
6.52 The camera space of the PUMA 560 manipulator with an eye-in-hand
camera tracking four feature points of the circular target trajectory
moving at ω = 0.45 rad/s. Various VFF algorithms for λ calculation
k
areimplementedintotheswitchingMBFGS-DBwithυ = 0.5. Uniform
quantization noise of ±1 pixel is added to the target feature points. . 251
6.53 The task space view showing one target point for clarity (the others are
similar) for the PUMA 560 manipulator with an eye-in-hand camera
using the switching MBFGS-DB with various VFF algorithms for λ
k
calculation and υ = 0.5. The robot is tracking four feature points
of a circular target trajectory moving at ω = 0.45 rad/s. Uniform
quantization noise of ±1 pixel is added to the target feature points. . 252
6.54 The error norm (top) and the forgetting factor λ (bottom) for the
k
PUMA 560 manipulator with an eye-in-hand camera using the switch-
ing MBFGS-DB with various VFF algorithms for λ and υ = 0.5. The
k
robot istracking four feature pointsofacirculartargettrajectory mov-
ing at ω = 0.45 rad/s. Uniform quantization noise of ±1 pixel is added
to the target feature points. . . . . . . . . . . . . . . . . . . . . . . . 253
6.55 The task space view showing one target point for clarity (the others are
similar) for the PUMA 560 manipulator with two eye-in-hand cameras
using the switching MBFGS-DB with various VFF algorithms for λ
k
and υ = 0.5. Each camera is tracking four feature points of a circular
target trajectory moving at ω = 0.45 rad/s. Uniform quantization
noise of ±1 pixel is added to the target feature points. . . . . . . . . 255
6.56 The task space in YZ view showing one target point comparison be-
tween the one and two eye-in-hand cameras used for the PUMA 560
manipulator using the switching MBFGS-DB with the DAFF and Alt
algorithms(υ = 0.5)withuniformquantizationnoiseof±1pixeladded
tothetargetfeaturepoints. Eachcameraistrackingfourfeaturepoints
of a circular target trajectory moving at ω = 0.45 rad/s. . . . . . . . 256
xxii
6.57 The task space view showing one target point for clarity (the others are
similar) for the PUMA 560 manipulator with an eye-in-hand camera
using the switching MBFGS-DB with various VFF algorithms for λ
k
and υ = 0.3. The robot is tracking four feature points of a square
target trajectory moving at a speed 50 mm/s. No additional noise is
added. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 259
6.58 The error norm (top) and the forgetting factor λ (bottom) for the
k
PUMA 560 manipulator with an eye-in-hand camera using the switch-
ing MBFGS-DB with various VFF algorithms for λ and υ = 0.3.
k
The robot is tracking four feature points of a square target trajectory
moving at a speed 50 mm/s. No noise is added. . . . . . . . . . . . . 260
6.59 The task space view showing one target point for clarity (the others are
similar) for the PUMA 560 manipulator with an eye-in-hand camera
using the switching MBFGS-DB with various VFF algorithms for λ
k
andυ = 0.3. Therobotistrackingfourfeaturepointsofasquaretarget
trajectory moving at a speed 50 mm/s. ±1 mm uniform quantization
noise is added to the EE location in addition to uniform quantization
noise of ±1 pixel added to the target feature points. . . . . . . . . . . 261
6.60 The error norm (top) and the forgetting factor λ (bottom) for the
k
PUMA 560 manipulator with an eye-in-hand camera using the switch-
ing MBFGS-DB with various VFF algorithms for λ and υ = 0.3. The
k
robot is tracking four feature points of a square target trajectory mov-
ing at a speed 50 mm/s. ±1 mm uniform quantization noise is added
to the EE location in addition to uniform quantization noise of ±1
pixel added to the target feature points. . . . . . . . . . . . . . . . . 262
6.61 The task space view showing one camera and one target point (left col-
umn), the error norm and λ (right column) of the PUMA 560 manip-
k
ulator with two eye-in-hand cameras using the switching MBFGS-DB
with the DAFF and the Alt algorithms with υ = 0.3. Each camera
tracks four feature points of a square target trajectory moving at a
speed 50 mm/s. Uniform quantization ±1 mm noise is added to the
EElocationinadditiontouniformquantizationnoiseof±1pixeladded
to the target feature points. . . . . . . . . . . . . . . . . . . . . . . . 264
6.62 The camera space of the PUMA 560 manipulator with an eye-in-hand
camera using the switching MBFGS-DB with various VFF algorithms
implemented with the LMA (left column) and without the LMA (right
column). The robot is tracking four feature points of a cycloidal tra-
jectory. Uniform quantization noise of ±1 pixel is added to the target
feature points. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 270
xxiii
6.63 The task space view showing one target point for clarity (the oth-
ers are similar) for the PUMA 560 manipulator with an eye-in-hand
camera using the switching MBFGS-DB with various VFF algorithms
implemented with the LMA (left column) and without the LMA (right
column). The robot is tracking four feature points of a cycloidal tra-
jectory. Uniform quantization noise of ±1 pixel is added to the target
feature points. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 271
6.64 The error norm and λ plots of the PUMA 560 manipulator with an
k
eye-in-hand camera using the switching MBFGS-DB for various VFF
algorithms implemented with the LMA (left column) and without the
LMA (right column). The robot is tracking four feature points of a
cycloidal target trajectory. Uniform quantization noise of ±1 pixel is
added to the target feature points. . . . . . . . . . . . . . . . . . . . 272
6.65 The camera space of the PUMA 560 manipulator with the eye-in-hand
camera using the DGN-PBM for various VFF algorithms implemented
withtheLMA(leftcolumn)andwithouttheLMA(rightcolumn). The
robot is tracking four feature points of a cycloidal trajectory. Uniform
quantization noise of ±1 pixel is added to the target feature points. . 273
6.66 The task space view showing one target point for clarity (the others are
similar) for the PUMA 560 manipulator with an eye-in-hand camera
using the DGN-PBM for various VFF algorithms implemented with
the LMA (left column) and without the LMA (right column). The
robot is tracking four feature points of a cycloidal trajectory. Uniform
quantization noise of ±1 pixel is added to the target feature points. . 274
6.67 The error norm and λ plots of the PUMA 560 manipulator with an
k
eye-in-hand camera using the DGN-PBM for various VFF algorithms
implemented with the LMA (left column) and without the LMA (right
column). The robot is tracking four feature points of a cycloidal target
trajectory. Uniform quantization noise of ±1 pixel is added to the
target feature points. . . . . . . . . . . . . . . . . . . . . . . . . . . . 275
xxiv
LIST OF SYMBOLS OR ABBREVIATIONS
BD Broyden-Dennis method.
BFGS BroydenFletcherGoldfarbShanno method.
BFGS-QN Quasi-Newton method with the BFGS method.
DBFGS Dynamic BFGS algorithm.
DBFGS-DB Switching modiﬁed DBFGS-dynamic Broyden algorithm.
DBM-RLS Dynamic Broyden’s method using recursive least-squares estimation.
DFN-BFGS Dynamic Full Newton method with BFGS algorithm.
DFN-BFGS-DB Switching modiﬁed DFN-BFGS-dynamic Broyden algorithm.
DGN-PBM DynamicGauss-NewtonalgorithmwithpartitionedBroyden’smethod.
ECL Endpoint closed-loop.
EOL Endpoint open-loop.
FFF Fixed forgetting factor algorithm.
Fu-DB Switching modiﬁed Fu-dynamic Broyden algorithm.
GN-VFF-RLS Gauss-Newton variable forgetting factor RLS.
GVFF-RLS Gradient-based VFF RLS algorithm.
IBVS Image-based visual servo system.
LMA Levenberg-Marquardt algorithm.
MBFGS Modiﬁed BFGS.
MBFGS-DB Switching modiﬁed BFGS-dynamic Broyden algorithm.
MBFGS-QN Quasi-Newton method with the MBFGS method.
NP The non-partitioned Broyden’s method.
P The partitioned Broyden’s method.
PBVS Position-based visual servo system.
RLS Recursive least-squares algorithm.
VFF Variable forgetting factor algorithm.
xxv
VS-ARLS Uncalibrated visual servoing using adaptive RLS algorithm.
´
H An approximation of H in which only the residual S is estimated.
k k k
´
H The modiﬁed Hessian matrix at iteration k.
d,k
α The Levenberg-Marquardt parameter.
fˇ fˇ = (cid:107)fk(cid:107).
k k fmax
∆f ∆f = f −f , the change in the image error.
k k−1
δ A trust region size.
η Learning rate of the VS-ARLS algorithm.
1
η Learning rate of the GN-VFF-RLS algorithm.
2
ˆ
H An estimated Hessian.
ˆ
H An estimated Hessian at iteration k.
k
ˆ
J An estimated Jacobian at iteration k.
k
ˆ
S An estimated Residual at iteration k.
k
λ Forgetting factor.
Λ Λ = 1−λ .
k k k
(·) Denotes kth iteration.
k
(cid:107)·(cid:107) l norm of a vector.
2
(cid:107)·(cid:107) Frobenius norm of a matrix.
F
ω An angular speed.
τ Time Constant.
θ Robot joint angles.
(cid:104) (cid:16) (cid:17) (cid:105)
J˜ J˜ = Jˆ fˆ .
k k k−1 t
k−1
(cid:20) (cid:21)
(θ −θ )
h˜ h˜ = k k−1 .
(t −t )
k k−1
υ Switching criterion.
ϕ Switching parameter.
D A diagonal matrix.
xxvi
E[·] Expected value.
f Error in the image space at iteration k.
k
f f = max{(cid:107)f (cid:107),(cid:107)f (cid:107),...,(cid:107)f (cid:107)}.
max max 1 2 k
(cid:104) (cid:105)
g∗ g∗ = JT (f + ∂fk+1h ) −(cid:2)JT(f + ∂fkh )(cid:3).
k k k+1 k+1 ∂t t k k ∂t t
g g = JT f −JTf .
k k k+1 k+1 k k
H The Hessian matrix.
H The Hessian matrix at iteration k.
k
h h = t −t , an increment of time.
t t k k−1
h h = θ −θ , an increment of θ.
θ θ k k−1
J ∂y, the composite Jacobian.
∂θ
J The Jacobian at iteration k.
k
m The aﬃne model of f.
k
P Estimate of the inverse of the correlation matrix of h .
k θ
q The quadratic model of the objective function F.
k
t Settling time.
s
t Cycle time.
cyc
y Robot EE feature points.
y∗ Target feature points.
z∗ z∗ = JT f −JTf .
k k k+1 k+1 k k+1
xxvii
SUMMARY
In visually guided control of a robot, a large residual problem occurs when the
robotconﬁgurationθ isnotintheneighborhoodofthetargetacquisitionconﬁguration
θ∗. Most existing uncalibrated visual servoing algorithms use quasi-Gauss-Newton
methods which are eﬀective for small residual problems. The solution used in this
study switches between a full quasi-Newton method for large residual case and the
quasi-Gauss-Newton methods for the small case. Visual servoing to handle large
residual problems for tracking a moving target has not previously appeared in the
literature.
For large residual problems various Hessian approximations are introduced in-
cluding an approximation of the entire Hessian matrix,the dynamic BFGS (DBFGS)
algorithm, and two distinct approximations of the residual term, the modiﬁed BFGS
(MBFGS) algorithm and the dynamic full Newton method with BFGS (DFN-BFGS)
algorithm. Due to the fact that the quasi-Gauss-Newton method has the advan-
tage of fast convergence, the quasi-Gauss-Newton step is used as the iteration is
suﬃciently near the desired solution. A switching algorithm combines a full quasi-
Newton method and a quasi-Gauss-Newton method. Switching occurs if the image
error norm is less than the switching criterion, which is heuristically selected.
Anadaptiveforgettingfactorcalledthedynamicadaptiveforgettingfactor(DAFF)
is presented. The DAFF method is a heuristic scheme to determine the forgetting
factor value based on the image error norm. Compared to other existing adaptive
forgetting factor schemes, the DAFF method yields the best performance for both
convergence time and the RMS error.
Simulation results verify validity of the proposed switching algorithms with the
xxviii
DAFFmethodforlargeresidualproblems. TheswitchingMBFGSalgorithmwiththe
DAFF method signiﬁcantly improves tracking performance in the presence of noise.
This work is the ﬁrst successfully developed model independent, vision-guided control
for large residual with capability to stably track a moving target with a robot.
xxix
CHAPTER I
INTRODUCTION
1.1 Motivation
Visual sensing is critical for many biological systems but its use in robotic applica-
tions is still relatively limited. One of the reasons is that the vision systems typically
require calibration and frequently this calibration drifts due to operating and envi-
ronmental factors. Uncalibrated visual servoing, on the contrary, has advantages over
the model-based visual control by eliminating requirement of system modeling and
camera calibration.
A number of studies formulate uncalibrated visual servoing as nonlinear opti-
mization problems in which Newton’s method and quasi-Newton methods are typi-
cally used for ﬁnding a solution. These methods are powerful techniques that give
quadratic convergence if certain assumptions apply. As a result, various algorithms
incorporate them to give eﬀective tracking performance in uncalibrated systems.
One of the major challenge of the quasi-Gauss-Newton algorithms is that they are
limited to only the zero- or small-residual cases. The residual S is a second order
k
diﬀerential term appears in the Hessian H matrix. For a visual control problem, a
k
zero- or small-residual problem refers to the case that the initial robot conﬁguration
θ is close to the target acquisition conﬁguration θ∗ so S is likely small and can be
0 k
ignored. Consequently, the quasi-Newton method becomes the quasi-Gauss-Newton
method when the residual S is excluded. Often the residual S is computationally
expensive and is set to zero.
However, there exists circumstances where the initial robot conﬁguration θ is
0
not near the desired target conﬁguration θ∗ and the residual S becomes signiﬁcant.
k
1
This is called the large-residual problem. In this case quasi-Gauss-Newton method is
less appropriate and the full quasi-Newton method (including S) should be applied.
Visually guided control to handle large residual problems for moving target tracking
has not appeared in the literature.
1.2 Literature Review
Theobjectiveofthisstudyistodevelopanuncalibratedvisualservoingsystemforthe
large residual problem that accurately tracks a moving target with fast convergence.
Since uncalibrated visual servoing is a sub-set of visual based control, an overview of
visual based control is discussed in Section 1.2.1. Thenvarious studies of uncalibrated
visual servoing related to large residual problems and adaptive forgetting factors are
presented in Section 1.2.2. The chapter is concluded in Section 1.2.3.
1.2.1 Visual Servoing Background
A sensory system that substantially improves autonomous system capabilities as well
as increases the versatility of robotic applications is visual-sensing. Using visual
information to control a robot end-eﬀector position in relation to a target is referred
to as visual servoing. the algorithm has signiﬁcantly played an important role in a
wide range of robotic applications such as grasping, teleoperation, missile tracking,
or aircraft landing.
In 1979 Hill and Park [33] introduced the ﬁrst taxonomy of visual servoing. In
1980,WeissandSanderson[79]organizedvisualservosystemsintofourclassiﬁcations:
dynamic look-and-move, direct visual servo, positioned-based, and imaged-based vi-
sualservosystems. LaterHutchinsonetal. [36]suggesttwocategories, position-based
and image-based visual servo control. They also distinguish between two degrees of
system observability: endpoint open-loop (EOL) and endpoint closed-loop (ECL) sys-
tems. An EOL system only observes the target while an ECL system observes both
the target and robot end-eﬀector.
2
Position-basedvisualservoing(PBVS)usesvisualinformationinconjunctionwith
a knowledge of the robot kinematic model, the geometric target model, and the
camera model to minimize error between the current and the desired robot position
in the task space. The desired robot position is obtained by extracting, interpreting,
and transforming image features to approximate target position in relation with the
camera pose. The system is remarkably sensitive to a precise knowledge of kinematic
robot model and accurate camera calibration. Examples of PBVS developments are
presented in [14, 80]. Because it requires robot and camera models, this scheme does
not serve the purpose of the research objective.
When the error between the robot end-eﬀector and target position is directly
described in terms of image feature parameters, this type of visual servo control is
known as image-based visual servo system (IBVS). This scheme servos a robot end-
eﬀector such that the image error is minimized without requiring a spatial robot pose
estimation and is more robust to robot or camera calibration errors. When a robot
kinematic model is available, errors mostly occur in the computation of the image Ja-
cobian or interaction matrix - a map between the robot joint onto the camera space
space. This scenario requires camera calibration to determine intrinsic and extrinsic
camera parameters. Intrinsic parameters include focal length, radial distortion com-
ponents, pixel sampling components, etc. Extrinsic parameters describe the position
and orientation of the camera with respect to a global coordinate frame or an arbi-
trary coordinate frame depending on the system conﬁguration. Two common camera
conﬁgurations used in visual servo control are a ﬁxed-camera system known as an
eye-to-hand camera system, and an eye-in-hand system where a camera is attached
to the robot end-eﬀector.
3
1.2.2 Literature Review of Uncalibrated Visual Servoing
The objective of this research is to develop a model-free visual-guided control that
eﬀectively tracks a moving target for large residual problems. Uncalibrated visual
servoing control does not require a priori knowledge of camera and robot models.
Hosoda and Asada [34, 35] and Jagersand et al. [37] demonstrate the Jacobian
estimation using the Broyden rank-one method to servo a robot end-eﬀector for static
target tracking. Piepmeier et al. [57] demonstrate a dynamic quasi-Newton approach
in which the dynamic Broyden’s method with an exponentially weighted (by forget-
ting factor λ) recursive least square (RLS) scheme is introduced. It estimates the
composite Jacobian which combines the camera image Jacobian and the robot kine-
matic Jacobian to track a moving target tracking with a stationary camera. In [59]
the algorithm is extended to an eye-in-hand system where a camera is attached to
an end-eﬀector for a moving target tracking. Simulation and experimental results
verify stable and convergent tracking for moving targets with both stationary and
eye-in-hand cameras. The details of these algorithms are reviewed in Chapter 3.
Piepmeier et al. [57, 59] use quasi-Gauss-Newton based algorithms, which assume
zero- or small-residuals so the residual S is neglected in the Hessian approximation.
k
Consequently, for large residual problems the algorithms either slowly converge or
diverge. To overcome this problem, Fu et al. [25] use a secant method to approximate
ˆ ˆ
the residual S . The estimation of residual S is done by an algorithm proposed by
k k
Dennis et al. [19, 17] for solving nonlinear least squares problems. This algorithm
uses a trust region method for guaranteeing global convergence, and the dynamic
Jacobian estimation method presented in [57]. Even though simulation results show
improved convergence with desirable accuracy, this algorithm is only applied to a
stationary target.
Kim et al. [40, 38, 39] also propose an uncalibrated visual servoing for large resid-
ual problems. Similar to [25], the full Newton’s method and the secant approximation
4
areusedtocalculaterobotjointanglesforstatictargettracking. However, themathe-
ˆ
matical formula for updating the residual S is diﬀerent. Although simulation results
k
show improvement of the system control, the trajectories of the robot end-eﬀector
exhibit signiﬁcant oscillation along target tracking. Due to the close relation to the
work presented in this thesis the details of these algorithms [25, 39] are presented in
Chapter 4.
The secant model is also used in Bonkovi´c et al. [5] with the so-called population-
based generalization method to update the composite Jacobian. The major disad-
vantage of this method is considerably more computational cost and complexity of
the Jacobian calculation compared to the Broyden method. The trade oﬀ between
Jacobian estimation complexity and system performance improvement has not been
investigated.
Miura et al. [46] present an uncalibrated visual servoing method using a modiﬁed
simplex method and a Newton-like method to optimally move the robot to a desired
position. One of the major problems is that an incorrect Jacobian estimation some-
times occurs due to the large motion of the robot between the vertices of the simplex.
A variety of diﬀerent methodologies are proposed to approximate the Jacobian. For
examples, a depth-independent Jacobian proposed by Wang et al. [78] is used to
estimate linearized camera parameters on-line. Qian and Su [63] propose to use the
Kalman ﬁltering technique to approximate the Jacobian components. Similarly, Lv
and Huang [44] introduce using a Kalman ﬁlter to estimate the Jacobian elements
while using a fuzzy logic adaptive controller to improve stability. These algorithms
do not study uncalibrated visual control for large residual problems.
Bilen et al. [4] present a experimental comparison of calibrated and uncalibrated
image based visual servoing in a microsystem application that requires high precision.
Based on their experiment, the calibrated method performed better than the uncal-
ibrated visual servoing with better settling time, accuracy, and precision if timing is
5
thetaskpriority. However, therewasnotlargediﬀerencebetweenthetwoapproaches.
Uncalibrated visual servoing gives more ﬂexibility control to the task since camera
calibration is tedious and error prone.
Ozgur and Unel [52] present an experimental validation of the dynamic quasi-
Gauss-Newton algorithm presented in [57, 59] for micropositioning and trajectory
following tasks. The dynamic quasi-Gauss-Newton algorithm is shown to position
and trajectory track in a robust manner with micron accuracies. An alternative
controller called Optimal controller [64] is used to evaluate the performance of the
dynamic quasi-Gauss-Newton algorithm with its dynamic Gauss-Newton controller.
thedynamicGauss-Newtoncontrolleryieldsbetterresultsinpositioningandfollowing
a square trajectory while the Optimal controller performs better for circular and
sinusoidal trajectory tracking. It is mentioned that if time is crucial for the task
that the calibrated visual control might be a better choice. This work conﬁrms the
feasibility of the algorithms proposed in [57, 59], even for microassembly tasks where
a high level of precision is required.
To improve convergence and precision, this research develops a methodology for
adaptively selecting an appropriate forgetting factor λ at each iteration. Due to the
k
limited number of RLS algorithms presented for uncalibrated visual servoing, there
exists little literature about an adaptive λ . One important work is presented in
k
[29] where an adaptive recursive least square (ARLS) algorithm is presented. The λ
k
valueiscalculatedbysolvinganoptimizationproblem. Thenitisusedinthedynamic
quasi-Gauss-Newton method [59] for uncalibrated visual servoing control. The ARLS
shows a smaller mean-square error as compared to using a ﬁxed forgetting factor.
More details of this work are presented in Chapter 5. Since the variable forgetting
factor(VFF)algorithmshavebeenwidelystudiedinRLSadaptiveﬁlteringtoimprove
the performance of the RLS algorithm, various VFF studies are reviewed in Section
5.3.
6
1.2.3 Summary
Although several uncalibrated visual servo system have been developed with various
methods to approximate the Jacobian, only a few studies focus on large residual
problems which are restricted to only tracking a stationary target. The dynamic
quasi-Gauss-Newton algorithms in [57, 59] are shown to be the most robust and
stable algorithms in both simulations and experiments in a number of studies and the
research presented in this thesis uses them as a foundation.
It should be noted that this section gives an overview of the previous work related
to uncalibrated visual servoing for large residual problems and more detail literature
references are given as individual topics are discussed in each chapter.
1.3 Contribution
This work develops a novel uncalibrated visual guided control with an adaptive for-
getting factor for large residual problems. To solve a diﬃculty encountered in the
dynamic quasi-Gauss-Newton algorithms [57, 59] for handling large residual prob-
lems, the full quasi-Newton method is investigated. The full quasi-Newton is argued
to oﬀer superior tracking due to the inclusion of the residual S term in the Hessian
k
approximation. Despite the fact that the residual S is usually diﬃcult to determine
k
analytically, variousalgorithmstoapproximatetheHessianmatrixareproposed. One
solutionistoapproximatethewholeHessianusingthedynamic BFGS (DBFGS) algo-
ˆ
rithm. ThesecondsolutionistoapproximatetheresidualS usingthemodiﬁed BFGS
k
(MBFGS) or dynamic full Newton method with BFGS (DFN-BFGS) algorithms, by
assuming that the Jacobian J is already available.
k
To ensure fast convergence and stability yet attain robust tracking performance, a
switching algorithm that alternates between the proposed full quasi-Newton method
7
and the dynamic quasi-Gauss-Newton method for a given switching criterion is in-
troduced and has lead to the switching DBFGS-DB, the MBFGS-DB, and the DFN-
BFGS-DB algorithms.
To further improve the performance of the switching algorithms, an adaptive for-
getting factor λ called the dynamic adaptive forgetting factor (DAFF) is introduced.
k
This is a heuristic method to adapt λ with respect to the image error norm (cid:107)f (cid:107). Al-
k k
though there are several existing variable forgetting factor (VFF) schemes presented
in the RLS adaptive ﬁltering literature, these algorithms are complex and do not
appear eﬀective for uncalibrated visual servoing.
Simulation results show that the switching MBFGS-DB algorithm with the DAFF
method consistently yields the best results for a variety of robot degrees-of-freedom,
camera conﬁgurations, trajectories, and target speeds. The DAFF algorithm is shown
to signiﬁcantly oﬀer the best overall tracking accuracy and convergence, especially in
the presence of noise. The number of cameras and the camera arrangement are shown
to signiﬁcantly aﬀect noise compensation. These results validate the eﬀectiveness of
the switching MBFGS-DB algorithm with the DAFF scheme to improve tracking
performance for large residual problems in the presence of noise.
1.4 Organization
The thesis is organized in the following manner:
Chapter 1 discusses the motivation of the research, the contributions, the uncal-
ibrated visual servoing literature review, and outlines the study.
Chapter 2 provides the theoretical background of Newton and quasi-Newton
methods for solving unconstrained optimization problems.
Chapter 3 reviews the dynamic quasi-Gauss-Newton algorithms either with or
without partitioning for Broyden’s method developed by Piepmeier et al. [57, 59].
8
Since this work is built on the dynamic quasi-Gauss-Newton algorithms, the mathe-
matical background of these algorithms are fundamental to the study in this thesis.
A few major diﬃculties of these algorithms, which have lead to derivation of the
proposed algorithms, are discussed.
Chapter 4 develops the DBFGS, DFN-BFGS, MBFGS methods for residual ap-
proximationforlargeresidualproblems. Thederivationofthesealgorithmsareanalo-
goustotheBFGSalgorithm. Twodistinctmethodsforsolvinglargeresidualproblems
are presented: i) approximation of the whole Hessian matrix, ii) approximation of the
residual term included in the Hessian matrix with an assumption that linear portion
JTJ is available. The DBFGS algorithm is an approximation of the whole Hessian
matrix, while the DFN-BFGS and the MBFGS algorithms are the approximations of
the residual terms. Unlike the Hessian approximation using the BFGS method, the
DBFGS algorithm includes the dynamic term ∂fh into the secant equation used for
∂t t
the Hessian approximation. The DFN-BFGS method, on the other hand, is derived
by directly employing the BFGS algorithm to approximate the residual term, while
the MBFGS method is derived by modifying a denominator of a term in the DFN-
BFGS formula. Its signiﬁcance is due to the fact that curvature information of the
objective function is enforced into the residual approximation. A convergence proof is
given for the MBFGS method. A hybrid between the dynamic quasi-Gauss-Newton
method and the (full) Newton method, with the approximated residual using a pro-
posed residual approximation method is developed. A discussion of the alternative
hybrid methods and a heuristic selection of the switching criterion are presented.
Chapter 5 presents the derivation of the DAFF algorithm. This method is in-
spired by observing λ behavior that is in analogy to a step response of a ﬁrst-order
k
diﬀerential system. Various VFF algorithms that are widely studied in RLS adap-
tive ﬁltering areas are also reviewed. The eﬀect of the DAFF method on improving
tracking performance is compared with various VFF algorithms in Chapter 6.
9
Chapter 6 simulates the proposed switching algorithms, the switching MBFGS-
DB, DBFGS-DB, and DFN-BFGS-DB algorithms on three and six DOF robot with
various camera conﬁgurations and trajectories. Comparison is made between the
proposed switching algorithms and dynamic quasi-Newton methods with or without
partitioning for Broyden’s method. Overall, the switching MBFGS-DB algorithm
provides the best results in terms of RMS errors, t , and stability for a higher DOF
s
robot, a complex trajectory, or a fast target speed. The diﬀerent VFF algorithms
presented in Chapter 5 are investigated to validate tracking improvement. Compar-
ison is made between the DAFF method, various existing VFF algorithms, and a
ﬁxed forgetting factor that are implemented in the switching MBFGS algorithms for
large residual problems with the presence of noise. The switching MBFGS with the
DAFF algorithm consistently yields the fastest convergence and the smallest RMS
tracking for a variety of trajectories and target speeds. The eﬀects of multiple cam-
eras and the camera arrangement on noise compensation are investigated. The eﬀect
of the Levenberg-Marquardt algorithm (LMA) implemented with various switching
algorithms and the adaptive forgetting factor schemes are presented. The LMA only
marginally improves tracking performance for all tested cases.
Chapter 7 summarizes the results and discusses possible future research.
In summary, this work derives and simulates uncalibrated visual servoing with
an adaptive forgetting scheme for large residual problems. This work is the ﬁrst
successfully developed visual guided control to handle large residual problems for
uncalibrated moving target tracking.
10
CHAPTER II
NEWTON’S METHOD AND QUASI-NEWTON
METHODS BACKGROUND
In this study visual servoing is formulated as a nonlinear optimization problem and
algorithms such as Newton’s method and quasi-Newton methods are typically used
for ﬁnding a solution. The theoretical background of Newton’s method for scalar
and multi-variable functions is presented in Section 2.1. Quasi-Newton methods in
which the derivative of a function is approximated rather than analytically calculated
is discussed in Section 2.2. Section 2.3 presents the modiﬁed Newton’s method in
which a Hessian matrix is adjusted to guarantee positive deﬁniteness. Section 2.4 and
Section 2.5 provide the basic fundamentals of line search and trust-region methods
respectively. The summary of this chapter is presented in Section 2.6.
2.1 Newton’s Method
2.1.1 Newton’s Method for a One-Variable Scalar Function
In numerical analysis, Newton’s method or the Newton-Raphson method is often used
to solve for the root of a function. For a one-variable scalar function f (x) where
x ∈ R Newton’s method can be derived from Taylor series approximation of f (x)
around x ,
k
f (x) = f (x )+f(cid:48)(x )(x−x )+... (2.1)
k k k
11
Dropping the higher order term yields an aﬃne model1 m (x) that retains the con-
k
stant and linear portion of f (x),
m (x) = f (x )+f(cid:48)(x )(x−x ) (2.2)
k k k k
Figure 2.1 shows a geometrical representation of an aﬃne model in which f (x) is
approximated about x .
k
Figure 2.1: A geometrical representation of an aﬃne model.
Newton’s method is obtained by setting (2.2) to zero,
0 = f (x )+f(cid:48)(x )(x−x ) (2.3)
k k k
where f(cid:48)(x) is the ﬁrst-order derivative of f (x). Solving (2.3) for x = x gives
k+1
f (x )
k
x = x − (2.4)
k+1 k f(cid:48)(x )
k
This is called Newton’s method for successively ﬁnding a root of a function f(x).
Newton’s method quickly converges to a solution if the initial value (x ) is relatively
0
close to the solution (x∗). The process is repeated until a suﬃciently-accurate root is
found.
1an aﬃne model corresponds to an aﬃne subspace through (x,F (x)) in which a line does not
necessary pass through the origin (a line must pass the origin in a linear subspace)
12
If f (x) is a linear function, Newton’s method locates the solution in one iteration.
For nonlinear problems, this process generates a sequence of points that is expected
to converge to a solution. For a complex nonlinear function, a quadratic model is
often used to approximate f (x).
Newton’s method is also well-known to be used for ﬁnding local minima or local
maxima of an objective fucntion F (x), which is known as optimization problem. In
this case, an aﬃne model M (x) of F (x) is
k
M (x) = F (x )+F(cid:48)(x )(x−x ) (2.5)
k k k k
Newton’s method is obtained by solving for the root of F(cid:48)(x) = 0 as
0 = F(cid:48)(x )+F(cid:48)(cid:48)(x )(x−x ) (2.6)
k k k
Solving (2.6) yields
F(cid:48)(x )
k
x = x − (2.7)
k+1 k F(cid:48)(cid:48)(x )
k
where F(cid:48)(cid:48)(x) is the second-order derivative of the objective function F (x).
2.1.2 Newton’s Method for a Multiple-Variable Function
Consider a nonlinear function f : Rm → Rn that is continuously diﬀerentiable at
x ∈ Rm. A solution x∗ where f(x∗) = 0 can be found using the Newton’s method
similar to (2.4). An aﬃne model m that approximates f(x) about x is
k k
∼
f(x) = m (x) = f (x )+J (x−x ) (2.8)
k k k k
(cid:12)
where J ∈ Rm×n is the Jacobian matrix, J = ∂f(cid:12)(cid:12) . A successive x can be
k k k+1
∂x(cid:12)
x
k
approximated from the current x by solving
k
m (x ) = f (x )+J (x −x ) = 0
k k+1 k k k+1 k
to give
x = x −J−1f (x ) (2.9)
k+1 k k k
13
This is known as Newton’s method for solving a set of m equations.
For unconstrained minimization problems, consider a scalar objective function
F(x) : Rm → R where m > 1 is continuously diﬀerentiable at x ∈ Rm and a solution
x∗ is a locally/globally minima of the objective function F(x). The derivation of
Newton’s method for m-dimensional minimization problems is similar to the one-
dimensional function in Section 2.1.1. The Taylor series of F (x) can be expressed
as
F (x) = F (x )+∇F (x−x )+O(x2) (2.10)
k k k
where ∇F is the ﬁrst partial derivatives of F(x) with respect to the m variables and
k
is called the gradient of F at x . Dropping the higher order term O(x2) in (2.10)
k
yields an aﬃne model M (x) of F(x) around x ,
k k
∼
F(x) = M (x) = F (x )+∇F (x−x ) (2.11)
k k k k
The minimum of F (x) can be found by solving
∂M (x)
k
0 =
∂x
= ∇F +H (x−x ) (2.12)
k k k
(cid:12)
∂2F(x)(cid:12)
whereH = ∇2F = (cid:12) istheHessian matrixofF(x)atx . TheHessianH is
k k ∂x2 (cid:12) k
x
k
an n by n matrix and is always symmetric if F(x) is twice continuously diﬀerentiable
[19]. Solving (2.12) at x = x gives
k+1
(x −x ) = −H−1∇F (2.13)
k+1 k k k
x = x −H−1∇F (2.14)
k+1 k k k
Equation (2.14) is known as Newton’s method for solving a minimization problem
where −H−1∇F is called the Newton direction. Figure 2.2 shows a pseudo-code
k k
algorithm utilizing Newton’s method to solve unconstrained minimization problems.
A spacial case of unconstrained optimization is a nonlinear least-squares problem.
It is well-known in data ﬁtting applications in which the best ﬁt is obtained by
14
Pseudo-code: Newton’s method
Given: F : Rm → R ; x ∈ Rm ; H ∈ Rn×n ; ∇F ∈ Rm×1
Initialize (cid:15), x , and x
0 1
Calculate F(x )
0
for k = 1,... do
Calculate F(x ), ∇F , and H
k k k
Find x∗ ∈ Rm for which F(x) is minimized
(cid:12) (cid:12)
(cid:12)F(xk)−F(xk−1)(cid:12)
if (cid:12) (cid:12) < (cid:15) then
(cid:12) F(x ) (cid:12)
k−1
break // Convergence criterion met.
end if
x = x −H−1∇F // (k +1)th solution
k+1 k k k
end for
Figure 2.2: Pseudo-code of Newton’s method for solving unconstrained optimization
problems
minimizing the sum of squared error between a measured value and the approximated
value from a model. Since visual servoing problems seek the robot joint angles θ that
minimize the error between the robot and target features, they are cast as nonlinear
least-squares problems. For this reason, Newton’s and other related methods used
for solving nonlinear least-squares problems in general are focused on in this chapter,
then nonlinear least-squares visual servoing problems are discussed in Chapter 3.
TheobjectivefunctionF(x)tobeminimizedisafunctionofsquarederrorfunction
f(x),
1
Minimize F(x) = fT(x)f(x) (2.15)
x∈Rm 2
where the error function f(x) : Rm → Rn is continuously diﬀerentiable at x ∈ Rm. A
15
solution of (2.15) can be found by Newton’s method given in (2.14). In this context,
∇F = JTf(x) (2.16)
k k
H = JTJ +S (2.17)
k k k k
where
∂f
k
J =
k
∂x
∂JT
S = k f
k k
∂x
Substituting them in (2.14) gives
x = x −(cid:0)JTJ +S (cid:1)−1JTf(x ) (2.18)
k+1 k k k k k k
S is the second-order term of the Hessian H and is known as the residual. Often
k k
the residual S is computationally expensive so it is assumed to be zero and can be
neglected if x is in the neighborhood of a solution x∗ (see Chapter 3). Then (2.18)
0
reduces to
x = x −(cid:0)JTJ (cid:1)−1JTf(x ) (2.19)
k+1 k k k k k
and is known as the Gauss-Newton method.
Newton’s method is a powerful technique that gives quadratic convergence if ∇F
k
atthesolutionx∗ isnonzero. However, theinitialvaluex isrequiredtobesuﬃciently
0
near the true solution x∗ to guarantee convergence so Newton’s method is often
referredasalocaltechnique. Further,themethodwillfailiftheHessianH issingular.
k
The other main drawback is due to the requirement of the analytical derivatives of
F (x). When the derivatives are diﬃcult to analytically obtain or unavailable and
an approximation of either ∇F or the Hessian H is used instead, then Newton’s
k k
method is called a quasi-Newton method.
Without a loss of generality, the capital letter described an objective function
F (x) that is a scalar function while the lower case letter described a function such as
f (x) where x ∈ Rn.
16
2.2 Quasi-Newton Methods
In many applications a function F (x) cannot be analytically expressed so its deriv-
atives are not available and must be approximated. Approximation schemes such as
a ﬁnite-diﬀerence approximation or a secant approach can be used to estimate the
Jacobian J and the Hessian matrix H . The secant approximation of J is typically
k k k
simpler than the secant approximation of the Hessian matrix H . The most popular
k
secant method used for the Jacobian estimation is known as Broyden’s method and
is discussed in Section 2.2.1. Secant methods used for estimating H are reviewed in
k
Section 2.2.2.
2.2.1 Broyden’s method
Recall that the objective function F(x) for a nonlinear least-squares problem is de-
scribed as
1
F(x) = fT(x)f(x) [2.15]
2
A solution of (2.15) can be found by Newton’s method given in (2.18) or in (2.19). If
(cid:12)
∂f(cid:12) ˆ
a analytical J = (cid:12) is not available, the approximate J can be determined using
k k
∂x(cid:12)
x
k
a secant technique.
The aﬃne model of the error function f (x) is deﬁned as in (2.8),
m (x) = f (x )+J (x−x ) (2.8)
k k k k
The model m is required to exactly represent the function at x = x as
k k−1
m (x ) = f (x ) (2.20)
k k−1 k−1
Substituting (2.20) into (2.8) at x = x yields
k−1
f (x ) = f (x )+J (x −x ) (2.21)
k−1 k k k−1 k
17
and rearranging gives,
J (x −x ) = f (x )−f (x ) (2.22)
k k k−1 k k−1
Equation (2.22) is known as the secant equation. Substituting h = x −x and
k−1 k k−1
y = f (x )−f (x ) gives
k−1 k k−1
J h = y (2.23)
k k−1 k−1
One of the most successful approaches to approximate J was introduced by C.
k
Broyden in 1965 [19]. Broyden suggested using a rank-one update to estimate Ja-
ˆ ˆ
cobian J from the previous Jacobian J by taking a solution of secant equation
k k−1
(2.23) that gives the minimal changes between the current and previous Jacobians,
(cid:13) (cid:13)
i.e., minimizing the Frobenius norm of the Jacobian diﬀerence (cid:13)Jˆ (x)−Jˆ (x)(cid:13)
(cid:13) k k−1 (cid:13)
F
as
(cid:16) (cid:17)
y −Jˆ h hT
k−1 k−1 k−1 k−1
ˆ ˆ
J = J + (2.24)
k k−1 hT h
k−1 k−1
which is called Broyden’s method. Dennis and Schnabel [19] give a proof to show that
ˆ
the quasi-Newton method using the Jacobian J from Broyden’s method converges to
k
x∗ superlinearly if the initial x is close to x∗ and the initial Jacobian Jˆ(x ) is close
0 0
to the actual initial Jacobian J (x ) if Jˆ(x∗) is nonsingular.
0
2.2.2 Hessian Approximation
When the Hessian matrix H requires a signiﬁcant calculation cost, a secant method
similar to the one presented in Section 2.2.1 can be used to eﬃciently approximate H.
Hessian approximation methods, including the Davidon-Fletcher-Powell (DFP) up-
date,thePSB(Powell-symmetric-Broyden)update,andtheBroyden-Fletch-Goldfarb-
Shanno (BFGS) method, are brieﬂy discussed in this section.
Secant techniques similar to those used for Jacobian estimation can be applied to
theHessianapproximation. ThesecantequationfortheHessianmatrixH ,analogous
k
18
to equation (2.23), is
H h = g (2.25)
k k−1 k−1
whereg = ∇F (x )−∇F (x ). SimilartotheJacobianapproximation,Broyden’s
k−1 k k−1
method can be used to approximate H as
k
(cid:16) (cid:17)
g −Hˆ h hT
k−1 k−1 k−1 k−1
ˆ ˆ
H = H + (2.26)
k k−1 hT h
k−1 k−1
ˆ ˆ
where H is an approximation of H . However, H obtained from (2.26) is not
k k k
ˆ
guaranteed to be symmetric even if H is symmetric. Since the Hessian matrix is
k
always symmetric and often positive deﬁnite, the Powell-symmetric-Broyden (PSB)
update can be used to ensure symmetric
(cid:16) (cid:17) (cid:16) (cid:17)T
g −Hˆ h hT +h g −Hˆ h
k−1 k−1 k−1 k−1 k−1 k−1 k−1 k−1
ˆ ˆ
H = H +
k k−1 hT h
k−1 k−1
(cid:16) (cid:17)
hT g −Hˆ h h hT
k−1 k−1 k−1 k−1 k−1 k−1
− (2.27)
(cid:0)hT h (cid:1)2
k−1 k−1
The details of this method is presented in [19]. Even though this method converges
ˆ
superlinearly [7], a H update using the PSB method may not be positive deﬁnite.
k+1
The solution of Newton’s method or a quasi-Newton method gives a critical point
that can be either a minima, a maxima, or a saddle point. In order to ensure that
this critical point is a minima, it requires the Hessian H to be positive deﬁnite. For
k
this reason, Hessian approximations that preserve positive deﬁniteness such as BFGS
and DFP are more popular methods in solving nonlinear optimization.
The BFGS method [19] is
g gT Hˆ h hT Hˆ
Hˆ = Hˆ + k−1 k−1 − k−1 k−1 k−1 k−1 (2.28)
k k−1 gT h hT Hˆ h
k−1 k−1 k−1 k−1 k−1
The DFP method [19] is
(cid:16) (cid:17) (cid:16) (cid:17)T
g −Hˆ h gT +g g −Hˆ h
k−1 k−1 k−1 k−1 k−1 k−1 k−1 k−1
ˆ ˆ
H = H +
k k−1 gT h
k−1 k−1
(cid:16) (cid:17)
hT g −Hˆ g gT
k−1 k−1 k−1 k−1 k−1
− (2.29)
(cid:0)gT h (cid:1)2
k−1 k−1
19
The main advantages of the BFGS and DFP methods is due to the resulting
ˆ ˆ
positive-deﬁnite H approximation if the initial Hessian H is positive deﬁnite. The
k 0
DFP method sometimes generates a numerically singular Hessian estimation so the
BFGS method is preferred over the DFP method.
ˆ
RegardlessofthemethodforapproximatingtheHessianH, thequasi-Newtonstep
h is similar to the Newton step (2.13) and a update x is similar to the equation
k k+1
ˆ
(2.14) (only that now the Hessian H is substituted with H ) as
k k
h = −Hˆ−1∇F (2.30)
k k k
or
x = x −Hˆ−1∇F (2.31)
k+1 k k k
where h = x − x . The iteration quadratically converges to a minimum if the
k k+1 k
starting value x is suﬃciently close to the solution x∗. If the Hessian matrix Hˆ is
0 k
positive deﬁnite, the Newton direction −Hˆ−1∇F (x ) is guaranteed to be a descent
k k
direction, i.e., x yields a decreasing value of the objective function F(x) such that
k+1
ˆ
F (x +h ) < F (x ). In practice, the Hessian matrix H is not necessarily positive
k k k k
deﬁnite at a point far from a minimum so the approximated model may not have a
ˆ
minimum. As a result, a modiﬁcation suggested to assure the positiveness of H is
k
discussed in Section 2.3.
2.3 Damped Hessian
A critical point obtained from Newton’s method or a quasi-Newton method is guar-
ˆ
anteed a minima only if the Hessian matrix H is positive deﬁnite. If the Hessian H
k k
ˆ
or H is not positive, some useful modiﬁcations are suggested in literature such as
k
[19, 42, 45, 50] by including an additional term such as
H = H +µ I (2.32)
d,k k k
20
where I is the identity matrix and µ is a scalar multiplier that is sometimes referred
k
ˆ
as a damping parameter. If H is safely positive deﬁnite then µ = 0 . Otherwise,
k k
µ > 0 is selected to be suﬃciently large so H is guaranteed to be positive deﬁnite.
k d,k
The modiﬁed Hessian is sometimes called the damped Hessian and is used in a quasi-
Newton method as
h = −H−1∇f (x ) (2.33)
k d,k k
or
x = x −H−1∇f (x ) (2.34)
k+1 k d,k k
This is called the modiﬁed Newton’s method in [19].
The damped Hessian was ﬁrst introduced by Levenberg [42] for nonlinear least-
squares curve ﬁtting applications. He proposed the damped Gauss-Newton method
as
(cid:0) (cid:1)
JTJ +µ I h = −JTf (x ) (2.35)
k k k k k k
This is similar to the Gauss-Newton method in (2.19) except that now the Hessian
H = JTJ is replaced by H = JTJ +µ I where µ is updated at each iteration.
k k k d,k k k k k
The update is based on the rate of objective function reduction. For example, if
the reduction rate of the objective function is fast, µ is decreased. On the other
k
hand, if the reduction rate is inadequate, µ may be increased. Varying µ in fact
k
interpolates the resulting solution between the Gauss-Newton algorithm (smaller µ)
and gradient descent method (larger µ). The greatest disadvantage of this method
(cid:0) (cid:1)
occurs when µ becomes too large and inverting JTJ +µI is not meaningful. As a
result, Marquardt [45] proposed
(cid:0) (cid:0) (cid:1)(cid:1)
JTJ +µ diag JTJ h = −JTf (x ) (2.36)
k k k k k k k k
in which the identity matrix I is substituted with the diagonal of JTJ and the equa-
k k
tion (2.36) is known as the Levenberg-Marquardt algorithm (LMA). The brief details
21
of the LMA implementation developed by [47] to calculate the damping parameter µ
and a diagonal matrix, instead of using JTJ as in (2.36), are discussed in Chapter 6.
Marquardt [45] proved that the solution of minimizing the damped model (using
the damped Hessian in (2.32)) is the same as of minimizing the original model in
a restricted region. This region is referred to the trust region where a ball, for ex-
ample, centered about the current iteration is created using a local model (usually a
quadratic model) and is restricted to values which accurately model the function. A
new iteration is limited to remain inside this a trusted region. This is an important
concept in nonlinear optimization problems. In fact, there are two strategies that
can be implemented with Newton’s method and quasi-Newton methods to improve
stability and convergence namely line search and trust region methods.
2.4 Line Search
In the line search technique a direction p is ﬁrst determined and then a search along
k
this direction from the current x is performed so that the next iteration yields a
k
lower objective function value,
F (x ) < F (x ) (2.37)
k+1 k
The objective of line search algorithm is to ﬁnd a step length α along p by solving
k
one-dimensional minimization subproblem,
minimize F(x +αp ) (2.38)
k k
α>0
A method that provides an exact solution of (2.38) is called an exact line search.
On the other hand, if a solution of (2.38) is loosely estimated, i.e., a calculation of
α yields a suﬃcient reduction in F(x +αp ) so that it is approximately close to a
k k
minima, the method is called an inexact line search. An exact line search is usually
expensive and unnecessary so an inexact line search is more practical.
22
The direction p that has been considered up to this point is the Newton direction
k
or a quasi-Newton direction. For simplicity let s ≡ H−1∇F is the Newton direction
k k k
and sˆ ≡ Hˆ−1∇F is a quasi-Newton direction. The direction s or sˆ does not
k k k k k
always yield a descent direction so F(x +αs ) may not reduce. These directions are
k k
ˆ
only guaranteed to be descent directions if H or H is positive deﬁnite. Therefore,
k k
ˆ
H or H is always assumed to be positive deﬁnite when implemented with a line
k k
search method in this study. This requirement further emphasizes the advantage of
the Hessian modiﬁcation in Section 2.3. The next iterate x using a quasi-Newton
k+1
direction, for example, is
x = x +α sˆ (2.39)
k+1 k k k
The other common search direction p is the steepest-descent direction where p =
k k
∇F
k
− . This direction is the steepest downhill direction from the current iteration
(cid:107)∇F (cid:107)
k 2
x . Without a loss of generality, p is used for the steepest-descent direction, while s
k k k
represents the Newton direction for the remainder of this study. An exact line search
example from [1] is shown in Figure 2.3 where a search along the steepest-descent
direction starts from x then converges to the solution x∗ after a few iterations.
0
One advantage of the steepest descent method is that it only requires ∇F and
k
not the Hessian H . However, in general the steepest descent method is not recom-
k
mended due to its slower convergence compared to Newton’s method or quasi-Newton
methods. Moreover, this method is scale variance of x, while the Newton direction
is not [19]. Since the steepest-descent method is less preferable, this section only
focuses on Newton’s method or a quasi-Newton method with an inexact line search
algorithm.
Even though x satisﬁes the simple condition in (2.37), there is no assurance
k+1
that x will converge to a solution. As a result, the inequality conditions known as
k+1
the Wolfe conditions are often recommended with inexact line search algorithms [50],
1. F (x +α s ) ≤ F (x )+c α sT∇F
k k k k 1 k k k
23
Figure 2.3: An example of an exact line search [1] starting from x to reach the
0
solution x∗ along the steepest-descent direction at each iteration.
2. sT∇F (x +α s ) ≥ c sT∇F
k k k k 2 k k
where 0 < c < c < 1. It is typically recommended to select c to be small and c
1 2 1 2
to be much larger. For example, Nocedal and Wright [50] recommend c = 10−4 and
1
c = 0.9 for the Newton or a quasi-Newton method. The ﬁrst condition is known as
2
the Armijo rule and imposes a suﬃcient reduction in F(x). The second condition is
known as the curvature condition and enforces a suﬃcient reduction of the slope of
F(x) for the step length α .
k
The search proceeds along a quasi-Newton direction sˆ until (2.37) is acheived.
k
If α = 1, the quasi-Newton step becomes the full quasi-Newton step which is usu-
ally recommended whenever (2.37) is satisﬁed [19]. If x + α sˆ is not acceptable
k k k
then α will be reduced until a desired value is found; this strategy is called back-
k
tracking method. Common methods such as bisection, the golden section search, and
polynomial/cubic methods are used to reduce the step length α.
Since a backtracking strategy prevents small steps, the curvature condition is
24
Pseudo-code: Backtracking line search method with the Armijo rule
Given: F : Rm → R ; x ∈ Rm ; α,ρ ∈ R; ∇F ∈ Rn×1 ; c ∈ (0, 1); 0 < l < u < 1
1 2
Initialize (cid:15), x , and x
0 1
for k = 1,... do
Determine a descent direction s
k
Start with α = 1
k
while F (x +α s ) ≤ F (x )+c α sT∇F do
k k k k 1 k k k
α = ρα // for some ρ ∈ [l,u]
k k
ˆ
ρ = line search(h ) // Determine the line search gain
k
end while
x = x +α s // (k +1)th solution
k+1 k k k
end for
Figure 2.4: Pseudo-code for backtracking line search with Newton’s method
typically not necessary in practice. The pseudo-code summary of backtracking line-
search algorithm with only the Armijo rule is illustrated in Figure 2.4. Then pseudo-
code is used to summarize a quasi-Newton method using BFGS to approximate the
Hessian matrix with the backtracking line-search algorithm in Figure 2.5.
When the full quasi-Newton step does not satisfy condition (2.37), it might indi-
cate that the model does not properly reﬂect the actual function in a neighborhood
around the current x . Since line search algorithms only continually search along the
k
quasi-Newton direction which is obtained from a ‘not-so-good’ model in this case,
other searching methods known as trust-region methods may oﬀer more suitable ap-
proaches.
25
Pseudo-code: The BFGS algorithm with backtracking line-search technique
Given: F : Rm → R ; x ∈ Rm ; H ∈ Rn×n ; ∇F ∈ Rn×1 ; s ∈ Rn×1; α,ρ ∈ R;
c ∈ (0, 1); 0 < l < u < 1
1 2
Initialize (cid:15), x , and x
0 1
for k = 1,... do
Calculate F(x ), ∇F , and H
k k k
(cid:12) (cid:12)
(cid:12)F(xk)−F(xk−1)(cid:12)
if (cid:12) (cid:12) < (cid:15) then
(cid:12) F(x ) (cid:12)
k−1
break // Convergence criterion met.
end if
ˆ
Calculate H
k
ˆ
h = x −x
k−1 k k−1
g = ∇F −∇F
k−1 k k−1
g gT Hˆ h hT Hˆ
Hˆ = Hˆ + k−1 k−1 − k−1 k−1 k−1 k−1
k k−1 gT h hT Hˆ h
k−1 k−1 k−1 k−1 k−1
sˆ = −Hˆ−1∇F // Determine the BFGS step
k k k
Start with α = 1
k
while F (x +α sˆ ) ≤ F (x )+c α sˆT∇F do
k k k k 1 k k k
α = ρα // for some ρ ∈ [l,u]
k k
ˆ
ρ = line search(h ) // Determine the line search gain
k
end while
x = x +α sˆ // (k +1)th solution
k+1 k k k
end for
Figure 2.5: Pseudo-code for the BFGS algorithm with the backtracking line-search
method
26
2.5 Trust-Region Methods
Trust region methods share some duality to line search approaches. While line search
methods seek for an appropriate step size α along a known searching direction, trust
region algorithms ﬁrst calculate a proper size of the trust region and then choose
an appropriate step direction. A trust region is referred to a restricted neighborhood
aroundthecurrentiterationx ofwhichalocalmodeladequatelyrepresentsafunction
k
F(x). Foranonlinearfunction,aquadraticmodelM isamoreappropriatemodel
quad,k
than an aﬃne model and it can be described as
1
F(x) ∼= M (x) = F (x )+∇FT(x−x )+ (x−x )TH (x−x ) (2.40)
quad,k k k k 2 k k k
This local quadratic model is minimized to solve the following constrained opti-
mization subproblem at each iteration,
1
minimize M (x +h ) = F (x )+∇FTh + hTH h (2.41)
quad,k k k k k k 2 k k k
subject to (cid:107)h (cid:107) ≤ δ (2.42)
k 2 k
where (cid:107)·(cid:107) refers to the Euclidean norm and δ > 0 determines the size of a trust-
2 k
region. Typically a trust region is determined as a sphere centered at the current x
k
with a radius δ in which the update x is limited to only stay inside this region
k k+1
where the current model is trusted as shown in Figure 2.6. This is an example of a
trust region of a function F(x ,x ) = −10x2+10x2+4sin(x x )−2x +x4 [76] where
1 2 1 2 1 2 1 1
the red dot is the center of the trust region at x = (0.7,−3.3) and the successive
k
x is limited to be within the radius δ from the current x .
k+1 k k
The solution of (2.41) is restricted by the size of the trust region δ . If this
k
solution is undesirable, the trust-region radius will be decreased which in fact alters
the direction of the resulting solution. This behavior is the major diﬀerence between
a trust region method and a line search algorithm in which a search direction is never
changed.
27
Figure 2.6: An example of a trust region [76] with a radius δ centered at x where
k k
the next update x is restricted to be inside the trust region.
k+1
The concept of trust region methods, though this terminology was not used orig-
inally, was introduced in [42]. Recall the damped Gauss-Newton method (2.35),
(cid:0) (cid:1)
JTJ +µ I h = −JTf (x ) [2.35]
k k k k k k
An improved version of (2.35) in [45] leads to the LMA as brieﬂy described in Section
2.3. However, the LMA heuristically adjusts the damping parameter µ according to
k
how F(x) is eﬀectively reduced in the previous step and no clear connection between
(2.35) with trust region methods was presented in the original work. The connection
between the LMA with trust region methods was ﬁrmly established in [47]. Although
various strategies of calculating µ and a diagonal matrix instead of the identity
k
matrix in (2.35) are introduced, this study uses the algorithm presented in [47] as a
basis. The detailed history of trust region methods can be found in [9].
In [19] it is shown that the solution of (2.41) is the same as the modiﬁed quadratic
model M in which the Hessian H in (2.40) is now substituted by the damped
mod,k k
28
˜
Hessian H (2.32) as
k
1
F(x) ∼= M (x) = F (x )+∇FT(x−x )+ (x−x )TH (x−x ) (2.43)
mod,k k k k 2 k d,k k
when h is constrained by
k
(cid:107)h (cid:107) ≤ δ
k 2 k
So (2.41) is solved by
h (µ ) = −(Hˆ +µ I)−1JTf = −H−1JTf (2.44)
k k k k k k d,k k k
Ifµ = 0and(cid:107)h (0)(cid:107) ≤ δ ,then(2.44)isaquasi-Gauss-Newtonsteph = −Hˆ−1JTf .
k k k k k k k
Otherwise, (2.44) is the solution of (2.41) for any unique µ > 0 such that (cid:107)h (µ )(cid:107) =
k k k
δ [50].
k
(cid:13) (cid:13)
If δ < (cid:13)H−1JTf (cid:13) then µ is needed to be solved for such that
k d,k k k 2 k
(cid:107)h (µ )(cid:107) = (cid:13)(cid:13)H−1JTf (cid:13)(cid:13) ∼= δ (2.45)
k k 2 d,k k k 2 k
which is a nonlinear equation in µ . Various methods are reviewed in [19, 50] to
k
approximate µ in this situation.
k
The direction of (2.44) is altered away from a quasi-Newton direction to the
steepest descent direction if the damping parameter µ is increased [43]. It is also
k
mentioned in [19] that varying the value of µ allows a smooth changing direction
k
of h (µ ) between a quasi-Gauss-Newton direction (when µ = 0) and the steepest-
k k k
descent direction where h (µ ) ∼= − 1 JTf when µ is large.
k k µ k k k
k
∼
Since (2.44) is constrained to satisfy (cid:107)h (µ )(cid:107) = δ , changing the size of trust
k k 2 k
region δ changes the direction of h (µ ). When δ is very small, the direction of
k k k k
h (µ ) is close to the steepest-descent direction. If the current solution x is far from
k k k
the desired solution x∗, the algorithm uses a steepest-descent method in which it
typically guarantees convergence but the rate of convergence is only linear. However,
if the current x is close to x∗, the trust region algorithm behaves like a quasi-
k
Gauss-Newton method; taking an advantage of a quadratic convergence rate of a
quasi-Newton method.
29
The eﬀects of changing µ to the change of δ are summarized in [77] as
• Decreasing µ results in increasing δ so the direction of the resultant solution
moves closer to the Newton direction
• Increasing µ results in decreasing δ so the direction of the resultant solution
moves closer to the steepest descending direction
The size of trust region δ can be controlled based on how well the predicted
k
model ﬁts the actual function. In general, the size of trust region increases if the
current model well predicts the function and decreases if the model poorly estimates
the function. The most common strategy is to compare the actual reduction of the
function with a predicted value obtained from its quadratic model M as in [23].
quad,k
The ratio ρ between the actual and predicted reduction of the function at current
k
iteration can be described as
F (x +s )−F (x )
k k k
ρ = (2.46)
k
M (x +s )−M (x )
quad,k k k quad,k k
If ρ is close to unity, the current model well approximates the actual reduction of the
k
function. Hence, the trust region can be expanded for the next iteration. If ρ > 0
k
but not close to unity, the trust-region radius maintains its same size. Otherwise,
the trust region should be contracted since the current model poorly agrees with the
actual function reduction. Examples of updating the trust-region radius can be found
in [50] and [23].
2.6 Summary
In an unconstrained minimization problem a minima of an objective function F (x)
where x ∈ Rm is determined by using Newton’s method:
x = x −H−1∇F [2.14]
k+1 k k k
(cid:12)
∂2F(x)(cid:12)
where H = ∇2F = (cid:12) is the Hessian matrix of F(x) at x .
k k ∂x2 (cid:12) k
x
k
30
For a nonlinear least-squares problem, a spacial case of unconstrained optimiza-
tion, the objective function F(x) is deﬁned as
1
Minimize F(x) = fT(x)f(x) [2.15]
x∈Rm 2
where f(x) is an error function. A local minima of F(x) can be calculated using
Newton’s method in (2.14) where
H = JTJ +S
k k k k
∇F = JTf(x )
k k k
Substituting these terms into (2.14) gives
x = x −(cid:0)JTJ +S (cid:1)−1JTf(x ) [2.18]
k+1 k k k k k k
If the Jacobian J is not analytically available, it can be approximated using
k
Broyden’s method,
(cid:16) (cid:17)
y −Jˆ h hT
k−1 k−1 k−1 k−1
ˆ ˆ
J = J + [2.24]
k k−1 hT h
k−1 k−1
In the case that the Hessian H expensively requires computation cost, a variety
k
of Hessian approximations can be used. For example, the BFGS method,
g gT Hˆ h hT Hˆ
Hˆ = Hˆ + k−1 k−1 − k−1 k−1 k−1 k−1 [2.28]
k k−1 gT h hT Hˆ h
k−1 k−1 k−1 k−1 k−1
ˆ
As a result, Newton’s method using either the approximate Jacobian J , the
k
ˆ
approximate Hessian H , or a combination of both yields a quasi-Newton method,
k
x = x −Hˆ−1∇F [2.31]
k+1 k k k
If S in the Hessian H is neglected, (2.18) becomes the Gauss-Newton method,
k k
x = x −(cid:0)JTJ (cid:1)−1JTf(x ) [2.19]
k+1 k k k k k
31
Newton’s method or a quasi-Newton method is guaranteed to converge to a min-
ima only if H is positive deﬁnite. In a case that H is not positive deﬁnite, a damped
k k
Hessian H is often applied as
d,k
x = x −H−1∇f (x ) [2.34]
k+1 k d,k k
where
H = H +µ I [2.32]
d,k k k
The identity matrix I is sometimes replaced by a diagonal matrix D . An algorithm
k
such as the LM algorithm is used to update the damping parameter µ and a diagonal
k
matrix D so that H is positive deﬁnite.
k d,k
To improve stability and convergence of Newton’s method or a quasi-Newton
method, line searches and trust region methods are recommended. Line search meth-
ods seek for a proper step length along a known searching direction while trust region
methods ﬁrst calculate a size of the trust region and then select an appropriate di-
rection.
32
CHAPTER III
DYNAMIC BROYDEN’S METHOD WITH
RECURSIVE-LEAST-SQUARES (RLS) UPDATE
The control of mechanical systems such as a robotic manipulator often relies on an
accurate nominal model. However as systems grow in size and complexity so do the
models. Further, inclusion of eﬀects that is more diﬃcult to successfully model such
as friction, backlash, and viscoelasticity may be necessary to increase response and
ﬁdelity for control. As systems rely less on modeling they usually compensate for it
by increased sensing. Visual sensing is critical for many biological systems but its use
in robotic applications is still relatively limited. One of the reasons is that the vision
systemstypicallyrequirecalibrationandfrequentlythiscalibrationsigniﬁcantlydrifts
duringoperationduetooperatingandenvironmentalfactors. Thischapterreviewsan
uncalibrated visual servoing algorithm using a robot manipulator to track a moving
target without an a priori model of either the robot or the camera. The algorithm is
introduced by Piepmeier et al. [57, 59, 60] who develop a dynamic Broyden’s method
to estimate a compound Jacobian, the transformation from robot joint velocities to
the target velocities on the camera plane. It is used to generate robot joint commands
via a dynamic quasi-Newton method that solves a nonlinear least squares problem.
An overview of visual servoing schemes is presented in Section 3.1. Some earlier
studies implementing quasi-Newton methods for image-based visual servoing prob-
lems related to this development are summarized in Section 3.2. Section 3.3 reviews
fundamental development of the dynamic Broyden’s method using recursive least-
squares estimation (DBM-RLS) for a stationary camera. Then the study is extended
33
to the dynamic Gauss-Newton algorithm with partitioned Broyden’s method (DGN-
PBM) where a camera is attached to a robot end-eﬀector. A few major limitations
of these algorithms are discussed in Section 3.4. Then the chapter is summarized in
Section 3.5.
3.1 Overview
In robotic applications visual servoing is an algorithm in which a robotic manipulator
canbecontrolledto trackatarget usingvisual informationfromone ormorecameras.
As a target and a robotic manipulator are viewed and an error between them is
determined, the robotic system is controlled to reach the target in the direction that
minimizes the error. In image-based visual servoing (IBVS) systems the error is
formed on the camera image planes, usually between selected feature points on the
target and the robotic end-eﬀector (EE). For properly selected features, making the
errors in the image plane vanish also make errors in the task space vanish.
The velocity relationship (and similarly the small motion relationship) between
robot EE feature points y in the image plane and the robot joint angles θ is
˙
y˙ = Jθ (3.1)
where
J = J J
camera robot
˙
is the composite Jacobian that directly maps the robot joint rate θ into the image
feature velocity y˙. Individually, the robot Jacobian maps joint rates into an EE twist
˙
T = J θ, and the camera Jacobian transforms the EE twist into the image velocity
robot
y˙ = J T of the selected feature points. The dimensions of J are determined by
camera k
the number of image feature coordinates and the number of actuators.
An error f is formed from the target image feature vector y∗ and the EE image
feature vector y in units of pixels and can be determined directly from the camera
34
image. For example, if a robot is tracking a moving target using a stationary camera
system the error f is given as
f (θ,t) = y(θ)−y∗(t) (3.2)
where the EE image feature vector y is only a function of the joint angles θ and the
target image feature vector y∗ is only a function of time t. The form of the error f
is dependent on the camera system setup. Two diﬀerent vision system settings are
discussed in the context of a single camera though it immediately extends to multiple
cameras.
1. Eye-to-hand system - the camera system is stationary and views both the end-
eﬀector and the target as in Figure 3.1. There are two distinct situations:
(a) Static target - the robot is controlled to reach a static location y∗ and the
error is f (θ) = y(θ)−y∗
(b) Moving target - the robot is controlled to track a moving target y∗(t) and
the error is f (θ,t) = y(θ)−y∗(t)
Figure 3.1: For an eye-to-hand system the camera is remote from the robot and the
target.
35
2. Eye-in-hand system - the camera system is attached to the EE. The EE image
featuresareseenasstationarypoints, withoneoftencoincidingwiththecamera
optical axis at the origin of the image frame, as in Figure 3.2. The two distinct
situations are:
(a) Static target - the robot is controlled to reach a static location y∗ and the
error is f (θ) = y −y∗(θ)
(b) Moving target - the robot is controlled to track a moving target y∗(t) and
the error is f (θ,t) = y −y∗(θ,t)
Figure 3.2: For an eye-in-hand system the camera is attached to the robot EE.
For the remainder of the development the most general case is assumed f ≡ f(θ,t)
since it applies to the special cases with small modiﬁcations.
The goal of visual servo control is to determine the joint angles θ that minimize
the error f at any given time t. This problem can be described as a nonlinear least
squares optimization problem where the objective function F(θ,t) to be minimized
is a function of the squared error between the EE image features y and the desired
target image features y∗ as seen on the image plane
1
F(θ,t) = fT (θ,t)f (θ,t) (3.3)
2
and is homogeneous in the units of (pixels)2.
36
The solution of (3.3) can be found using either Newton’s method (if an analytic
derivative of f is available) or using quasi-Newton methods (if an analytic derivative
of f is not available). Because a priori knowledge of the robot kinematic model
and the camera model is assumed unknown the derivatives of f are not analytically
available and quasi-Newton methods are applicable. A novel uncalibrated visual
servoing that utilizes a dynamic quasi-Newton method with the dynamic Broyden’s
method to track a moving target is introduced by Piepmeier et al. [57, 59, 60]. This
model independent visual servoing provides robust steady-state tracking behavior
when signiﬁcant changes in the robot kinematic model or in the orientation of the
camera occur. The theoretical fundamentals of the algorithm is brieﬂy reviewed in
Section 3.3.
3.2 Previous Work in Nonlinear Visual Servoing Optimiza-
tion
Theearlierdevelopmentsofuncalibratedvisualservoingalgorithmsutilizingnonlinear
least-square optimization with quasi-Newton methods are done by Hosoda and Asada
[34] and Jagersand, Fuentes, and Nelson [37]. Hosoda and Asada [34] introduced
a nonlinear least squares method with exponential weighting matrix to recursively
estimate the Jacobian Jˆ at the kth iteration as
k
(cid:16) (cid:17)
∆f −Jˆ h hTP
k−1 θ θ k−1
ˆ ˆ
J = J + (3.4)
k k−1 λ+hTP h
θ k−1 θ
1 (cid:18) P h hTP (cid:19)
P = P − k−1 θ θ k−1
k λ k−1 λ+hTP h
θ k−1 θ
where ∆f = f − f , h = θ − θ , P is a full rank weighting matrix, and
k k−1 θ k k−1
ˆ
0 < λ ≤ 1 is called the forgetting factor. If λ = 1, then J is estimated by averaging
k
all past information. If λ < 1, old data is deweighted by increasing powers of λ
so the calculation relies more on recent data and “forgets” older data. As a rough
approximation the eﬀective number of weighted iterations used in the calculation is
37
given by
1
n ≈
memory
1−λ
so when λ = 1 the memory is inﬁnite. Though equation (3.4) is only applicable for
the time-invariant Jacobian J(θ), slow motion control can be achieved by tuning the
forgetting factor λ. The control algorithm they introduced (for the kth iteration) is
(cid:16) (cid:17)
θ˙ = Jˆ+y˙∗ + I −JˆTJˆ k −KJˆTf (3.5)
where k is a gain vector and K is a positive deﬁnite gain matrix which must be
selected. They also use the same Jacobian estimation (3.4) in conjunction with a
known robot Jacobian in [35] for an adaptive hybrid control algorithm. The hybrid
algorithm combines vision and force sensory information to calculate robot joint rate
˙
θ as
θ˙ = J−1 (u +u )
robot force img
where u is the force feedback output and u is the control output based on the
force img
image information that is calculated by
u = Jˆ+ (y˙∗ −Kf)
img img
where Jˆ+ is the pseudo-inverse of the Jacobian estimated by (3.4). Successful sim-
img
ulation and experimental results for a stationary camera are provided in [34] but the
case of a moving target is not addressed, except when it can be approximated as
stationary.
Jagersand et al. [37] propose using Broyden’s method to estimate the Jacobian
for tracking a static target scenario using a stationary camera system from
(cid:16) (cid:17)
∆f −Jˆh hT
k θ θ
ˆ ˆ
J = J + (3.6)
k+1 k hTh
θ θ
∆f = f −f
k k−1
h = θ −θ
θ k k−1
38
ˆ
This estimated J is then used in a quasi-Newton method to solve for the next step
k
h . In order to ensure the convergence of this algorithm, a trust region method is
θ
used to automatically adapt the maximum allowable step length α. The general idea
of this trust-region method is similar to the trust-region concept presented in Chapter
2. The step size δ is a solution of the constrained equation,
k
(cid:13) (cid:13)2
Minimize(cid:13)y −y∗ +Jˆδ (cid:13) (3.7)
(cid:13) k k k(cid:13)
(cid:107)δ (cid:107)<α
k k
The restriction (cid:107)δ (cid:107) < α ensures that the robot never moves outside a region where
k k
the current model approximation cannot be trusted. The successive value of α is
k+1
(cid:107)∆y (cid:107)
measured
adjusted depending on the model agreement d = as
k ˆ
(cid:107)Jδ(cid:107)

12αk if dk ≤ dlower


αk+1 = αk if dlower < dk ≤ dupper





max(2(cid:107)δ(cid:107),α) if dk > dupper
Extensive experiments are performed with three, six, and twelve DOF robots
to verify that this estimation can improve stability and convergence of the robot
controllers.
These proposed quasi-Newton methods only address static target tracking using
a stationary camera. Consequently, tracking convergence for a moving target is not
guaranteed unless the appropriate derivatives are included [60]. As a result, Piep-
ˆ
meier et al. [57, 59, 60] propose a dynamic Broyden’s method to update J as part
k
of a quasi-Newton method for moving target tracking. They show that the algorithm
converges asymptotically. The contributions of this novel method over the aforemen-
tioned algorithms are summarized as
1. Development of an uncalibrated visual servoing algorithm for moving target
tracking that applies to camera systems that arbitrarily move and includes the
eye-to-hand and eye-in-hand cases
39
2. Derivation of the dynamic Broyden’s update with a recursive least-squares tech-
nique as a part of the dynamic quasi-Newton’s method that solve nonlinear
visual servoing problems
3.3 Dynamic Quasi-Newton Method via Recursive Least
Squares Estimation
3.3.1 Theoretical Fundamental
For moving-target tracking problems, the objective function F(θ,t) in (3.3) is gener-
ally a function of the robot joint angles θ and time t which are assumed independent.
This section ﬁrst considers the eye-to-hand case where the camera is stationary, then
extend it to the eye-in-hand case with a moving camera.
The Newton method is derived by expanding (3.3) in a Taylor series about (θ,t),
F(θ+h ,t+h ) = F(θ,t)+F h +F h +O(h2) (3.8)
θ t θ θ t t θ
where F and F are partial derivatives of F with respect to θ and t while h and h
θ t θ t
are increments of θ and t respectively. At a given sampling period h , the function F
t
is minimized by solving
∂F(θ+h ,t+h )
θ t
0 =
∂θ
0 = F +F h +F h +O(h2) (3.9)
θ θθ θ θt t θ
Dropping the higher order term O(h2) and substituting in h = θ − θ yields
θ θ k+1 k
Newton’s method,
θ = θ −(F )−1(F +F h ) (3.10)
k+1 k θθ θ θt t
Equation (3.10) is referred as the dynamic Newton’s method [57] due to the inclusion
of the term F h .
θt t
40
Expanding (3.10) in terms of f(θ,t) gives
F = JTf (3.11a)
θ k k
F = JTJ +S (3.11b)
θθ k k k
∂f
F = JT k (3.11c)
θt k ∂t
∂JT
S = k f (3.11d)
k k
∂θ
∂f
k
J = (3.11e)
k
∂θ
So (3.10) becomes,
∂f
θ = θ −(JTJ +S )−1JT(f + kh ) (3.12)
k+1 k k k k k k ∂t t
S is a second-order term in the second derivative of F and is known as the residual.
k
There is a signiﬁcant distinction between zero-residual, small-residual, and large-
residual cases for nonlinear least-squares problems [19]. For example, in data-ﬁtting
application if x∗ ﬁts the model m(x∗) of the measured data exactly then S(x∗) is
zero and this problem is called the zero-residual problem. However, in nonlinear
optimization the residual S can be signiﬁcant and often analytically unavailable or
computationally expensive. So nonlinear least-squares algorithms typically assume
zero- or small-residual condition. In those cases S is ignored so (3.12) reduces to
(cid:18) (cid:19)
∂f
θ = θ −(cid:0)JTJ (cid:1)−1JT f + kh (3.13)
k+1 k k k k k ∂t t
which is known as the Gauss-Newton method. Note that (cid:0)JTJ (cid:1)−1JT is the overcon-
k k k
strained pseudo-inverse of the full column rank matrix J . Since the range space of
k
J is homogeneous in the units of pixels there are no problems of units noninvariance.
k
In order to eliminate the need for an analytical model to calculate J , [57, 59,
k
60] propose an explicit time dependent algorithm that modiﬁes Broyden’s rank one
method in (3.6),
(cid:18) (cid:19)
∂f (t)
∆f −Jˆ h − k h hT
k−1 θ ∂t t θ
ˆ ˆ
J = J + (3.14)
k k−1 hTh
θ θ
41
Pseudo-code: Dynamic Broyden’s Method with RLS estimation (DBM-RLS)
Given: f : Rn → Rm ; θ ,θ ∈ Rn ; Jˆ ∈ Rm×n,P ∈ Rn×n,λ ∈ (0,1)
0 1 0 0
Initialize: J , θ , θ , and P
0 0 1 0
for k = 1,... do
∆f = f −f
k k−1
h = θ −θ
θ k k−1
(cid:18) (cid:19)
∂f (t)
Jˆ = Jˆ +(cid:0)λ+hTP h (cid:1)−1 ∆f −Jˆ h − k h hTP
k k−1 θ k−1 θ k−1 θ ∂t t θ k−1
1 (cid:16) (cid:17)
P = P −(cid:0)λ+hTP h (cid:1)−1(cid:0)P h hTP (cid:1)
k λ k−1 θ k−1 θ k−1 θ θ k−1
(cid:18) (cid:19)
(cid:16) (cid:17)−1 ∂f (t)
θ = θ − JˆTJˆ JˆT f + k h
k+1 k k k k k ∂t t
end for
Figure 3.3: A pseudo-code for the DBM-RLS
This method is called the dynamic Broyden’s method and using it in (3.13) yields the
dynamic quasi Gauss-Newton method,
(cid:18) (cid:19)
(cid:16) (cid:17)−1 ∂f
θ = θ − JˆTJˆ JˆT f + kh (3.15)
k+1 k k k k k ∂t t
The signiﬁcant improvement of this method over the previous work is due to the
∂f (t)
k
dynamic time-dependent term h in equations (3.14) and (3.15). In eﬀect f
t k
∂t
∂f (t)
k
is substituted by f + h and that oﬀers a better estimation of the next error
k t
∂t
term f which is used to compute the update θ .
k+1 k+1
The Broyden estimator only uses the most recent data but this can be adapted for
exponentially deweighted data in a manner similar to (3.4) with a forgetting factor
λ. The result is the dynamic Broyden’s method using recursive least square (RLS)
estimation or DBM-RLS and is summarized by the pseudo-code in Figure 3.3.
42
The proof showing convergence in the neighborhood of a moving target is pre-
sented in [60]. Furthermore, it is also shown that the standard Newton’s method is
not guaranteed convergence for a moving target.
∂f
k
To implement the algorithm it is necessary to approximate for which the
∂t
eye-to-hand system it can be determined as a simple ﬁrst order diﬀerence,
∂fk = ∂(y(θ)−y∗(t))(cid:12)(cid:12)(cid:12) = −∂y∗(t)(cid:12)(cid:12)(cid:12) ∼= −yk∗ −yk∗−1 (3.16)
∂t ∂t (cid:12) ∂t (cid:12) h
k k t
For the eye-in-hand system a similar simple estimation is not possible because the
target features vector y∗ is now a function of both the robot joint angles θ and time
t. y∗ may change due to either robot movement, target motion, or a combination of
both. Instead [59] introduces the dynamic Gauss-Newton algorithm with partitioned
∂f
ˆ k
Broyden’s method or DGN-PBM to simultaneously estimate J and . This is
k
∂t
˜
summarized by the pseudo-code in Figure 3.4 where the partitioned Jacobian J =
k
(cid:20) (cid:21)
(cid:16) (cid:17) (cid:16) (cid:17) ∂f
Jˆ fˆ has fˆ is approximating k.
k t t ∂t
k k
3.3.2 Simulation and Experimental Results
3.3.2.1 The DBM-RLS Algorithm
The dynamic Broyden’s method and the DBM-RLS algorithm are evaluated by sim-
ulations using the one, two, and six DOF robotic systems with a stationary camera
system in [57]. From these results the dynamic Broyden’s method demonstrates su-
perior tracking performance over the static Broyden’s method, but its tracking ability
is degraded with the presence of noise. However, the DBM-RLS algorithm demon-
strates a signiﬁcant improvement to provide stable and convergent tracking even in
the presence of system noise.
The stability and convergence of the DBM-RLS algorithm is also analyzed exper-
imentally using a two-DOF planar robot to track a moving target in [57]. Two types
of target trajectories are performed: a synthetic and a real target trajectory. For
synthetic target tracking a computer generates an elliptical target path in the image
43
Pseudo-code: Dynamic Gauss-Newton Algorithm with Partitioned Broyden’s
Method (DGN-PBM)
(cid:16) (cid:17)
Given: f : Rn → Rm ; θ ,θ ∈ Rn ; Jˆ ∈ Rm×n; fˆ ∈ Rm×1; P ∈ Rn+1×n+1 ;
0 1 0 t 0
0
λ ∈ (0,1)
(cid:16) (cid:17)
ˆ
Initialize: J , θ , θ , f , and P
0 0 1 t 0
0
for k = 1,... do
∆f = f −f
k k−1
h = θ −θ
θ k k−1
h = t −t
t k k−1
(cid:20) (cid:21)
(θ −θ )
h˜ = k k−1
(t −t )
k k−1
(cid:104) (cid:16) (cid:17) (cid:105)
J˜ = Jˆ fˆ
k−1 k−1 t
k−1
(cid:16) (cid:17)−1(cid:16) (cid:17)
J˜ = J˜ + λ+h˜TP˜ h˜ ∆f −J˜ h˜ h˜TP˜
k k−1 k−1 k−1 k−1
(cid:18) (cid:19)
1 (cid:16) (cid:17)−1(cid:16) (cid:17)
P˜ = P˜ − λ+h˜TP˜ h˜ P˜ h˜h˜TP˜
k k−1 k−1 k−1 k−1
λ
(cid:18) (cid:19)
(cid:16) (cid:17)−1 ∂f (t)
θ = θ − JˆTJˆ JˆT f + k h
k+1 k k k k k ∂t t
end for
Figure 3.4: A pseudo-code for the DGN-PBM method
plane, while for a real target tracking the target motion is generated by rotating a
arm, attached with a 10 mm white disc at its end, in a circular arc.
Synthetic Target
The results show that the steady-state tracking can be achieved with a variety of
target speeds ranging from 0.05 to 0.25 where h is a sampling period. However its
ht ht t
performance varies with target speeds. The tracking errors exponentially increase as
target speed increases but they are bounded within a relatively small range and the
EE still follows the target motion. Further, increased noise in target motion increases
44
the tracking errors but convergence or stability is not aﬀected in this range of target
speeds.
The performance comparison between the DBM-RLS and the calibrated visual
servoing method is also studied for the same target motion. While the calibrated
method presents some overshoot, the DBM-RLS method produces somewhat better
tracking. Moreover, the DBM-RLS method yields a more robust algorithm when the
camera or the robot model is reconﬁgured. In this case, the calibrated method is
completely degraded and fails to converge after the camera is moved. The DBM-RLS
performance, on the other hand, is not aﬀected by the reconﬁguration and presents
no loss of tracking accuracy.
Actual Target
With the same setup and algorithm used in the synthetic target case, the robot EE
is controlled to follow a 10 mm white disc attached at the end of a arm rotating in
a circular arc. The DBM-RLS method eﬀectively provides a stable and convergent
tracking for a moving target, though its performance is decreased due to presence
of noise in image processing and the imprecise target motion. In addition, eﬀects of
varying the forgetting factor λ is brieﬂy investigated. An optimal value of λ evidently
exists (the detail of this matter is discussed in Section 3.4).
3.3.2.2 The DGN-PBM Algorithm
In [59] the simulation results of the DGN-PBM method using a six DOF robot with
an eye-in-hand camera system are presented. Diﬀerent controllers used to calculate
(cid:16) (cid:17)
ˆ
the updated θ and methods used to approximate the time-dependent f are
k+1 t
k
(cid:16) (cid:17)
ˆ
investigated. Among the combination of controllers and the f approximation,
t
k
the algorithm presented in the pseudo-code in Figure 3.4 yields the best results by
oﬀering the least numbers of trials when the system lost track of the target and the
control becomes unstable.
45
Experimental results implementing the DGN-PBM method into an eye-in-hand,
planar two-DOF robot was presented in [58]. The DGN-PBM method illustrates
stable convergent tracking behavior even though the orientation of the camera or the
kinematic model of the robot is signiﬁcantly changed.
3.3.2.3 Conclusion
From simulation and experimental results these methods robustly provide stable and
convergent tracking with a variety of robot DOF, target motions, and speeds. More-
over, these uncalibrated visual servoing schemes signiﬁcantly improve tolerance to
robot and camera conﬁguration changes. Hence, they are independent from analyt-
ical models, calibration, and parameter tuning and can be eﬃciently applied to any
type of manipulator and camera systems. However, these algorithms present a num-
ber of disadvantages that still needed to be addressed. Section 3.4 discusses some of
these challenges.
3.4 Limitations
Three major challenges existing in the DBM-RLS algorithms either with or without
partitioning for Broyden’s method are discussed in this study:
1. Large initial error for a dynamic target tracking
2. Selection of an optimal forgetting factor λ
3. A singular or ill-conditioned Hessian matrix F = JTJ +S
θθ k k k
3.4.1 Large Initial Error
Eventhoughtheabovealgorithmsexhibitrobustuncalibratedvisualservoingschemes
in both eye-to-hand and eye-in-hand systems, they are limited to only the zero- or
small-residual cases where the Gauss-Newton method is applicable. The initial robot
46
conﬁguration θ is assumed to be in the neighborhood of the target acquisition conﬁg-
0
urationθ∗. ConvergenceisonlyguaranteedifF (θ∗)ispositivedeﬁnite,butgenerally
θθ
it is not. Hao et al. [30] note that the performance of the algorithms substantially
depends on a proper initial estimation of the Jacobian matrix. If the initial choice of
Jacobian diﬀers too greatly from the actual Jacobian, the robot may move erratically
for a few iterations.
With the small-residual condition, the Gauss-Newton method can be expected to
perform well if any of the following conditions hold [49]:
1. The error f is small
2. The function is linear or close to linear
Unfortunately, these assumptions are overly restrictive situations. If the initial
error, or a subsequent error, is large then S = ∂JTf in (3.12) becomes substantial
∂θ
and an estimation of S is necessary. For the visual servoing problem, the residual
error becomes large if the target is signiﬁcantly far from the initial conﬁguration of
the robot or if the target is located outside of the robot workspace. Figure 3.5 shows
an initial large-error simulation result using a six DOF robot with an eye-in-hand
camera similar to one presented in [59] utilizing the DGN-PBM method (excluding
the S approximation). This example demonstrates that the transient tracking trajec-
tory may be uncontrollable before the robot converges to the steady-state tracking
if the S approximation is not properly included. Since the Gauss-Newton method
becomes less eﬀective on large-residual problems, methods that attempt to improve
this problem is investigated in Chapter 5.
3.4.2 Selection of Optimal Forgetting Factor
While a constant value of the forgetting factor λ is utilized in the DBM-RLS and the
DGN-PBM algorithms, the optimal performance of these schemes is dependent on its
selection [57]. Simulation results show that a lower value of λ improves convergence
47
Figure 3.5: A simulation result of a six DOF robot with an eye-in-hand system using
the DGN-PBM method when an initial error is signiﬁcant shown in the task space
view.
time but deteriorates steady-state tracking performance. In contrast, a higher λ in-
duces diﬃculties in acquiring the target, yet steady-state tracking ability is enhanced.
A switching scheme that utilizes a lower λ initially then changes to a higher value
when the image error norm is below a certain criteria demonstrates some improve-
ment in both transient and steady-state tracking. Simulation results using the same
system setup as in the large initial error case show that an inappropriate choice of λ
can cause uncontrollable motion before the robot converges to steady-state tracking
as shown in Figure 3.6. In some complex trajectory tracking this problem leads to
failure in tracking. As a result, an adaptive forgetting factor λ that may lead to a
more robust dynamic quasi-Newton method is discussed in Chapter 6.
48
Figure3.6: Asimulationresultofaneye-in-hand,sixDOFrobotusingtheDGN-PBM
method with a constant λ shown in the task space view.
3.4.3 Ill-conditioned Hessian Matrix
Nonlinear optimization problems sometimes yield an ill-conditioned or, in the worst
ˆ ˆ
case, a singular approximate Hessian matrix H (= F ). Since the quasi-Newton
k θθ
method (3.12) requires the inverse of the Hessian matrix, the ill-conditioning usually
leads to numerical problems that results in slow or no convergence. A scheme such as
the Levenberg-Marquardt algorithm [42] that modiﬁes the Hessian matrix to ensure
positive deﬁniteness may be implemented to overcome this deﬁciency. In addition,
methods are available in [19] guarantee a positive deﬁnite approximate Hessian, even
if the actual Hessian is not positive deﬁnite. Though this introduces nonphysical
artifacts, it may improve eﬀective near singularities. A proper strategy to cope with
this limitation is investigated in Chapter 6.
49
3.5 Summary
The brief reviews of the DBM-RLS algorithms either with or without partitioning
for Broyden’s method (the DBM-RLS and the DGN-PBM algorithms) developed by
Piepmeieretal. [57,59,60]arepresentedinthischapter. Thesemethodsareshownto
be eﬀective for moving target tracking with the eye-to-hand and eye-in-hand camera
conﬁgurations. Dependingonacamerasystemsetup, generallytheerrorvectorf(θ,t)
between the EE image feature y and the desired target image features y∗ as seen on
the image plane can be measured,
f (θ,t) = y(θ)−y∗(t) [3.2]
Avisualservoingproblemiscastasanonlinearleastsquaresoptimizationproblem
wheretheobjectivefunctionF(θ,t)tobeminimizedisthesquarederrorfT (θ,t)f (θ,t),
1
F(θ,t) = fT (θ,t)f (θ,t) [3.3]
2
A solution θ∗ that minimizes (3.3)can be calculatedusing theGauss-Newton method,
(cid:18) (cid:19)
∂f
θ = θ −(cid:0)JTJ (cid:1)−1JT f + kh [3.13]
k+1 k k k k k ∂t t
in which it is assumed that the initial Robot conﬁguration θ is in the neighborhood
1
of the desired robot conﬁguration θ∗. Since a priori knowledge of the robot kinematic
model and the camera model are assumably unknown, i.e., an analytical model to
calculate J is unavailable, the Jacobian J can be recursively estimated using a
k k
dynamic Broyden’s method with the recursive least square method as
(cid:18) (cid:19)
∂f (t)
∆f −Jˆ h − k h hT
k−1 θ ∂t t θ
ˆ ˆ
J = J + [3.14]
k k−1 hTh
θ θ
ˆ
Substituting an approximation of J into (3.13) yields the dynamic quasi Gauss-
k
Newton method,
(cid:18) (cid:19)
(cid:16) (cid:17)−1 ∂f
θ = θ − JˆTJˆ JˆT f + kh [3.15]
k+1 k k k k k ∂t t
50
A signiﬁcant improvement of the DBM-RLS algorithms over the previous work in
∂f (t)
k
[34, 37] is due to the dynamic time-dependent term h in equations (3.14) and
t
∂t
(3.15).
From simulation and experimental results the DBM-RLS algorithms robustly pro-
vide stable and convergent tracking with a variety of robot DOF, target motions,
and speeds. Furthermore, they improve tolerance to robot and camera conﬁguration
changes. However, there exists a number of challenges using these novel uncalibrated
visual servoing algorithms:
1. Large initial error for a dynamic target tracking
2. Selection of an optimal forgetting factor λ
3. A singular or ill-conditioned Hessian matrix F = JTJ +S
θθ k k k
These issues are thoroughly investigated and discussed in Chapter 4, Chapter 5, and
Chapter 6.
51
CHAPTER IV
MODIFIED METHODS FOR THE LARGE-RESIDUAL
VISUAL SERVOING PROBLEM
One of the major disadvantages of the DBM-RLS and the DGN-PBM algorithms is
that they are limited to only the zero- or small-residual cases since the algorithms
exploit the quasi-Gauss-Newton method in which the residual S is neglected. This
chapter introduces the theoretical fundamentals of the nonlinear least-squares visual
control problem for the large-residual case in which the initial robot conﬁguration
θ is not in the neighborhood of the target acquisition conﬁguration θ∗. In this
0
case, S becomes substantial and the inclusion of the residual S can signiﬁcantly
improvetheoverallperformanceofthealgorithms. Duetodiﬃcultiesintheanalytical
computation of the residual S, various methods are used to approximate the residual
S.
This chapter starts with Section 4.1 where a brief summary of the related ter-
minologies and fundamentals for solving large-residual visual servoing problems are
reviewed. Various algorithms used to solve large-residual cases for optimization are
discussed in Section 4.2. Section 4.3 presents previous attempts for solving large-
residual cases in uncalibrated visual servoing applications. Due to the fact that only
static target tracking has appeared in literature, various algorithms are proposed for
solving moving target tracking for large-residual cases and is presented in Section
4.4. In this section a novel algorithm called the modiﬁed BFGS (MBFGS) method
is developed. Then the convergence analysis of the MBFGS algorithm and its con-
vergence rate are discussed in Section 4.5 and Section 4.6 respectively. Section 4.7
discusses a hybrid method known as the switching modiﬁed BFGS-dynamic Broyden
52
or switching MBFGS-DB algorithm which is a combination of the MBFGS algorithm
and the DGN-PBM method. This novel hybrid attains fast convergence with a low-
ered computational cost for solving large-residual visual servoing problems because
it only employs the MBFGS algorithm when the error is greater than a criteria and
switches to the DGN-PBM method otherwise. Lastly the summary of this chapter is
presented in Section 4.8.
4.1 Introduction
In Chapter 3 the visual servoing problem is cast as nonlinear least-squares optimiza-
tion problem seeking the solution of
Minimize F : Rm → R (4.1)
in which F is an objective function deﬁned as
1
F (θ,t) = fT (θ,t)f (θ,t) (4.2)
2
where f : Rm → Rn is an image plane error vector in pixels between the robot EE
feature vector y and the target feature vector y∗.
A solution of the minimization problem (4.2) can be found by the dynamic New-
ton’s method as
θ = θ −(F )−1(F +F h ) (4.3)
k+1 k θθ θ θt t
where F is also known as the Hessian matrix H
θθ k
Expanding (4.3) in terms of f(θ,t) gives
F = JTf (4.4a)
θ k k
F = JTJ +S (4.4b)
θθ k k k
∂f
F = JT k (4.4c)
θt k ∂t
∂JT
S = k f (4.4d)
k k
∂θ
∂f
k
J = (4.4e)
k
∂θ
53
Equation (4.3) becomes,
∂f
θ = θ −(JTJ +S )−1JT(f + kh ) (4.5)
k+1 k k k k k k ∂t t
where S is known as the residual and the Hessian matrix H is
k k
H = JTJ +S (4.6)
k k k k
Substitution into (4.5) yields,
∂f
θ = θ −H−1JT(f + kh ) (4.7)
k+1 k k k k ∂t t
This is known as the full dynamic Newton method due to the inclusion of the residual
S in the Hessian H .
k k
The algorithms presented in Chapter 3 implement a quasi-Gauss-Newton method
in which the residual S is neglected and (4.6) reduces to H = JTJ . These algo-
k k k k
rithms robustly provide stable and convergent tracking if the initial robot conﬁgu-
ration θ is close to the target acquisition conﬁguration θ∗, i.e., the zero- or small-
0
residual case. If the residual S becomes signiﬁcant, the nonlinear least-squares prob-
k
lem (4.1) is called the large-residual problem. Even though the LMA can generally
be used to solve for a solution of the large-residual problem, the rate of convergence
can be unacceptably slow or sometimes fail to converge [67].
Inordertoimprovethisproblemvariousalgorithmsareintroducedtoapproximate
the Hessian H and can be categorized into two classes:
k
ˆ
1. Approximation of the whole Hessian H giving H
k k
ˆ
2. Approximation of only the residual S giving S
k k
4.2 Approximation of the Hessian for Large-Residual Prob-
lems Background
The original algorithms developed for the large-residual problems are introduced for
general nonlinear optimization using Newton’s method or a quasi-Newton method
54
that do not include the dynamic time-dependent term ∂fkh as in (4.7). For such a
∂t t
case (4.7) becomes
θ = θ −H−1JTf (4.8)
k+1 k k k k
The algorithms reviewed in this section are developed using Newton’s method (4.8)
for the large-residual problems in general nonlinear least squares optimization. To
improve uncalibrated visual servoing algorithms (the DBM-RLS and the DGN-PBM
algorithms in Chapter 3) a modiﬁed BFGS method for approximating the residual
S is developed in Section 4.4. In that case the developed algorithm employs the
k
dynamic Newton’s method (4.7) to eﬃciently deal with the error vector f that is a
function of two independent variables, robot joint angles θ and time t.
4.2.1 Approximation of the Whole Hessian
The approximation of the Hessian H (4.6) can be done using secant techniques
k
similar to those in Section 2.2.2 in Chapter 2. In this context, the Hessian H is
k
ˆ
approximated as H such that it satisﬁes
ˆ
H h = g (4.9)
k k−1 k−1
where
h = θ −θ (4.10)
k−1 k k−1
g = ∇F −∇F
k−1 k k−1
= JTf −JT f (4.11)
k k k−1 k−1
ˆ ˆ
Then H can be updated from H using rank 1 and rank 2 Hessian updates. For
k k−1
example, the rank 1 update [67] is
(cid:16) (cid:17)(cid:16) (cid:17)T
ˆ ˆ
g −H h g −H h
k−1 k−1 k−1 k−1 k−1 k−1
ˆ ˆ
H = H + (4.12)
k k−1 (cid:16) (cid:17)T
ˆ
g −H h h
k−1 k−1 k−1 k−1
55
The two well-known rank 2 Hessian approximations are the BFGS method [19],
g gT Hˆ h hT Hˆ
Hˆ = Hˆ + k−1 k−1 − k−1 k−1 k−1 k−1 (4.13)
k k−1 gT h hT Hˆ h
k−1 k−1 k−1 k−1 k−1
and the DFP method [19],
(cid:16) (cid:17) (cid:16) (cid:17)T
g −Hˆ h gT +g g −Hˆ h
k−1 k−1 k−1 k−1 k−1 k−1 k−1 k−1
ˆ ˆ
H = H +
k k−1 gT h
k−1 k−1
(cid:16) (cid:17)T
g −Hˆ h h g gT
k−1 k−1 k−1 k−1 k−1 k−1
− (4.14)
(cid:0)gT h (cid:1)2
k−1 k−1
ˆ
The approximated Hessian H is used in the quasi-Newton method to calculate
k
θ ,
k+1
Hˆ h = −JTf (4.15)
k k k k
where h = θ −θ .
k k+1 k
Nazareth [48] introduces a hybrid method that combines a quasi-Newton method
and the Gauss-Newton method so that the resultant search direction is a weighted
average between the quasi-Newton and the Gauss-Newton directions and is controlled
via a weighting parameter φ as
(cid:104) (cid:105)
φ JTJ +(1−φ )Hˆ h = −JTf (4.16)
k k k k k k k k
ˆ
where H is an approximation of H , and 0 ≤ φ ≤ 1 is adaptively chosen according
k k k
to how well the Gauss-Newton model can be trusted. To examine the Gauss-Newton
method performance [48] compares the actual reduction in the function F value
k−1
with the predicted value from a Gauss-Newton model. This is implemented with the
LMA so (4.16) becomes
(cid:104) (cid:105)
φ JTJ +(1−φ )Hˆ +µ I h = −JTf (4.17)
k k k k k k k k k
ˆ
A strategy for selecting µ is similar to choosing φ . The Hessian H is assumed to
k k k
be positive semi-deﬁnite and Davidon’s optimally conditioned algorithm [13] is used
56
ˆ
for approximating the Hessian H in [48]. As k increases and φ gets close to being
k k
zero, this method yields superlinear convergence (a property of the Gauss-Newton
method). If the initial H is approximated as JTJ with µ = 0, then for linear
0 1 1 1
problems the algorithm converges in one step.
4.2.2 Approximation of the Residual S
ˆ
One disadvantage of approximating the whole Hessian H is that J is already avail-
k k
able either analytically or from approximation using ﬁnite diﬀerences so JTJ , which
k k
ˆ
is often the dominant portion of H in (4.6), is already known. In order to minimize
k
computing costs a number of studies focus on algorithms that only approximate the
residual S . Since S is an n×n symmetric matrix, similar to the Hessian matrix H ,
k k k
an approximation of S can be done using secant techniques similar to the Hessian
k
ˆ ´
H approximation as in Section 4.2.1. As a result, H is used to distinguish this type
k k
ˆ
of the Hessian approximation from the approximation of H in Section 4.2.1. For the
k
ˆ
remainder of this development, H is referred to as an approximation of the whole
k
´
Hessian H , while H is referred to as an approximation of H in which only the
k k k
residual S is approximated,
k
H´ = JTJ +Sˆ (4.18)
k k k k
ˆ
where S is an approximation of the residual S .
k k
ˆ
Although in this study only the approximation of Jacobian J is available, for
k
simplicity of notation presented in this chapter J is used to represent general cases.
k
Methods that adapt the Hessian approximation techniques for estimating S in-
k
cluding the Broyden-Dennis (BD) method [15], the Betts (B) method [3], and the
early version of NL2SOL [16] ([49] referred this method as the DGW method) are
discussed in this section.
Recall the secant equation of the Hessian approximation as
H h = g [4.9]
k k−1 k−1
57
where
h = θ −θ [4.10]
k−1 k k−1
and
g = JTf −JT f [4.11]
k−1 k k k−1 k−1
Substituting H from (4.6) and g from (4.11) into (4.9) gives
k k−1
(cid:0) (cid:1)
JTJ +S h = JTf −JT f (4.19)
k k k k−1 k k k−1 k−1
or more concisely,
S h = γ (4.20)
k k−1 BD,k
where
γ = JTf −JT f −JTJ h (4.21)
BD,k k k k−1 k−1 k k k−1
Equation (4.20) is the secant equation which is similar to (4.9) for the Hessian
approximation. As a result, the residual S approximation can be done by simply
k
ˆ ˆ
substituting S instead of H in the formulas such as in (4.12)-(4.14). Diﬀerences
between the BD method, the B method, and NL2SOL is how γ in (4.20) is
BD,k
deﬁned and what approach is applied to approximate S . The form of γ in (4.21)
k BD,k
is known as the Broyden-Dennis method or the BD method [15]. This approach
ˆ
applies Powell’s symmetric rank 2 update (or the PSB method, see Chapter 2) for S
k
approximation [61].
A slight modiﬁcation of γ was proposed by Betts [3] that leads to
BD,k
γ = JTf −JT f −JT J h (4.22)
B,k k k k−1 k−1 k−1 k−1 k−1
ˆ
in which Betts uses Davidon’s symmetric rank 1 to update S [12].
k
58
Lastly Dennis et al. [16] introduced
γ = JTf −JT f −JT J h (4.23)
DGW,k k k k−1 k k−1 k−1 k−1
ˆ
where S is updated using the Davidon-Fletcher-Powell (DFP) method. Equation
k
(4.23) is used in their nonlinear least-squares code NL2SOL of which the later version
is presented in [17, 20]. The details of this algorithm are discussed in Section 4.3.2.
Dennis et al. [17] tested the various choices for γ ,
k
• The Broyden-Dennis: γ = JTf −JT f −JTJ h
BD,k k k k−1 k−1 k k k−1
• The Betts: γ = JTf −JT f −JT J h
B,k k k k−1 k−1 k−1 k−1 k−1
• The Dennis-Gay-Welsch (NL2SOL): γ = JTf −JT f −JT J h
DGW,k k k k−1 k k−1 k−1 k−1
and concluded that the choice used in NL2SOL gives the best results.
Nazareth [49] tested the B method, the BD method, the early version of NL2SOL
[16], a full quasi-Newton method (DQN), the LMA, and his own hybrid algorithm (N)
(4.17). All methods were implemented with a trust region algorithm so diﬀerences
between these methods are only conﬁned to the diﬀerent ways in approximating the
ˆ
HessianH . Hetestedsixzero-residualandﬁvelarge-residualproblemsandmeasured
k
the numbers of function and Jacobian evaluations for eﬃciency comparison between
these methods.
Nazareth concluded that algorithms B, BD, and NL2SOL perform well in the
large-residual problems, but the DGW method is the clear winner. For the zero-
residual cases the LMA yields the most eﬃcient method except for one function that
the hybrid algorithm (N) did better than the LMA.
Seber and Wild [67] summarize their observations from Nazareth’s results into 3
themes:
1. For zero-residual problems the Hessian approximation using a Gauss-Newton
method with the LMA implementation seems to be best
59
2. For large-residual problems the DGW method appears to be best
3. Better overall performance of these algorithms may be improved through some
forms of hybridization
The other interesting observation from Nazareth’s result is that for a zero-residual
problemwherethesolutionofafunctionisbadlyscaled, NL2SOL(theDGWmethod)
requires less than half the numbers of function and Jacobian evaluations compared to
the LMA or the N method. Although this observation was not mentioned in either
[49] or [67], it may lead to a potential improvement in the case of an ill-conditioned
or badly-scaled Hessian approximation which is further discussed in Chapter 6.
4.2.3 The Gill-Murray Method
The Gill-Murray (GM) method [26] qualitatively diﬀers from the above methods.
This method is motivated from the fact that any vector direction p can be written in
a form p = p +p where p lies in the range space of J and p lies in the null space
1 2 1 k 2
of JT, where rank(J ) = q < n. Similarly, the Newton step h can be expressed as
k k k
h = h +h where h is in the range space of JTJ with dimension q and h
k 1,k 2,k 1,k k k 2,k
is in the null space of JTJ with dimension n − q. As a result, it is believed that
k k
the Gauss-Newton method is deﬁcient because it only includes the component in the
range space of JTJ but excludes the component in the null space of JTJ .
k k k k
In [26] the GM method calculates h as a sum of a set of q eigenvectors T corre-
k 1
sponding to the ﬁrst q largest dominant eigenvalues of JTJ and a set of eigenvalues
k k
for its complementary space T with dimension n − q corresponding to the lesser
2
eigenvalues of JTJ . The parameter q is called the grade and is needed to be selected
k k
to properly determine the size of the dominant and the complementary sets of T and
1
T . The Newton step becomes
2
h = T c˜ +T c˜ (4.24)
C,k 1 1 2 2
60
which is known as the corrected Gauss-Newton step [67]. In this case T c˜ is h and
1 1 1,k
T c˜ is h where c˜ and c˜ are vectors that have dimension q and n−q respectively.
2 2 2,k 1 2
Three alternatives are detailed in [26] for solving (4.24):
1. Explicit second derivatives
2. Finite-diﬀerence approximation
3. Quasi-Newton approximation
The corrected Gauss-Newton step is the sum of a Gauss-Newton step which is
spanned by the q-dimensional eigenvectors in T corresponding to the q largest eigen-
1
values of JTJ and a Newton step which is spanned by the n − q eigenvectors in
k k
T corresponding to the smallest n − q eigenvalues of JTJ . If J has full rank n,
2 k k k
then the corrected step h (4.24) is the Gauss-Newton step. On the contrary, if the
C,k
current corrected step h yields poor progression, then more eigenvalues are moved
C,k
into the lesser eigenvalue set by decreasing q. Thus, the corrected Newton step h
C,k
behaves more like or becomes the Newton step in the case that q = 0. As a result,
the GM method oﬀers an interpolation between the Gauss-Newton step (q = n) and
the Newton step (q = 0) [67].
Nazareth [49] did not include the GM method in his study so no comparative
performance between the DWG method (or NL2SOL) and the GM method has been
studied. However, it is recommended in [67] that a combination between NL2SOL
and the GM method should be empirically developed.
4.3 Review of Large-Residual Visual Servoing Problems
For visual servoing problems, the residual error S is crucial when the target is signif-
k
icantly far from the initial conﬁguration of the robot or the target is located outside
the robot workspace. However, only a few studies have been done for large-residual
cases in visual servoing problems. This section discusses two main studies that have
61
been done by Kim et al. [40, 38, 39] and Fu et al. [25]. For simplicity the original
terminologiesandnotationsareadaptedtobeconsistentwiththosedeﬁnedinSection
4.1.
4.3.1 Kim et al. Studies
Kim and Lee [40] propose an uncalibrated visual servoing algorithm using the full
Newton’s method and the secant approximation to calculate robot joint angles for
the large-residual case. The objective function in this context is slightly diﬀerent
from (4.2) because it is only used for static target tracking with a stationary camera
system. Hence, the objective function F(θ) is
1
F(θ) = fT(θ)f(θ) (4.25)
2
where
f(θ) = y(θ)−y∗ (4.26)
and y∗ is constant. Similar to (4.2) f : Rm → Rn is an error vector between a robot
EE feature vector y and a static target image feature vector y∗ in unit pixels as seen
on the image plane except that now the objective function F is only a function of
robot joint angles θ. As a result, the full Newton’s method for this application does
not use the dynamic time-dependent term ∂fkh and the next robot joint angles can
∂t t
be found using (4.8) as
θ = θ −H−1JTf [4.8]
k+1 k k k k
Kim and Lee [40] applied a secant technique to the residual term S as
k
S h = (J −J )T f (4.27)
k k−1 k k−1 k
where h = θ −θ . The approximation of S is given in [40] as
k−1 k k−1 k
(J −J )T f hT
S = k k−1 k k−1 (4.28)
k hT h
k−1 k−1
62
Then the calculated S is used in (4.8) to solve for the successive robot joint angles
k
θ .
k+1
The method in (4.28) using a secant technique for the residual S update is imple-
k
mented in conjunction with a Jacobian approximation similar to the one presented
in the DBM-RLS algorithm [57]. Since this algorithm is developed for static target
∂f
k
tracking the Jacobian approximation does not include the time-varying term h ,
t
∂t
(cid:16) (cid:17)
Jˆ = Jˆ +(cid:0)λ+hT P h (cid:1)−1 ∆f −Jˆ h hT P (4.29)
k k−1 k−1 k−1 k−1 k−1 k−1 k−1 k−1
1 (cid:16) (cid:17)
P = P −(cid:0)λ+hT P h (cid:1)−1(cid:0)P h hT P (cid:1) (4.30)
k λ k−1 k−1 k−1 k−1 k−1 k−1 k−1 k−1
Both simulation and experimental results are performed in [39] to validate the
performance of the algorithm using the S update in (4.28) with a non-recursive
k
Jacobian update for tracking a moving target with the eye-to-hand conﬁguration.
Experimentsareperformedtovalidatetheeﬃciencyofthisalgorithmagainstamodel-
based visual servoing algorithm. This algorithm reduces the average error norm in
comparison to the model-based visual servoing.
4.3.2 Fu et al. Studies
Fu et al. [25] also use a full Newton’s method with a Jacobian approximation for
solving large-residual visual servoing problems. They develop an uncalibrated visual
servoing algorithm for static target tracking in an eye-to-hand conﬁguration similar
to Kim and Lee’s work [40, 38, 39]. In this context, the objective function F(θ) and
the error vector f(θ) are the same as in (4.25) and in (4.26) respectively.
The full Newton’s method (4.8) is also employed for determining θ ,
k+1
θ = θ −H−1JTf [4.8]
k+1 k k k k
where H = JTJ +S .
k k k k
In this work the recursive Jacobian approximation (4.29) and (4.30) are also uti-
lized for the Jacobian estimation to achieve model-free static target tracking.
63
The three major contributions presented in [25] that diﬀers from Kim and Lee in
[40, 38, 39] are:
1. A diﬀerent method is used to approximate the residual S
k
2. A trust region method is implemented to improve the algorithm stability
3. Diﬀerent camera conﬁgurations are studied to improve the algorithm perfor-
mance
1. The approximation of the residual S
k
In order to approximate the residual S a secant technique used in NL2SOL [17, 20]
k
is employed. First the residual S is re-introduced in a diﬀerent form as
n
(cid:88)
S = f ∇2f
i i
i=1
where ∇2f is a third order tensor. Dennis et al. [17, 20] introduce a secant approxi-
i
mation to the residual S as
k+1
(cid:88)
S h = f (θ )∇2f (θ )h
k+1 k i k+1 i k+1 k
(cid:88)
∼
= f (θ )(∇f (θ )−∇f (θ ))
i k+1 i k+1 i k
Recall that ∇f (θ ) = JT so
i k+1 k+1
S h ∼= JT f −JTf ≡ z∗ (4.31)
k+1 k k+1 k+1 k k+1 k
where h = θ −θ .
k k+1 k
To update S from S and satisfy (4.31), Dennis et al. [17, 20] employ an
k+1 k
algorithm that slightly diﬀers from the DFP method (a very well-known method for
Hessian approximation),
(cid:16) (cid:17) (cid:16) (cid:17)T (cid:16) (cid:17)
z∗ −Sˆ h g T +g z∗ −Sˆ h hT z∗ −Sˆ h g g T
k k k k k k k k k k k k k k
ˆ ˆ
S = S + − (4.32)
k+1 k g Th (g Th )2
k k k k
64
where g = ∇F −∇F = JT f −JTf . The diﬀerence between g and z∗ is
k k+1 k k+1 k+1 k k k k
(cid:0) (cid:1) (cid:0) (cid:1)
g −z∗ = JT f −JTf − JT f −JTf
k k k+1 k+1 k k k+1 k+1 k k+1
= JT (f −f )
k k+1 k
2. Trust region method
Fu et al. [25] embed a trust region method presented in [23] into their algorithm
to guarantee global convergence. In this case the quadratic model q is used as a
k
suborder approximation of the objective function F (θ),
1 1
q = fTf +(cid:0)JTf (cid:1)T (θ−θ )+ (θ−θ )T (cid:0)JTJ +S (cid:1)(θ−θ ) (4.33)
k+1 2 k k k k k 2 k k k k k
The least-squares solution of the objective function F(θ) is now obtained by solving
a subproblem of the following constrained equation,
1 1
min q = fTf +(cid:0)JTf (cid:1)T (θ−θ )+ (θ−θ )T (cid:0)JTJ +S (cid:1)(θ−θ ) (4.34)
k 2 k k k k k 2 k k k k k
such that
(cid:107)θ−θ (cid:107) ≤ δ
k k
where δ determines the size of the trust region.
k
To solve (4.34) they employ the LMA yielding the modiﬁed Newton method,
θ = θ −(cid:0)JTJ +S +α D2(cid:1)−1JTf (4.35)
k+1 k k k k k k k k
where α is the Levenberg-Marquardt parameter or the damping parameter and D
k k
is a diagonal matrix. Both α and D are updated using Mor´e’s approach [47].
k k
The size of the trust region δ is calculated according to how well the model q
k k
approximates the objective function F . To evaluate the performance of the current
k
model q , the ratio r between the actual reduction of the function and the predicted
k
value obtained from the model q is computed. The actual reduction of the objective
k
function is
∆F = F −F (4.36)
k−1 k
65
while, the predicted reduction is
∆q = F −q (4.37)
k k+1
and the ratio r is
∆F
r = (4.38)
∆q
The value of r determines whether the trust region size δ needs to be adjusted. The
k
closer r is to unity, the better the approximation of F using the current model q .
k k
Fu et al. follows Fletcher’s conditions [23] for updating δ ,
k


0.5(cid:107)Dkhk(cid:107)2 if r ≤ 0.25



δk+1 = 2(cid:107)Dkhk(cid:107)2 if r ≥ 0.75





(cid:107)Dkhk(cid:107)2 if otherwise
3. Eﬀects of camera conﬁguration in improving precision tracking
Two stationary cameras are used in [25] and camera arrangements are studied to
improve precision in robot motion control. Two cases of camera conﬁgurations are
discussed: 1) the two cameras views (optical axes) are nearly parallel and, 2) the
two cameras are arranged such that the optical axes are perpendicular to each other.
Whenthecamerasarearrangedasincase1), bothcamerasmaybecomeinsensitiveto
thetargetmotionparalleltotheopticalaxes. Incontrast,thesecondcasesigniﬁcantly
improves upon this problem.
A summary of the required steps implementing the Fu et al. algorithm [25] is
shown in the pseudo-code in Figure 4.1.
Simulations using a spatial RRR robot to track a static target in an eye-to-hand
conﬁguration are performed to validate the eﬃciency of the algorithm in comparison
with the Gauss Newton method in which a Jacobian estimation is done using (4.29)
and (4.30). Each algorithm is used to calculate θ for both small- and large-residual
k+1
cases. From these results, their algorithm outperforms the latter algorithm in both
66
Pseudo-code: Summary of the algorithm in [25] for the large-residual visual
servoing problem
Given: f : Rn → Rm ; θ ,θ ∈ Rn ; Jˆ ∈ Rm×n,P ∈ Rn×n,λ ∈ (0,1)
0 1 0 0
Initialize: Jˆ, θ , θ , , y , y∗, S = 0, and P
0 0 1 0 0 0
for k = 0,... do
Calculate H
k
H = JTJ +S
k k k k
Compute θ
k+1
θ = θ −(cid:0)JTJ +S +α D2(cid:1)−1JTf
k+1 k k k k k k k k
Update Jacobian J
k
∆f = f −f , h = θ −θ
k k−1 k−1 k k−1
(cid:16) (cid:17)
Jˆ = Jˆ +(cid:0)λ+hT P h (cid:1)−1 ∆f −Jˆ h hT P
k k−1 k−1 k−1 k−1 k−1 k−1 k−1 k−1
1 (cid:16) (cid:17)
P = P −(cid:0)λ+hT P h (cid:1)−1(cid:0)P h hT P (cid:1)
k λ k−1 k−1 k−1 k−1 k−1 k−1 k−1 k−1
Compute the ratio r
∆F
r =
∆q
Update trust region size δ
k

0.5(cid:107)D h (cid:107) if r ≤ 0.25
 k k 2
δ = 2(cid:107)D h (cid:107) if r ≥ 0.75
k+1 k k 2

(cid:107)D h (cid:107) if otherwise
k k 2
Update the residual S
k
(cid:16) (cid:17) (cid:16) (cid:17)T (cid:16) (cid:17)
z∗ −Sˆ h g T +g z∗ −Sˆ h hT z∗ −Sˆ h g g T
k k k k k k k k k k k k k k
ˆ ˆ
S = S + −
k+1 k g Th (g Th )2
k k k k
where
z∗ = JˆT f −JˆTf
k k+1 k+1 k k+1
g = JˆT f −JˆTf
k k+1 k+1 k k
end for
Figure 4.1: Pseudo-code for the algorithm in [25]
67
cases. For the large-residual case, the algorithm presented by Fu et al. quickly con-
verges to the desired robot conﬁguration θ∗ while the other method fails to converge.
In addition, the average error is substantially reduced when the two cameras are
arranged perpendicularly to each other.
4.4 Modiﬁed Hessian Approximations for the Large-Residual
Visual Servoing Problem
Bothpreviousstudiesaremainlydevelopedforstatictargettrackinginaneye-to-hand
conﬁguration. An algorithm for moving target tracking in an eye-in-hand conﬁgura-
tion for the large-residual cases does not seem to have appeared in the literature.
Although Kim et al. [39] brieﬂy presented moving target tracking in an eye-to-hand
conﬁguration the theoretical development was not given. As a result, this section
is devoted to a development of a novel algorithm for solving the large-residual vi-
sual servoing problems without a priori requirement of a kinematic robot model or a
camera calibration.
This development is originally inspired by the work of Fu et al. [25]. An attempt
to implement Fu’s algorithm for a moving target tracking has been made. For sim-
plicity, the eye-to-hand camera conﬁgurations with a RRR robot presented in [25]
are initially used to simulate both static and moving target tracking. For static tar-
get tracking similar simulation results presented in [25] are obtained. However, for
the moving target tracking case the performance of this algorithm deteriorates and
often diverges. It is worth mentioning that Fu’s algorithm embeds three diﬀerent
issues, i.e., estimating S , a trust region method, and the LMA, of which imperfect
k
implementation of any issue may aﬀect the overall performance of the algorithm. In
addition, the residual S approximation in [25] follows NL2SOL [17, 20] which is a
k
complex FORTRAN code containing 2360 lines excluding comments. Furthermore,
the algorithm for updating the damping parameter α and the diagonal matrix D
k k
might yield a size of the trust region δ that satisﬁes (4.34) but is still too large
k
68
for small-approximation Jacobian based control in robotic applications. Therefore,
a novel algorithm that oﬀers improved stability for moving target tracking with less
complexity and calculation costs is developed in this section.
Sincetheideasofimplementingatrust-regionmethodandtheLMAin[25]demon-
strates a potential to improve the eﬃciency and stability of the algorithm, the LMA
similar to those used in [25] are also parts of this novel algorithm and they are dis-
cussed in more detail in Chapter 6.
In this section three distinct algorithms are proposed for the Hessian H approx-
k
imation:
1. Approximation of the whole Hessian H using the DBFGS update
k
2. Approximation of the residual S
k
(a) Using the BFGS update
(b) Using the modiﬁed BFGS update
4.4.1 Approximation of the whole Hessian H using the DBFGS update
k
For the most general case of visual servoing problems the objective function F(θ,t)
is deﬁned as in (4.2) since it applies to the special cases, i.e., an eye-to-hand camera
conﬁguration, with small modiﬁcations. From
1
F (θ,t) = fT (θ,t)f (θ,t) [4.2]
2
and expanding (4.2) in a Taylor series about (θ,t) gives
F(θ+h ,t+h ) = F(θ,t)+F h +F h +O(h2) (4.39)
θ t θ θ t t θ
where F and F are partial derivatives of F with respect to θ and t while h and h
θ t θ t
are increments of θ and t respectively. At a given sampling period h , the function F
t
69
is minimized by solving
∂F(θ+h ,t+h )
θ t
0 =
∂θ
0 = F +F h +F h +O(h2) (4.40)
θ θθ θ θt t θ
Dropping the higher order term O(h2) yields
θ
0 = F +F h +F h (4.41)
θ θθ θ θt t
Rearranging (4.41) gives
F h = −(F +F h )
θθ θ θ θt t
∂
= − (F +F h )
t t
∂θ
= −∇(F +F h ) (4.42)
t t
Recall that F ≡ H and the secant equation for approximating the Hessian H is
θθ k k+1
analogous to (4.9),
H h = g∗ (4.43)
k+1 k k
where h = θ −θ . However, in this case from (4.42) g∗ is deﬁned diﬀerently as
k k+1 k k
g∗ = ∇(F +F h ) −∇(F +F h ) (4.44)
k t t k+1 t t k
Expanding (4.44) in terms of f(θ,t) in (4.4) yields
(cid:20) (cid:21) (cid:20) (cid:21)
∂f ∂f
g∗ = JT (f + k+1h ) − JT(f + kh ) (4.45)
k k+1 k+1 ∂t t k k ∂t t
It should be emphasized that (4.45) diﬀers from g (4.11) in Section 4.3.2 due
k−1
to the inclusion of the time-dependent term JT ∂fk+1h −JT∂fkh . For simpler ref-
k+1 ∂t t k ∂t t
erencing the secant equation (4.43) is referred to as the dynamic secant equation.
Since the Hessian H is symmetric and often positive symmetric, an algorithm
k
that preserves symmetric positiveness of H such as the BFGS method is preferred.
k
70
As a result, the derivation of the Hessian H update that satisﬁes the dynamic secant
k
equation can be done analogously to the BFGS derivation. The following derivation
of the H approximation follows the steps presented in [19].
k+1
From the Lemma 9.2.1 in [19] H is symmetric and positive deﬁnite if and only
k+1
if
H = M MT for some nonsingular M ∈ Rn×n (4.46)
k+1 k+1 k+1 k+1
such that
M MT h = g∗ for given h ,g∗ ∈ Rn and h (cid:54)= 0 (4.47)
k+1 k+1 k k k k k
Equation (4.47) can be rewritten as
M v = g∗ (4.48)
k+1 k k
MT h = v (4.49)
k+1 k k
The following procedures are suggested in [19] for solving (4.47),
1. M is selected such that M v = g∗. In this step M is a function of v
k+1 k+1 k k k+1 k
and g∗
k
2. v is selected to satisfy MT h = v
k k+1 k k
Using the Cholesky factorization on H gives
k
H = K KT (4.50)
k k k
In order to properly choose M for step 1, Broyden’s method is used to approximate
k+1
M with the minimal changes from K , i.e., minimizing the Frobenius norm of the
k+1 k
diﬀerence between the two matrices,
(g∗ −K v )vT
M = K + k k k k (4.51)
k+1 k vTv
k k
Substituting (4.51) into v = MT h in step 2 gives,
k k+1 k
(g∗ −K v )Th
v = KTh +v k k k k (4.52)
k k k k vTv
k k
71
Rearranging (4.52) yields
(cid:18) (g∗ −K v )Th (cid:19)
v 1− k k k k = KTh (4.53)
k vTv k k
k k
Let
v = αKTh (4.54)
k k k
and then substituting (4.54) into (4.53), multiplying through by the denominator
vTv , and rearranging the equation gives
k k
αKTh (α2hTK KTh −(g∗ −K v )Th ) = α2hTK KTh KTh
k k k k k k k k k k k k k k k k
where
g∗Th
α2 = k k
hTK KTh
k k k k
g∗Th
= k k (4.55)
hTH h
k k k
Substituting α into (4.54) gives an expression for v
k
(cid:18) g∗Th (cid:19)1/2
v = k k KTh (4.56)
k hTH h k k
k k k
Next substituting (4.51) into (4.46) gives,
(cid:34) (cid:35)
(cid:20) (g∗ −K v )vT(cid:21) v (g∗ −K v )T
H = K + k k k k KT + k k k k
k+1 k vTv k vTv
k k k k
(g∗ −K v )vTKT
= K KT + k k k k k
k k vTv
k k
K v (g∗ −K v )T
+ k k k k k
vTv
k k
(g∗ −K v )vTv (g∗ −K v )T
+ k k k k k k k k
(vTv )2
k k
g∗vTKT −K v vTKT
= K KT + k k k k k k k
k k vTv
k k
K v g∗T −K v vTKT
+ k k k k k k k
vTv
k k
g∗g∗T −g∗vTKT −K v g∗T +K v vTKT
+ k k k k k k k k k k k k
vTv
k k
g∗g∗T K v vTKT
H = K KT + k k − k k k k (4.57)
k+1 k k vTv vTv
k k k k
72
Substituting (4.56) into vTv yields
k k
(cid:18) g∗Th (cid:19)
vTv = k k hTK KTh
k k hTH h k k k k
k k k
(cid:18) g∗Th (cid:19)
= k k hTH h
hTH h k k k
k k k
= g∗Th (4.58)
k k
and then substituting (4.56) and (4.58) into (4.57) gives
g∗g∗T
H = K KT + k k
k+1 k k g∗Th
k k
(cid:34) (cid:35)(cid:34) (cid:35)
(cid:18) 1 (cid:19) (cid:18) g∗Th (cid:19)1/2 (cid:18) g∗Th (cid:19)1/2
− ·K k k KTh hTK k k KT
g∗Th k hTH h k k k k hTH h k
k k k k k k k k
g∗g∗T
= K KT + k k
k k g∗Th
k k
(cid:18) 1 (cid:19) (cid:18) g∗Th (cid:19)
− · k k (cid:2)K KTh hTK KT(cid:3)
g∗Th hTH h k k k k k k
k k k k k
Finally, using H = K KT yields
k k k
g∗g∗T (cid:18) g∗Th (cid:19)(cid:18)H h hTH (cid:19)
H = H + k k − k k k k k k
k+1 k g∗Th hTH h g∗Th
k k k k k k k
g∗g∗T H h hTH
= H + k k − k k k k (4.59)
k g∗Th hTH h
k k k k k
Although (4.59) appears to be in the same form of the well-known BFGS update
[19], in this case g∗ is deﬁned diﬀerently by (4.45) due to the inclusion of the time-
k
dependent terms. Consequently, (4.59) is referred as the dynamic BFGS (DBFGS)
update. In summary the DBFGS update is
g∗g∗T H h hTH
H = H + k k − k k k k [4.59]
k+1 k g∗Th hTH h
k k k k k
where
(cid:18) (cid:19) (cid:18) (cid:19)
∂f ∂f
g∗ = JT f + k+1h −JT f + kh (4.60)
k k+1 k+1 ∂t t k k ∂t t
h = θ −θ (4.61)
k k+1 k
73
Pseudo-code: The DBFGS method
Given: Rn → Rm ; θ ,θ ∈ Rn ; Jˆ ∈ Rm×n,P ∈ Rn×n,λ ∈ (0,1)
0 1 0 0
Initialize: J , θ , θ , H and P
0 0 1 0 0
for k = 1,... do
ˆ
Calculate: J using the dynamic Broyden’s method for a Jacobian
k
estimation
∆f = f −f
k k−1
h = θ −θ
k−1 k k−1
h = t −t
t k k−1
(cid:20) (cid:21)
(θ −θ )
h˜ = k k−1
(t −t )
k k−1
(cid:104) (cid:16) (cid:17) (cid:105)
J˜ = Jˆ fˆ
k−1 k−1 t
k−1
(cid:16) (cid:17)−1(cid:16) (cid:17)
J˜ = J˜ + λ+h˜TP˜ h˜ ∆f −J˜ h˜ h˜TP˜
k k−1 k−1 k−1 k−1
(cid:18) (cid:19)
1 (cid:16) (cid:17)−1(cid:16) (cid:17)
P˜ = P˜ − λ+h˜TP˜ h˜ P˜ h˜h˜TP˜
k k−1 k−1 k−1 k−1
λ
ˆ
Calculate: H using the DBFGS update
k
(cid:18) (cid:19) (cid:18) (cid:19)
∂f ∂f
g∗ = JˆT f + kh −JˆT f + k−1h
k−1 k k ∂t t k−1 k−1 ∂t t
g∗ g∗ T Hˆ h hT Hˆ
Hˆ = Hˆ + k−1 k−1 − k−1 k−1 k−1 k−1
k k−1 g∗ Th hT Hˆ h
k−1 k−1 k−1 k−1 k−1
Calculate: θ using the quasi-Newton’s method
k+1
(cid:18) (cid:19)
(cid:16) (cid:17)−1 ∂f (t)
θ = θ − Hˆ JˆT f + k h
k+1 k k k k ∂t t
end for
Figure 4.2: A pseudo-code for the DBFGS update
The DBFGS update is implemented with the dynamic Broyden’s method for a
Jacobian approximation similar to the DGN-PBM algorithm as shown in the pseudo-
code of Figure 4.2.
74
The Hessian approximation H using the standard BFGS method,
k
g g T H h hT H
H = H + k−1 k−1 − k−1 k−1 k−1 k−1 (4.62)
k k−1 g Th hT H h
k−1 k−1 k−1 k−1 k−1
∂f ∂f
where g does not include the dynamic terms JT kh −JT k−1h and is deﬁned
k−1 k ∂t t k−1 ∂t t
as
g = JTf −JT f (4.63)
k−1 k k k−1 k−1
is used as a comparative method to the DBFGS update (4.59). For future reference
the Hessian approximation (4.62) where g is deﬁned as in (4.63) is referred as the
k−1
standard BFGS update.
4.4.2 Approximation of the residual S using the BFGS method
k
ˆ
In Section 4.2.2 a secant technique used for the Hessian H approximation is extended
k
to estimate the residual S . As presented in [49], NL2SOL [17, 20] demonstrates
k
a stability improvement for solving the large-residual optimization problems. This
method further shows a potential to provide a more rapid and robust algorithm
to achieve static target tracking [25] for the large-residual visual servoing problem.
As a result, two approaches inspired by the residual S approximation presented in
k
NL2SOL are developed for moving target tracking, namely the BFGS method and
the modiﬁed BFGS method. This section reviews an approximation of the residual
S using the BFGS method, then Section 4.4.3 discusses the residual approximation
k
using a novel modiﬁed BFGS method.
Dennis et al. [17, 20] introduce a secant equation for the residual S as
k
S h = JTf −JT f ≡ z∗ [4.31]
k k−1 k k k−1 k k−1
Instead of using the DFP-like method to approximate S from S as in [17, 20],
k k−1
the BFGS method, which is well-known to be more robust and stable than the DFP
method, can be used,
z∗ z∗ T Sˆ h hT Sˆ
Sˆ = Sˆ + k−1 k−1 − k−1 k−1 k−1 k−1 (4.64)
k k−1 z∗ Th hT Sˆ h
k−1 k−1 k−1 k−1 k−1
75
where
z∗ = JTf −JT f
k−1 k k k−1 k
ˆ ´
Then S from (4.64) is used to approximate H as
k k
H´ = JˆTJˆ +Sˆ (4.65)
k k k k
ˆ
where J can be approximated using the dynamic Broyden’s method as in the DGN-
k
PBM algorithm [59]. Since in this case the objective function F(θ,t) is now a function
of both the robot joint angles θ and time t, the image error vector f(θ,t) may change
duetoeitherrobotmovement, targetmotion, oracombinationofboth. Theinclusion
∂f ∂f
k ˆ k
ofthetime-varyingterm h isnecessaryforestimatingJ and simultaneously.
t k
∂t ∂t
Then the dynamic full quasi-Newton method is utilized to estimate θ as
k+1
(cid:18) (cid:19)
(cid:16) (cid:17)−1 ∂f (t)
θ = θ − H´ JˆT f + k h (4.66)
k+1 k k k k ∂t t
This algorithm is called the dynamic full Newton method with BFGS algorithm or
DFN-BFGS. The pseudo-code summarizing the implementation of the DFN method
is shown in Figure 4.3.
4.4.3 Approximation of the residual S using the MBFGS update
k
A slight modiﬁcation of (4.64) has been made where gT h replaces z∗ Th ,
k−1 k−1 k−1 k−1
z∗ z∗ T Sˆ h hT Sˆ
Sˆ = Sˆ + k−1 k−1 − k−1 k−1 k−1 k−1 (4.67)
k k−1 gT h hT Sˆ h
k−1 k−1 k−1 k−1 k−1
and
z∗ = JˆTf −JˆT f
k−1 k k k−1 k
g = JˆTf −JˆT f
k−1 k k k−1 k−1
This is called the modiﬁed BFGS method or MBFGS for estimating the residual S .
k
The MBFGS method is also implemented in conjunction with a Jacobian estima-
tion presented in the DGN-PBM algorithm [59] to approximate θ as in (4.66). The
k+1
summary of this approach is shown in the pseudo-code in Figure 4.4.
76
Pseudo-code: The Dynamic Full Newton Method with BFGS Algorithm
(DFN-BFGS)
Given: Rn → Rm ; θ ,θ ∈ Rn ; Jˆ ∈ Rm×n,P ∈ Rn×n,λ ∈ (0,1)
0 1 0 0
Initialize: J , θ , θ , H and P
0 0 1 0 0
for k = 1,... do
ˆ
Calculate: J using the DGN-PBM algorithm [59]
k
∆f = f −f
k k−1
h = θ −θ
k−1 k k−1
h = t −t
t k k−1
(cid:20) (cid:21)
(θ −θ )
h˜ = k k−1
(t −t )
k k−1
(cid:104) (cid:16) (cid:17) (cid:105)
J˜ = Jˆ fˆ
k−1 k−1 t
k−1
(cid:16) (cid:17)−1(cid:16) (cid:17)
J˜ = J˜ + λ+h˜TP˜ h˜ ∆f −J˜ h˜ h˜TP˜
k k−1 k−1 k−1 k−1
(cid:18) (cid:19)
1 (cid:16) (cid:17)−1(cid:16) (cid:17)
P˜ = P˜ − λ+h˜TP˜ h˜ P˜ h˜h˜TP˜
k k−1 k−1 k−1 k−1
λ
ˆ
Update the residual S
k
z∗ z∗ T Sˆ h hT Sˆ
Sˆ = Sˆ + k−1 k−1 − k−1 k−1 k−1 k−1
k k−1 z∗ Th hT Sˆ h
k−1 k−1 k−1 k−1 k−1
where
z∗ = JˆTf −JˆT f
k−1 k k k−1 k
´
Calculate H
k
H´ = JˆTJˆ +Sˆ
k k k k
Calculate: θ using the dynamic full quasi-Newton method
k+1
(cid:18) (cid:19)
(cid:16) (cid:17)−1 ∂f (t)
θ = θ − H´ JˆT f + k h
k+1 k k k k ∂t t
end for
Figure 4.3: Pseudo-code for the DFN-BFGS approach
77
The main diﬀerence is that the denominator z∗ Th in (4.64) is replaced by
k−1 k−1
gT h in (4.67). In order to understand the impact of these quantities recall that
k−1 k−1
the Hessian H approximation satisﬁes the secant equation,
k
H h = g [4.9]
k k−1 k−1
where
h = θ −θ [4.10]
k−1 k k−1
and
g = JTf −JT f [4.11]
k−1 k k k−1 k−1
Transposing (4.9) and multiplying through by h gives
k
hT H h = gT h (4.68)
k−1 k k−1 k−1 k−1
The quantity gT h is known as the approximate curvature [27] of the objective
k−1 k−1
function F . The new quadratic model q of the function F can be approximated
k−1 k k
ˆ
using the update H satisfying (4.9),
k
1
q (θ) = F +∇FT(θ−θ )+ (θ−θ )TH (θ−θ ) (4.69)
k k k k 2 k k k
Equation (4.68) implies that the approximate curvature g Th implements the
k−1 k−1
exact curvature of the new quadratic model q in the direction of h .
k k−1
A similar derivation of z∗ Th in (4.64) can be done. Each Sˆ update from
k−1 k−1 k
(4.64) satisﬁes the secant equation,
S h = JTf −JT f ≡ z∗ [4.31]
k k−1 k k k−1 k k−1
or
S h = z∗ (4.70)
k k−1 k−1
Then transposing (4.70) and multiplying through by h gives
k−1
hT S h = z∗ Th (4.71)
k−1 k k−1 k−1 k−1
78
Since S is only a component of H , i.e., H = JTJ + S , the approximate
k k k k k k
curvature z∗ Th only represents a part of the curvature information of quadratic
k−1 k−1
model q . As a result, replacing the approximate curvature g Th as in (4.67)
k k−1 k−1
basically enforces the curvature information of the function F into the residual S
k k
approximation. Although the exact relationship between z∗Th and the approximate
k k
curvature g Th of the function F(θ,t) has not been established, simulation results
k k
in Chapter 6 shows signiﬁcant improvement using (4.67) over the method in (4.64).
Another aspect of (4.67) can be established by multiplying the second term of the
right hand side of (4.64) with the unity term,
(cid:32) (cid:33)
z∗ Th g Th
k−1 k−1 · k−1 k−1
g Th z∗ Th
k−1 k−1 k−1 k−1
to give
(cid:32) (cid:33)
z∗ z∗ T z∗ Th g Th Sˆ h hT Sˆ
Sˆ = Sˆ + k−1 k−1 k−1 k−1 · k−1 k−1 − k−1 k−1 k−1 k−1 (4.72)
k k−1 z∗ Th g Th z∗ Th hT Sˆ h
k−1 k−1 k−1 k−1 k−1 k−1 k−1 k−1 k−1
or
(cid:32) (cid:33)(cid:32) (cid:33)
z∗ z∗ T gT h Sˆ h hT Sˆ
Sˆ = Sˆ + k−1 k−1 k−1 k−1 − k−1 k−1 k−1 k−1 (4.73)
k k−1 gT h z∗ Th hT Sˆ h
k−1 k−1 k−1 k−1 k−1 k−1 k−1
Substituting (4.71) and (4.68) for z∗ Th and gT h gives
k−1 k−1 k−1 k−1
(cid:32) (cid:33)
z∗ z∗ T (cid:18)hT H h (cid:19) Sˆ h hT Sˆ
Sˆ = Sˆ + k−1 k−1 k−1 k k−1 − k−1 k−1 k−1 k−1 (4.74)
k k−1 gT h hT S h hT Sˆ h
k−1 k−1 k−1 k k−1 k−1 k−1 k−1
Substituting H = JTJ +Sˆ gives
k k k k
 (cid:16) (cid:17) 
Sˆk = Sˆk−1 +(cid:32)zgk∗T−1zhk∗−1T(cid:33)hTk−1 hJTkTJSk +hSˆk hk−1− Sˆkh−T1hkS−ˆ1hTk−h1Sˆk−1 (4.75)
k−1 k−1 k−1 k k−1 k−1 k−1 k−1
Comparing (4.75) with (4.67) requires that
(cid:16) (cid:17)
hT JTJ +Sˆ h
k−1 k k k k−1
= 1 (4.76)
hT Sˆ h
k−1 k k−1
for (4.67) and (4.75) to be the same. This is the case only if
hT Sˆ h >> hT (cid:0)JTJ (cid:1)h
k−1 k k−1 k−1 k k k−1
79
so that
(cid:16) (cid:17)
hT JTJ +Sˆ h
k−1 k k k k−1
≈ 1 (4.77)
hT Sˆ h
k−1 k k−1
Therefore, for the case that hT Sˆ h is relatively large compared to the term
k−1 k k−1
hT JTJ h , the MBFGS method is the same as using the unmodiﬁed BFGS
k−1 k k k−1
ˆ
method for approximating S (4.64). Otherwise, the MBFGS method generates dif-
k
ferent results from the unmodiﬁed BFGS method. Simulation results in Chapter 6
show that the approach in Figure 4.4 outperforms approaches in Figure 4.3 and in
Figure 4.2 when (cid:107)S (cid:107) is relatively the same as of (cid:107)JˆTJˆ(cid:107) where (cid:107)·(cid:107) refers to the
k F k k F F
Frobenius norm.
To minimize computational cost this novel MBFGS method is only employed on
the large-residual problem (not necessarily restricted to only the case that S is dom-
k
inant compared to the linear term JˆTJˆ). If the residual S becomes relatively small
k k k
so that S can be approximated as zero, then the quasi-Newton method becomes the
k
quasi-Gauss-Newton method and the DGN-PBM approach is used instead. Conse-
quently, a switching method where the algorithm presented in Figure 4.4 is applied
whenever (cid:107)f (cid:107) is greater than a criteria and the DGN-PBM approach is employed
k
otherwise is created to eﬃciently calculate the next θ when the residual error is
k+1
signiﬁcant. The details of the switching method are discussed in Section 4.7.
4.5 Convergence Analysis of the MBFGS Method
InoptimizationproblemstheBFGSmethodisawell-knownandwidespreadapproach
for approximating the Hessian matrix in a quasi-Newton method with satisfactory
convergence properties. For example, Powell [62] proved a global convergence using
the BFGS method with an inexact line search. Byrd, Nocedal, and Yuan [8] extended
the proof of Powell [62] for convergence analysis of other algorithms in Broyden’s
class formula excluding the DFP method where κ = 1 in (4.78). The Broyden’s class
80
Pseudo-code: The Modiﬁed BFGS method for the Residual Approximation
(MBFGS)
Given: Rn → Rm ; θ ,θ ∈ Rn ; Jˆ ∈ Rm×n,P ∈ Rn×n,λ ∈ (0,1)
0 1 0 0
ˆ
Initialize: J , θ , θ , H and P
0 0 1 0 0
for k = 1,... do
ˆ
Calculate: J using a Jacobian estimation in the DGN-PBM algorithm [59]
k
∆f = f −f
k k−1
h = θ −θ
k−1 k k−1
h = t −t
t k k−1
(cid:20) (cid:21)
(θ −θ )
h˜ = k k−1
(t −t )
k k−1
(cid:104) (cid:16) (cid:17) (cid:105)
J˜ = Jˆ fˆ
k−1 k−1 t
k−1
(cid:16) (cid:17)−1(cid:16) (cid:17)
J˜ = J˜ + λ+h˜TP˜ h˜ ∆f −J˜ h˜ h˜TP˜
k k−1 k−1 k−1 k−1
(cid:18) (cid:19)
1 (cid:16) (cid:17)−1(cid:16) (cid:17)
P˜ = P˜ − λ+h˜TP˜ h˜ P˜ h˜h˜TP˜
k k−1 k−1 k−1 k−1
λ
ˆ
Update the residual S
k
z∗ z∗ T Sˆ h hT Sˆ
Sˆ = Sˆ + k−1 k−1 − k−1 k−1 k−1 k−1
k k−1 g Th hT Sˆ h
k−1 k−1 k−1 k−1 k−1
where
z∗ = JˆTf −JˆT f
k−1 k k k−1 k
g = JˆTf −JˆT f
k−1 k k k−1 k−1
´
Calculate H
k
H´ = JˆTJˆ +Sˆ
k k k k
Calculate: θ using the dynamic full quasi-Newton method
k+1
(cid:18) (cid:19)
(cid:16) (cid:17)−1 ∂f (t)
θ = θ − H´ JˆT f + k h
k+1 k k k k ∂t t
end for
Figure 4.4: Pseudo-code for the MBFGS approach
81
formula [6] for Hessian approximation is
g g T Hˆ h hTHˆ (cid:16) (cid:17)
Hˆ = Hˆ + k k − k k k k +κ hTHˆ h w wT (4.78)
k+1 k g Th hTHˆ h k k k k k
k k k k k
where κ ∈ [0,1],
g = ∇F −∇F
k k+1 k
h = θ −θ
k k+1 k
and
(cid:20) (cid:21)
g H h
k k k
w = −
k gTh hTH h
k k k k k
For convenience in future reference, let
(cid:0) (cid:1)
d ≡ ∇F = JTf
k k k k
so that g becomes
k
g ≡ d −d
k k+1 k
For κ = 0, (4.78) yields the BFGS method and for κ = 1, it gives the DFP
method. Even though it has been shown in [21] that all members of this class give
the same result with exact line searches, Byrd et al. [8] states that the performance
of this class varies with inexact line searches, which are more eﬃcient and require less
computational cost compared to exact line searches. Since the MBFGS method is
developed from the BFGS method, the convergence analysis of the MBFGS method
heavily depends on the proof of the Broyden’s class method presented in [8] where
κ = 0 with inexact line searches.
The Hessian approximation from (4.78) is used in a quasi-Newton method for
determining θ ,
k+1
θ = θ +α s (4.79)
k+1 k k k
82
where
s = −Hˆ−1d (4.80)
k k k
αisasteplengthparameterthatisselectedusinganinexactlinesearchalgorithmthat
satisﬁes the Wolfe Conditions [8, 50] to ensure a suﬃcient reduction of the objective
function F(θ) as
F ≤ F +c α dTs (4.81)
k+1 k 1 k k k
c dTs ≤ dT s (4.82)
2 k k k+1 k
where c ,c are positive constants such that 0 < c < 1 and 0 < c < c < 1.
1 2 1 2 1 2
If the objective function F(θ,t) has a minimizer θ∗ at a given time t then Hˆ(θ∗),
it is assumed to be positive deﬁnite. Dennis and Mor´e [18] proved that if the step
length α is always chosen as 1, it satisﬁes conditions (4.81) and (4.82), and
k
∞
(cid:88)
(cid:107)θ −θ∗(cid:107) < ∞ (4.83)
k
k=0
so θ converges superlinearly to θ∗.
k
Other representative studies related to the BFGS and Broyden class approaches
are presented in [28, 66, 72, 74].
The goal of solving an optimization problem in this analysis is to ﬁnd θ that
k+1
minimizes the objective function F(θ,t) at any given instant t so t is held constant
and is dropped from the convergence analysis for simplicity. Since Byrd et al. [8] have
already established the convergence analysis for the Broyden’s class formula used in
conjunction with a line search algorithm, the MBFGS convergence analysis mainly
follows the same process. The major diﬀerence is due to the fact that in [8] the BFGS
ˆ
method (4.78) is used to approximate the whole Hessian matrix H in (4.80), which
k
is subsequently used in the quasi-Newton method to calculate θ as in (4.79). In
k+1
contrast, the MBFGS method is used to approximate the residual S which is only a
k
83
component of the Hessian H´ , i.e., H´ = JˆTJˆ +Sˆ . Consequently, the resulting S
k k k k k k
update using the MBFGS method is indirectly used to calculate θ .
k+1
For the remainder of the convergence analysis, the Jacobian J is assumed to be
k
knownandispositivedeﬁnite. ApropermethoddealingwithacasewhentheHessian
is ill-conditioned or becomes singular is discussed in Chapter 6.
4.5.1 Convergence Analysis of the BFGS method
This section reviews the convergence analysis of the Broyden’s class formula for ap-
ˆ
proximating the Hessian H presented in [8] that is implemented with an inexact line
k
search for determining a solution of unconstrained optimization using a quasi-Newton
method. It shows that if the objective function is assumed to be uniformly convex,
ˆ
the sequence of θ from (4.79)-(4.80) using the Hessian approximation H from (4.78)
k k
with κ ∈ [0,1) converges to a solution linearly. The study in [8] further implies the
results of Dennis and Mor´e [18] and of Griewank and Toint [28] for superlinear con-
vergence if the step length α = 1 is always chosen when it is permissible. However,
k
this convergence analysis implies that θ is suﬃciently close to the minimizer θ∗ and
k
the sequence of θ remains in the neighborhood of the solution. In [8] it is also shown
k
that the iterates generated by (4.79)-(4.80) gives superlinear convergence even if the
diﬀerent values of κ ∈ [0,1) are applied in (4.78) as long as cos(ϑ ), the angle be-
k
tween the gradient vector d and the Newton step h , is bounded away from zero.
k k
This concept is in fact the key attribute applied to the MBFGS algorithm for proving
its convergence in Section 4.5.2.
Since a similar analysis with the same line search, the same assumptions, and
some of the lemmas developed in [8] can be extended to the MBFGS algorithm, it is
appropriate to review these assumptions, lemmas, and theorems herein as fundamen-
tal knowledge for the extended convergence study of the MBFGS algorithm, which is
developed in Section 4.5.2. Since only the BFGS algorithm is relevant, the review of
84
the Broyden’s class formula is only focused on the BFGS method i.e., κ = 0 in (4.78).
The following two assumptions hold throughout the remainder of the develop-
ment. Note that Assumption 1 is originally presented as a preliminary rather than
an assumption in [8]. However, for simplicity of the extended analysis development
(the MBFGS algorithm), it is suitable to present these conditions as Assumption 1.
Assumption 1. The objective function F(θ) is assumed to be twice continuously dif-
ferentiableandisuniformlyconvexonthelevelsetD whereD = {x ∈ Rm : F(θ) ≤ F(θ )}.
1
¯
Let H(θ) be the true value of the Hessian matrix of F(θ) and let H is deﬁned as
(cid:90) 1
¯
H = H(θ +τh )dτ
k k
0
¯
H is an average value of the Hessian H(θ) over the interval between θ and θ .
k k+1
Also let θ∗ be the unique minimizer of F(θ) in D and the true Hessian at that point
is H(θ∗). The approximated Hessian Hˆ is assumed to be positive deﬁnite and conse-
k
quentially the inequality
gTh > 0 (4.84)
k k
holds for all values of k.
Assumption 2 (Byrd et al. [8]). The level set D is convex and m and m are
1 2
positive constants such that
m (cid:107)q(cid:107)2 ≤ qTH(θ)q ≤ m (cid:107)q(cid:107)2 (4.85)
1 2
for all q ∈ Rm and all θ ∈ D.
¯
The average Hessian H satisﬁes the following secant equation
¯
g = Hh (4.86)
k k
Substituting h for q and gT = hTH¯ for qTH(θ) in (4.85) yields
k k k
m (cid:107)h (cid:107)2 ≤ gTh ≤ m (cid:107)h (cid:107)2 (4.87)
1 k k k 2 k
85
From the deﬁnition of g ,
k
g = d −d (4.88)
k k+1 k
Transposing and multiplying (4.88) by h gives
k
gTh = dT h −dTh (4.89)
k k k+1 k k k
From the condition in (4.82), the approximate curvature gTh is constrained by
k k
−(1−c )dTh ≤ gTh = dT h −dTh (4.90)
2 k k k k k+1 k k k
The quantity dTh directly relates to the angle ϑ between the steepest descent di-
k k k
rection −d and the step h ,
k k
−dTh = (cid:107)d (cid:107)(cid:107)h (cid:107)cosϑ (4.91)
k k k k k
The angle ϑ plays a crucial role determining the length of the step h that results in
k k
the reduction of the function F(θ) at each iteration and is presented in a number of
studies such as [62, 74]. Indeed, the angle ϑ is the key variable used for convergence
k
proofoftheBroyden’sclassformulain[8]. Inordertounderstandtheeﬀectofcos(ϑ )
k
on the sequence of θ obtained from (4.79)-(4.80) using the Hessian approximation
k
ˆ
H from (4.78), it is necessary to review the following lemmas from [8].
k
From (4.87), (4.90), and (4.91) the lower and the upper bounds of (cid:107)h (cid:107) can be
k
established. The range of (cid:107)h (cid:107) and the upper bound of F −F∗ are concluded in
k k+1
Lemma 2.1 in [8] which is herein presented as Lemma 1 and Lemma 2 respectively.
Lemma 1 (Lemma 2.1 [8]). (see proof on p. 97)
Consider the resultant iteration, θ = θ +α s , using (4.79), where α satisﬁes
k+1 k k k k
the Wolfe conditions (4.81) and (4.82). If Assumption 1 and Assumption 2 hold, then
c (cid:107)d (cid:107)cosϑ ≤ (cid:107)h (cid:107) ≤ c (cid:107)d (cid:107)cosϑ (4.92)
3 k k k 4 k k
(1−c ) 2(1−c )
2 1
where c and c are positive constants such that c = and c = .
3 4 3 4
m m
2 1
The upper bound of F −F∗ is
k+1
86
Lemma 2 (Byrd et al. [8]). (see proof on p. 99)
(cid:2) (cid:3)
F −F∗ ≤ 1−c m c cos2ϑ (F −F∗) (4.93)
k+1 1 1 3 k k
Equation (4.93) requires that cosϑ needs to be bounded away from zero so that
k
θ converges to θ∗. Byrd et al. [8] proved this statement by using the trace of the
k
ˆ
Hessian H approximation in (4.78),
k
(cid:107)Hˆ h (cid:107)2 (cid:107)g (cid:107)2
ˆ ˆ k k k
Tr(H ) ≤ Tr(H )− + (4.94)
k+1 k hTHˆ h gTh
k k k k k
ˆ ˆ
where Tr(H ) is the trace of H .
k+1 k+1
It is shown that each term in (4.94) is bounded (see Lemma 3.1 in [8]),
Lemma 3 (Byrd et al. [8]).
(cid:107)g (cid:107)2
k
≤ m (4.95)
gTh 2
k k
(cid:107)Hˆ h (cid:107)2 α
k k k
− ≤ − (4.96)
hTHˆ h c cos2ϑ
k k k 4 k
The proof of each inequality is presented in [8].
Substituting the inequalities (4.95) and (4.96) in (4.94) gives
α
ˆ ˆ k
Tr(H ) ≤ Tr(H )+m − (4.97)
k+1 k 2 c cos2ϑ
4 k
ˆ ˆ
BecausetheapproximatedH isassumedtobepositivedeﬁnite, soisitstraceTr(H )
k k
[75]. In (4.97) the third term on the right-hand side reduces the trace and this term
α
k
is proportional to .
cos2ϑ
k
In fact, [8] shows that
α
k
0 < ≤ cosϑ (4.98)
ˆ k
c Tr(H )
4 k
ˆ
Thus cosϑ is small when (i) α is small or (ii) Tr(H ) is large. Two cases are
k k k
considered in [8]. The ﬁrst case assumes that the step length α is bounded away
k
from zero and that cosϑ is arbitrarily small so the third term of the right-hand
k
87
ˆ
side in (4.97) becomes dominant and Tr(H ) is reduced. However, from (4.98)
k+1
ˆ
if cosϑ becomes arbitrarily small, the bound of Tr(H ) becomes large (since
k+1 k+1
ˆ
α is assumed to be bounded away from zero). Thus the calculated Tr(H ) is
k+1 k+1
self-conﬂicting that limits its value to impossibly become too large. Therefore, the
tendency of cos(ϑ ) becoming close to zero is self limiting if α is assumably bounded
k k
away from zero.
Thesecondcaseassumesthatthesteplengthα tendstozero. Inthiscaseconsider
k
hTHˆ h
Lemma 2.2 in [8] which establishes the relationship between α and k k k,
k (cid:107)h (cid:107)2
k
Lemma 4 (Byrd et al. [8]).
hTHˆ h hTHˆ h
c k k k ≤ α ≤ c k k k (4.99)
3 (cid:107)h (cid:107)2 k 4 (cid:107)h (cid:107)2
k k
hTHˆ h
When α is close to zero, k k k becomes very small and the trace equation
k (cid:107)h (cid:107)2
k
hTHˆ h
(4.97) is no longer useful [8]. The relation between the quantity k k k and Tr(Hˆ )
(cid:107)h (cid:107)2 k
k
can be established as
hTHˆ h (cid:107)Hˆ h (cid:107)(cid:107)h (cid:107)
k k k ≤ k k k
(cid:107)h (cid:107)2 (cid:107)h (cid:107)2
k k
canceling (cid:107)h (cid:107) in both the numerator and denominator on the right-hand side gives
k
hTHˆ h (cid:107)Hˆ h (cid:107)
k k k ≤ k k (4.100)
(cid:107)h (cid:107)2 (cid:107)h (cid:107)
k k
ˆ
(cid:107)H h (cid:107)
k k
where holds in the following inequality [8],
(cid:107)h (cid:107)
k
ˆ
(cid:107)H h (cid:107)
k k ˆ
≤ Tr(H ) (4.101)
k
(cid:107)h (cid:107)
k
Notethat(cid:107)·(cid:107)ofavectorisreferredtotheEuclideannormwhereas(cid:107)·(cid:107) ofamatrixis
F
referred to the Frobenius norm of a matrix throughout the remainder of the analysis.
The derivation of (4.101) is presented in the proof of Lemma 10 on p. 107.
88
Combining (4.100) and (4.101) gives
hTHˆ h
k k k ≤ Tr(Hˆ ) (4.102)
(cid:107)h (cid:107)2 k
k
hTHˆ h
and it can be concluded that if k k k goes to zero, which is due to small eigenvalues
(cid:107)h (cid:107)2
k
ˆ ˆ
of H , Tr(H ) becomes very small and so does its determinant. The determinant of
k k
ˆ
H is expressed in [56] as
k
(cid:16) (cid:17) gTh
det(Hˆ ) ≥ det Hˆ k k (4.103)
k+1 k hTHˆ h
k k k
Equations (4.102) and (4.103) are used to show that Tr(Hˆ ) ≤ ck where c is a
k+1 0 0
ˆ
positive constant [8]. Then the relation between the trace and the determinant of H
k
is developed in [8] as
k (cid:34) ˆ (cid:35)n
(cid:89) 1−c 1 Tr(H )
2 k+1
≤
α det(Hˆ ) n
i=1 i 1
or
k
(cid:89) 1−c 1
2 ≤ (cn)k (4.104)
α det(Hˆ )nn 0
i=1 i 1
ˆ
where n is the number of eigenvalues of H. From (4.104) α is in fact bounded away
k
from zero (see Lemma 3.2 in [8] for details) and is presented herein as
Lemma 5 (Byrd et al. [8]). If κ ∈ [0,1], there exists a constant c > 0 such that
k
(cid:89)
α ≥ ck (4.105)
i
i=1
for all k ≥ 1
Lemma 5 contradicts to the assumption of the second case whereas the step length
α is assumed to be arbitrarily small, thus this case is not possible. Due to the result
k
ˆ
fromtheﬁrstcaseinwhichthetendencyofcos(ϑ )tozeroisself-limitingTr(H )from
k k
becoming negative. Byrd et al. [8] conclude that “all the updates in the restricted
Broyden class have a strong self correcting property with respect to the determinant.”
Then Byrd et al. [8] introduce Theorem 3.1 that is presented as
89
Theorem 4.5.1 (Byrdetal. [8]). Assume that the function F(θ) satisﬁes Assumption
ˆ
1 and Assumption 2 and let θ be a starting point, then for any positive deﬁnite H ,
1 1
the sequence of θ , generated by (4.78)-(4.80) with κ ∈ [0,1) and line search satisfying
k
(4.81)-(4.82), converges to θ∗.
To prove this theorem, recall the trace inequality as
α
ˆ ˆ k
0 < Tr(H ) ≤ Tr(H )+m − [4.97]
k+1 k 2 c cos2ϑ
4 k
Since it is proved that α is bounded from below in Lemma 5, if there are too many
k
ˆ
iterates such that {cosϑ } becomes arbitrarily small then Tr(H ) can become neg-
k k+1
ˆ
ative, which violates the fact that H is positive deﬁnite. As a result, Theorem
k+1
4.5.1 is proved by contradiction in which it seeks to prove that (4.97) is satisﬁed even
ˆ
if {cosϑ } → 0. It is shown that Tr(H ) is negative for suﬃciently large k when
k k+1
{cosϑ } → 0, thus it is impossible to satisfy (4.97). As a result, cosϑ is bounded
k k
from below. Then combining this result with Lemma 2 , Byrd et al. conclude that
the iterates θ converge to the solution.
k
4.5.2 Convergence Analysis of the MBFGS method
The Hessian approximation in the case of the MBFGS method is
H´ = JTJ +Sˆ (4.106)
k k k k
ˆ
in which the MBFGS method is used to update S as
k
z∗z∗T Sˆ h hTSˆ
Sˆ = Sˆ + k k − k k k k (4.107)
k+1 k gTh hTSˆ h
k k k k k
where
h = θ −θ
k k+1 k
z∗ = JT f −JTf
k k+1 k+1 k k+1
g = JT f −JTf
k k+1 k+1 k k
≡ d −d
k+1 k
90
In this section the Jacobian J is again assumed to be known and is positive
k
deﬁnite. For simplicity of referencing, the BFGS-QN algorithm is referred to the
quasi-Newton method in which the BFGS method presented in Byrd et al. [8] where
ˆ
κ = 0 is used to approximate H in calculating of θ . The MBFGS-QN algorithm
k k+1
is referred to as the quasi-Newton method in which the MBFGS method is used to
´
approximate H in calculating of θ . Both approaches are assumed to satisfy the
k k+1
Wolfe conditions (4.81)-(4.82) to generate the sequence θ as
k+1
θ = θ +α s´ (4.108)
k+1 k k k
or
h = α s´ (4.109)
k k k
where
s´ = −H´−1d (4.110)
k k k
´
Since s´ is approximated from H , which is diﬀerent from the s calculation using
k k k
ˆ
H in the previous sections, the notation s´ is introduced to distinguish between
k k
the two approaches. Note that, d = ∇F = JTf is the same for both methods.
k k k k
Furthermore, Assumption 1 and Assumption 2 are still valid and are also assumed
in this section (both assumptions are hold in regardless of how the Hessian matrix
is approximated). In addition, the following assumptions are applied in the MBFGS
method.
Assumption 3. The objective function F(θ) is assumed to be twice continuously dif-
ferentiableandisuniformlyconvexonthelevelsetD whereD = {x ∈ Rm : F(θ) ≤ F(θ )}.
1
Let S(θ) be the true value of ∇2F(θ) and let S¯ is an average value of ∇2F(θ) over
the interval between θ and θ deﬁned as
k k+1
(cid:90) 1
¯
S = S(θ +τh )dτ
k k
0
91
ˆ
For this section it is assumed that the approximated residual S is positive deﬁnite
k
and consequentially the inequality
z∗Th > 0 (4.111)
k k
holds for all values of k.
Assumption 4. The level set D is convex and w and w are positive constants such
1 2
that
w (cid:107)q´(cid:107)2 ≤ q´TS(θ)q´≤ w (cid:107)q´(cid:107)2 (4.112)
1 2
for all q´∈ Rm and all θ ∈ D.
¯
The average residual S satisﬁes the following secant equation
z∗ = S¯h (4.113)
k k
Substituting h for q and z∗T = hTS¯ for qTS(θ) in (4.112) yields
k k k
w (cid:107)h (cid:107)2 ≤ z∗Th ≤ w (cid:107)h (cid:107)2 (4.114)
1 k k k 2 k
ˆ ´
Since S , which is a component of the Hessian H , is calculated from the MBFGS
k k
approach, the relationship between z∗ and cosϑ and between s and h as in (4.91)
k k k
in Section 4.5.1 can be established. Transposing both sides of (4.113) and multiplying
through by h yields
k
hTS¯h = z∗Th (4.115)
k k k k
= (cid:107)z∗(cid:107)(cid:107)h (cid:107)cosγ (4.116)
k k k
where γ is the angle between z∗ and h . Recall
k k k
−dTh = (cid:107)d (cid:107)(cid:107)h (cid:107)cosϑ [4.91]
k k k k k
and
h = −α H´−1d [4.109]
k k k k
92
which is rewritten as
´
H h = −α d (4.117)
k k k k
Transposing, and multiplying through by h yields
k
hTH´ h = −α dTh (4.118)
k k k k k k
´
To obtain the relation between cosϑ and cosγ , substituting (4.106) for H and
k k k
(4.91) for dTh gives
k k
(cid:16) (cid:17)
hT JTJ +Sˆ h = α (cid:107)d (cid:107)(cid:107)h (cid:107)cosϑ (4.119)
k k k k k k k k k
ˆ ∼ ¯
If S = S is assumed, then substituting (4.116) into (4.119) gives
k
(cid:107)J h (cid:107)2 +(cid:107)z∗(cid:107)(cid:107)h (cid:107)cosγ = α (cid:107)d (cid:107)(cid:107)h (cid:107)cosϑ (4.120)
k k k k k k k k k
ˆ ´
For Hessian approximations H and H both d and cosϑ retain their original
k k k k
deﬁnitionsso(4.92)and(4.93)inLemma1andLemma2arestillvalidintheMBFGS
approach. Then the convergence analysis of the MBFGS method can be done anal-
ogously to the BFGS algorithm. To prove that the sequence θ generated by the
k
MBFGS algorithm converges to θ∗ when both Wolfe conditions are satisﬁed, it is
necessary to prove that cosϑ is bounded away from zero so Lemma 2 is satisﬁed.
k
Using the trace equation analogous to that in [8] gives
Tr(H´ ) = Tr(JT J )+Tr(Sˆ ) (4.121)
k+1 k+1 k+1 k+1
Because the J is positive deﬁnite, Tr(JT J ) is a positive number. Therefore
k+1 k+1 k+1
ˆ ´ ˆ
only Tr(S ) can reduce Tr(H ) and for simplicity only Tr(S ) is considered.
k+1 k+1 k+1
ˆ
The trace equation of S using the MBFGS method is
k+1
(cid:107)z∗(cid:107)2 (cid:107)Sˆ h (cid:107)2
Tr(Sˆ ) = Tr(Sˆ )+ k − k k (4.122)
k+1 k gTh hTSˆ h
k k k k k
Each of the terms in (4.122) is bounded and the following lemmas hold,
93
Lemma 6. (see proof on p. 100)
(cid:107)z∗(cid:107)2
k ≤ w (4.123)
gTh 3
k k
where w is a constant.
3
Lemma 7. (see proof on p. 101)
ˆ
α (cid:107)d (cid:107)−σ (cid:107)h (cid:107) ≤ (cid:107)S h (cid:107) ≤ α (cid:107)d (cid:107)+σ (cid:107)h (cid:107) (4.124)
k k k k k k k k k k
(cid:112)
where σ ≡ (cid:107)J (cid:107) = Tr(JTJ ).
k k F k k
Lemma 8. (see proof on p. 103)
(cid:107)Sˆ h (cid:107)2 (cid:18) α (cid:19)
k k k
− ≤ − −σ (4.125)
hTSˆ h c cosϑ k
k k k 4 k
A similar convergence analysis of the MBFGS-QN algorithm can be done analo-
gouslytotheBFGS-QNalgorithmbyusingthetraceequationin(4.122). Substituting
the inequalities (4.123) and (4.125) into (4.122) yields
(cid:18) (cid:19)
α
ˆ ˆ k
Tr(S ) ≤ Tr(S )+w − −σ
k+1 k 3 k
c cosϑ
4 k
or
α
ˆ ˆ k
Tr(S ) ≤ Tr(S )+w +σ − (4.126)
k+1 k 3 k
c cosϑ
4 k
ˆ ˆ
Since S is assumed to be positive deﬁnite, then Tr(S ) is positive. The
k+1 k+1
ˆ
reduction of Tr(S ) is due to the fourth term in the right-hand side of (4.126) that
k+1
α
k
is proportional to . This term becomes large if (i) α is large, or (ii) cosϑ is
k k
cosϑ
k
very small. As a result, similar reasoning and analysis as in [8] are applied in this
case in which the two scenarios are also considered. The ﬁrst case assumes that the
step length α is bounded away from zero and the cosϑ is arbitrarily small, thus
k k
α
ˆ k
Tr(S ) is reduced since becomes dominant. However, from
k
c cosϑ
4 k
α
k
≤ cosϑ [4.98]
ˆ k
c Tr(H )
4 k
94
ˆ
it can be implied that Tr(H ) becomes large if cosϑ tends to be arbitrarily small.
k k
Although a large value of Tr(Hˆ ) may be a result of a large value of Tr(JT J )
k k+1 k+1
ˆ
even if Tr(S ) is small, this is not the case being considered here since the MBFGS-
k
QN algorithm is only utilized when the residual S is signiﬁcant. Thus the value of
k
Tr(Sˆ ) is assumed at least to be as signiﬁcant as of Tr(JT J ). Since Tr(Sˆ ) varies
k k+1 k+1 k
due to the value of cosϑ , (4.98) implies that an arbitrarily small value of cosϑ is
k k
ˆ
somewhat a result of a large value of Tr(S ). Hence, this phenomenon demonstrates
k
the self-correcting property of the MBFGS approach when cos(ϑ ) tends to go to zero
k
if α is assumed to be bounded away from zero.
k
The second case assumes that the step length α tends to zero. From Lemma 4
k
hTHˆ h
when α is close to zero, k k k becomes very small and so does the determinant
k (cid:107)h (cid:107)2
k
ˆ
of H . Similar to the analysis in Section 4.5.1 that the trace equation (4.97) is no
k
ˆ
longer useful, it is necessary to carry on the study using the determinant of S and
k+1
Lemma 9. (see proof on p. 104)
(cid:0)z∗Th (cid:1)2
det(Sˆ ) = det(Sˆ ) k k (4.127)
k+1 k (cid:16) (cid:17)
(gTh ) hTSˆ h
k k k k k
Lemma 9 leads to Lemma 10 and ﬁnally Lemma 11 in which the mean of α is
k
proved to be bounded away from zero.
Lemma 10. (see proof on p. 107) There exists a constant c > 0 such that
5
k (cid:18) (cid:19)
(cid:89) α
i
+σ ≥ c (4.128)
i 5
c
4
i=1
for all k ≥ 1.
Lemma 11. (see proof on p. 111) There exists a constant c > 0 such that
6
k
(cid:89)
α ≤ ck (4.129)
i 6
i=1
for all k ≥ 1.
95
Since α is bounded away from zero as in Lemma 11, the only factor that can
i
ˆ
reduce Tr(S ) is due to cosϑ . Equation (4.126) is rewritten as,
k+1 k
α
ˆ ˆ k
0 < Tr(S ) ≤ Tr(S )+w +σ +η (4.130)
k+1 k 3 k k
c
4
where
1
η = − (4.131)
k
cosϑ
k
If too many steps generate cosϑ ≈ 0, the last term on the right-hand side of (4.130)
k
ˆ ˆ
canmakeTr(S )negative. Hence, theassumptionthatTr(S )ispositivedeﬁnite
k+1 k+1
is violated. Thus, cosϑ is required to bounded away from zero to satisfy (4.130),
k
ˆ
i.e., the trace of S is positive. Consequently, the following theorem is presented.
k+1
Theorem 4.5.2. For the starting iterate θ for which the objective function F(θ)
1
´
satisﬁes Assumptions 1, 2, 3, and 4, then for any positive deﬁnite H , the MBFGS
1
method (4.106)-(4.110) that satisﬁes the Wolfe conditions (4.81)-(4.82) generates θ
k
that converge to θ∗
Proof. This proof can be done by contradiction analogous to the BFGS-QN approach
presentedintheprevioussection. Asaresult,thefollowingstepsattempttoshowthat
ˆ
the trace Tr(S ) remains positive for suﬃciently large k even if {cosϑ } becomes
k+1 k
arbitrarily small. If {cosϑ } → 0, then η gets close to −∞. As a result, there is
k k
2w
3
an index K such that, for all i > K then η < − . Then starting from i = K ,
0 0 i c1/k 0
5
(4.130) can be expressed as
k k
(cid:88) (cid:88) α
ˆ ˆ i
0 < Tr(S ) ≤ Tr(S )+w (k +1−K )+ σ + η
k+1 K0 3 0 i ic
4
i=K0 i=K0
2w
3
Substituting η < − gives
i c1/k
5
k k
(cid:88) 2w (cid:88) α
ˆ ˆ 3 i
0 < Tr(S ) ≤ Tr(S )+w (k +1−K )+ σ − (4.132)
k+1 K0 3 0 i c1/k c4
i=K0 5 i=K0
96
Using the geometric/arithmetic mean inequality of (4.128) gives
k (cid:18) (cid:19)
1 (cid:88) α
c1/k ≤ i +σ
5 k c i
4
i=1
and then rearranging,
k k
(cid:88) (cid:88) α
kc1/k − σ ≤ i (4.133)
5 i c
4
i=1 i=1
From (4.133), when i = K then
0
(cid:88)k K(cid:88)0−1 α (cid:88)k α
kc1/k − σ − i ≤ i (4.134)
5 i c c
4 4
i=1 i=1 i=K0
Substituting (4.134) into (4.132) gives
(cid:32) (cid:33)
(cid:88)k 2w (cid:88)k K(cid:88)0−1 α
0 < Tr(Sˆ ) ≤ Tr(Sˆ )+w (k +1−K )+ σ − 3 kc1/k − σ − i
k+1 K0 3 0 i c1/k 5 i c4
i=K0 5 i=1 i=1
or
2w (cid:88)k 2w K(cid:88)0−1 α
ˆ ˆ 3 3 i
0 < Tr(S ) ≤ Tr(S )+w (1−k)−w K +(1+ ) σ +
k+1 K0 3 3 0 c1/k i c1/k c4
5 i=K0 5 i=1
ˆ
From the second term on the right-hand side, Tr(S ) becomes negative for suf-
k+1
´ ˆ
ﬁciently large k and thus contradicts the assumption that H and S are positive
k k
deﬁnite. Consequently, cosϑ is bounded away from zero. From (4.93) in Lemma 2,
k
(cid:2) (cid:3)
F −F∗ ≤ 1−c m c cos2ϑ (F −F∗) [4.93]
k+1 1 1 3 k k
it can be concluded that the sequence θ generated by using the MBFGS method
k
converges to θ∗.
4.5.3 Proofs of Lemmas
Proof of Lemma 1. Into (4.90) is substituted the upper bound for gTh from (4.87)
k k
and −dTh from (4.91),
k k
(1−c )(cid:107)d (cid:107)(cid:107)h (cid:107)cosϑ ≤ m (cid:107)h (cid:107)2
2 k k k 2 k
97
canceling (cid:107)h (cid:107) from both sides and rearranging gives
k
c (cid:107)d (cid:107)cosϑ ≤ (cid:107)h (cid:107) (4.135)
3 k k k
(1−c )
2
where c ≡ > 0.
3
m
2
Theupper boundof(cid:107)h (cid:107)canbecalculatedby usingaTaylorseriesapproximation
k
of the function F(θ) about θ ,
k
1
F(θ+h ) = F(θ )+dTh + hTH¯h
k k k k 2 k k
or
1
F(θ+h )−F(θ ) = dTh + hTH¯h
k k k k 2 k k
Using this in the ﬁrst Wolfe condition (4.81) gives,
1
dTh + hTH¯h ≤ c dTh
k k 2 k k 1 k k
and then introducing the inequality (4.87) yields
1
m (cid:107)h (cid:107)2 ≤ −(1−c )dTh
2 1 k 1 k k
into which dTh is substituted from (4.91),
k k
1
m (cid:107)h (cid:107)2 ≤ (1−c )(cid:107)d (cid:107)(cid:107)h (cid:107)cosϑ
1 k 1 k k k
2
As a result, the upper bound of (cid:107)h (cid:107) is
k
2(1−c )
1
(cid:107)h (cid:107) ≤ (cid:107)d (cid:107)cosϑ
k k k
m
1
or
(cid:107)h (cid:107) ≤ c (cid:107)d (cid:107)cosϑ (4.136)
k 4 k k
2(1−c )
1
where c ≡ > 0. From (4.135) and (4.136), (cid:107)h (cid:107) is in a range of
4 k
m
1
c (cid:107)d (cid:107)cosϑ ≤ (cid:107)h (cid:107) ≤ c (cid:107)d (cid:107)cosϑ
3 k k k 4 k k
98
Proof of Lemma 2. The proof is a review of Lemma (4.93) from [8]. From the ﬁrst
Wolfe condition (4.81),
F −F ≤ c α dTs
k+1 k 1 k k k
is substituted α s = h from (4.79),
k k k
F −F ≤ c dTh
k+1 k 1 k k
Introducing (4.91) yields,
F −F ≤ −c (cid:107)d (cid:107)(cid:107)h (cid:107)cosϑ (4.137)
k+1 k 1 k k k
and then substituting the lower bound of (cid:107)h (cid:107) from the inequality in (4.92) gives
k
F −F ≤ −c c (cid:107)d (cid:107)2cos2ϑ (4.138)
k+1 k 1 3 k k
Since the function F(θ) is convex on the level set D, then
F −F∗ ≤ dT(θ −θ∗)
k k k
≤ (cid:107)d (cid:107)(cid:107)θ −θ∗(cid:107) (4.139)
k k
At θ∗, H¯(θ∗) satisﬁes the secant equation (4.86),
g∗ = (cid:0)H¯(cid:1)(θ∗)(θ −θ∗) (4.140)
k k
Since the gradient d can be expressed as
k
d = H¯(θ −θ∗) (4.141)
k k
then transposing and multiplying (4.141) by (θ −θ∗) gives
k
dT(θ −θ∗) = (θ −θ∗)TH¯(θ −θ∗) (4.142)
k k k k
Equation (4.142) also satisﬁes (4.85), that is
m (cid:107)θ −θ∗(cid:107)2 ≤ (θ −θ∗)TH¯(θ −θ∗) ≤ m (cid:107)θ −θ∗(cid:107)2 (4.143)
1 k k k 2 k
99
Taking the lower bound of (4.143),
m (cid:107)θ −θ∗(cid:107)2 ≤ (θ −θ∗)Td (4.144)
1 k k k
the right hand side is expanded as
m (cid:107)θ −θ∗(cid:107)2 ≤ (cid:107)θ −θ∗(cid:107)(cid:107)d (cid:107)
1 k k k
Canceling (cid:107)θ −θ∗(cid:107) from both sides,
k
1
(cid:107)θ −θ∗(cid:107) ≤ (cid:107)d (cid:107) (4.145)
k k
m
1
and substituting (cid:107)θ −θ∗(cid:107) from (4.145) into (4.139) yields
k
(cid:107)d (cid:107)2 ≤ m (F −F∗) (4.146)
k 1 k
Substituting (cid:107)d (cid:107)2 from (4.146) and adding F −F∗ to both sides of (4.138) ﬁnally
k k
yields,
(cid:2) (cid:3)
F −F∗ ≤ 1−c c m cos2ϑ (F −F∗)
k+1 1 3 1 k k
Proof of Lemma 6. The quantity (cid:107)z∗(cid:107)2 can be described as
k
(cid:107)z∗(cid:107)2 = z∗Tz∗
k k k
Introducing (4.113) gives,
(cid:107)z∗(cid:107)2 = hTS¯S¯h
k k k
or
= hTS¯1/2S¯S¯1/2h (4.147)
k k
Denoting
´b ≡ S¯1/2h (4.148)
k k
100
where S¯1/2S¯1/2 = S¯ . Then substituting (4.148) into (4.147) gives
k
(cid:107)z∗(cid:107)2 =´bTS¯´b
k k k
(cid:107)z∗(cid:107)2
Since ´bTS¯´b satisﬁes (4.112), it also follows (4.114). Thus the upper bound of k
k k gTh
k k
can be calculated by substituting the upper bound of z∗Th from (4.114) and the
k k
lower bound of gTh from (4.87) as,
k k
(cid:107)z∗(cid:107)2 w (cid:107)h (cid:107)2
k ≤ 2 k
gTh m (cid:107)h (cid:107)2
k k 1 k
≤ w
3
w
2
where w = .
3
m
1
Proof of Lemma 7. Into
´
H h = −α d [4.117]
k k k k
substitute H´ = JTJ +Sˆ to give,
k k k k
Sˆ h = −(cid:0)α d +JTJ h (cid:1) (4.149)
k k k k k k k
and then
(cid:107)Sˆ h (cid:107) = (cid:107)α d +JTJ h (cid:107)
k k k k k k k
Using the triangle inequality for the right-hand side gives
(cid:107)Sˆ h (cid:107) ≤ α (cid:107)d (cid:107)+(cid:107)JTJ h (cid:107) (4.150)
k k k k k k k
ˆ
The lower bound of (cid:107)S h (cid:107) can be calculated from
k k
H´ = JTJ +Sˆ (4.151)
k k k k
Multiplying by h on both sides and rearranging the equation gives
k
Sˆ h = H´ h −(cid:0)JTJ (cid:1)h (4.152)
k k k k k k k
101
so
(cid:107)Sˆ h (cid:107) = (cid:107)H´ h −(cid:0)JTJ (cid:1)h (cid:107) (4.153)
k k k k k k k
According to the reverse triangle inequality the right-hand side of (4.153) is
(cid:12) (cid:12)
(cid:12)(cid:107)H´ h (cid:107)−(cid:107)(cid:0)JTJ (cid:1)h (cid:107)(cid:12) ≤ (cid:107)H´ h −(cid:0)JTJ (cid:1)h (cid:107) (4.154)
(cid:12) k k k k k (cid:12) k k k k k
Since (cid:0)JTJ (cid:1)h ≤ H´ h , then
k k k k k
(cid:107)H´ h (cid:107)−(cid:107)(cid:0)JTJ (cid:1)h (cid:107) ≤ (cid:107)H´ h −(cid:0)JTJ (cid:1)h (cid:107) (4.155)
k k k k k k k k k k
Substituting (4.155) into (4.153) gives
(cid:107)H´ h (cid:107)−(cid:107)(cid:0)JTJ (cid:1)h (cid:107) ≤ (cid:107)Sˆ h (cid:107) (4.156)
k k k k k k k
´
Replacing H h by −α d in (4.117) yields
k k k k
(cid:107)−α d (cid:107)−(cid:107)(cid:0)JTJ (cid:1)h (cid:107) ≤ (cid:107)Sˆ h (cid:107)
k k k k k k k
or
α (cid:107)d (cid:107)−(cid:107)(cid:0)JTJ (cid:1)h (cid:107) ≤ (cid:107)Sˆ h (cid:107) (4.157)
k k k k k k k
since α > 0. Combining (4.150) and (4.157) gives,
k
α (cid:107)d (cid:107)−(cid:107)(cid:0)JTJ (cid:1)h (cid:107) ≤ (cid:107)Sˆ h (cid:107) ≤ α (cid:107)d (cid:107)+(cid:107)JTJ h (cid:107) (4.158)
k k k k k k k k k k k k
Since J is positive deﬁnite then
k
(cid:113)
(cid:107)J (cid:107) = Tr(JTJ ) ≡ σ1/2 (4.159)
k F k k k
where σ > 0. Hence
k
(cid:107)JTJ (cid:107) = Tr(JTJ ) = σ (4.160)
k k F k k k
for all k. (cid:107)JTJ h (cid:107) satisﬁes the following inequality.
k k k
(cid:0) (cid:1)
(cid:107) JTJ h (cid:107) ≤ (cid:107)JTJ (cid:107) (cid:107)h (cid:107)
k k k k k F k
≤ σ (cid:107)h (cid:107) (4.161)
k k
102
Substituting (4.161) into (4.158) yields,
ˆ
α (cid:107)d (cid:107)−σ (cid:107)h (cid:107) ≤ (cid:107)S h (cid:107) ≤ α (cid:107)d (cid:107)+σ (cid:107)h (cid:107)
k k k k k k k k k k
Proof of Lemma 8. Since Sˆ is assumed to be positive, hTSˆ h > 0, then applying
k k k k
the matrix norms inequality gives
hTSˆ h ≤ (cid:107)Sˆ h (cid:107)(cid:107)h (cid:107) (4.162)
k k k k k k
(cid:107)Sˆ h (cid:107)2
k k
As a result, susbstituting (4.162) into the denominator of yields
hTSˆ h
k k k
(cid:107)Sˆ h (cid:107)2 (cid:107)Sˆ h (cid:107)2
k k k k
≤ (4.163)
(cid:107)Sˆ h (cid:107)(cid:107)h (cid:107) hTSˆ h
k k k k k k
ˆ
Canceling (cid:107)S h (cid:107) in the numerator and the denominator on the right-hand side of
k k
(4.163) gives
(cid:107)Sˆ h (cid:107) (cid:107)Sˆ h (cid:107)2
k k k k
≤ (4.164)
(cid:107)h (cid:107) hTSˆ h
k k k k
ˆ
The lower bound of (cid:107)S h (cid:107) in (4.124) is equivalent to
k k
ˆ
α (cid:107)d (cid:107)−σ (cid:107)h (cid:107) (cid:107)S h (cid:107)
k k k k k k
≤ (4.165)
(cid:107)h (cid:107) (cid:107)h (cid:107)
k k
From the inequality (4.92), (cid:107)d (cid:107) can be expressed as
k
(cid:107)h (cid:107)
k
≤ (cid:107)d (cid:107) (4.166)
k
c cosϑ
4 k
Substituting (4.166) into (4.165) yields
(cid:107)h (cid:107)
k
α −σ (cid:107)h (cid:107)
kc cosϑ k k (cid:107)Sˆ h (cid:107)
4 k ≤ k k
(cid:107)h (cid:107) (cid:107)h (cid:107)
k k
Factoring out (cid:107)h (cid:107) and canceling this term in the numerator and the denominator
k
gives
ˆ
α (cid:107)S h (cid:107)
k k k
−σ ≤ (4.167)
k
c cosϑ (cid:107)h (cid:107)
4 k k
103
From (4.164),
α (cid:107)Sˆ h (cid:107)2
k k k
−σ ≤
c cosϑ k hTSˆ h
4 k k k k
ˆ
Proof of Lemma 9. The determinant of S is
k+1
(cid:32) (cid:33)
(cid:16) (cid:17) z∗z∗T Sˆ h hTSˆ
det Sˆ = det Sˆ + k k − k k k k (4.168)
k+1 k gTh hTSˆ h
k k k k k
From Sylvester’s determinant theorem [31], it is stated that for any n×m matrix A,
m×n matrix B, and invertible n×n matrix X,
(cid:0) (cid:1)
det(X +AB) = det(X)det I +BX−1A (4.169)
where I is the n×n identity matrix. It is also true that for any column vector u and
row vector vT (each with n components),
(cid:0) (cid:1) (cid:0) (cid:1)
det X +uvT = det(X) 1+vTX−1u (4.170)
As a result, (4.168) is rearranged into the form
(cid:34) (cid:35)
(cid:16) (cid:17) (cid:18) z∗z∗T(cid:19) Sˆ h hTSˆ
det Sˆ = det Sˆ + k k − k k k k (4.171)
k+1 k gTh hTSˆ h
k k k k k
Analogous to (4.170)
(cid:18) z∗z∗T(cid:19)
X ≡ Sˆ + k k (4.172)
k gTh
k k
ˆ
S h
k k
u ≡ (4.173)
(cid:16) (cid:17)1/2
hTSˆ h
k k k
(cid:16) (cid:17)T
ˆ
S h
k k
vT ≡ (4.174)
(cid:16) (cid:17)1/2
hTSˆ h
k k k
104
So applying Sylvester’s determinant theorem (4.170) gives
(cid:34) (cid:35)
(cid:16) (cid:17) (cid:18) z∗z∗T(cid:19) Sˆ h hTSˆ
det Sˆ = det Sˆ + k k − k k k k
k+1 k gTh hTSˆ h
k k k k k
 (cid:16) (cid:17)T 
ˆ
(cid:18) z∗z∗T(cid:19) Skhk (cid:18) z∗z∗T(cid:19)−1 Sˆ h
= det Sˆ + k k 1− Sˆ + k k k k 
k gTh  (cid:16) (cid:17)1/2 k gTh (cid:16) (cid:17)1/2
k k hTSˆ h k k hTSˆ h
k k k k k k
(4.175)
The ﬁrst parentheses on the right-hand side of (4.175) is simpliﬁed by applying
Sylvester’s determinant theorem (4.170) as
(cid:32) (cid:33)
(cid:18) z∗z∗T(cid:19) z∗TSˆ−1z∗
det Sˆ + k k = det(Sˆ ) 1+ k k k (4.176)
k gTh k gTh
k k k k
Next the quantities inside the square bracket are simpliﬁed. In order to do so,
(cid:18) z∗z∗T(cid:19)−1
Sˆ + k k is required. This can be calculated using the Sherman-Morrison
k gTh
k k
formula for calculating the sum of an invertible matrix X and uvT (which is called the
dyadic product)whereuisacolumnvectorandvT isarowvectorand1+vTX−1u (cid:54)= 0.
The Sherman-Morrison formula [2, 68] states that
X−1uvTX−1
(cid:0)X +uvT(cid:1)−1 = X−1 − (4.177)
1+vTX−1u
(cid:18) z∗z∗T(cid:19)−1
Since Sˆ + k k is in a form analogous to (cid:0)X +uvT(cid:1)−1 where in this case
k gTh
k k
ˆ
X ≡ S
k
z∗
u ≡ k
(gTh )1/2
k k
z∗T
vT ≡ k
(gTh )1/2
k k
then applying the Sherman-Morrison formula gives
(cid:18) z∗z∗T(cid:19)−1 Sˆ−1z∗z∗TSˆ−1
Sˆ + k k = Sˆ−1 − k k k k
k gkThk k (gTh )1/2(cid:32)1+ z∗TkSˆk−1zk∗ (cid:33)(gTh )1/2
k k (gTh )1/2(gTh )1/2 k k
k k k k
105
which reduces to
(cid:18) z∗z∗T(cid:19)−1 Sˆ−1z∗z∗TSˆ−1
Sˆ + k k = Sˆ−1 − k k k k (4.178)
k gkThk k (cid:16)gkThk +z∗TkSˆk−1zk∗(cid:17)
(cid:18) z∗z∗T(cid:19)−1
Tosimplifythesquarebracketin(4.175)substituting Sˆ + k k from(4.178)
k gTh
k k
in the square bracket gives
 (cid:16) (cid:17)T 
ˆ
Skhk (cid:18) z∗z∗T(cid:19)−1 Sˆ h
1− Sˆ + k k k k 
 (cid:16) (cid:17)1/2 k gTh (cid:16) (cid:17)1/2
hTSˆ h k k hTSˆ h
k k k k k k
(cid:16) (cid:17)T  
ˆ
Skhk  Sˆ−1z∗z∗TSˆ−1  Sˆ h
= 1− Sˆ−1 − k k k k k k
(cid:16)hTkSˆkhk(cid:17)1/2  k (cid:16)gkThk +z∗TkSˆk−1zk∗(cid:17) (cid:16)hTkSˆkhk(cid:17)1/2
(cid:32) (cid:33)
hTSˆ Sˆ−1Sˆ h hTSˆ Sˆ−1z∗z∗TSˆ−1Sˆ h
= 1− k k k k k + k k k k k k k k
hTkSˆkhk (cid:16)gkThk +z∗TkSˆk−1zk∗(cid:17)(cid:16)hTkSˆkhk(cid:17)
(cid:32) (cid:33)
hTSˆ h hTz∗z∗Th
= 1− k k k + k k k k
hTkSˆkhk (cid:16)gkThk +z∗TkSˆk−1zk∗(cid:17)(cid:16)hTkSˆkhk(cid:17)
hTz∗z∗Th
= k k k k (4.179)
(cid:16) (cid:17)(cid:16) (cid:17)
gTh +z∗TSˆ−1z∗ hTSˆ h
k k k k k k k k
Substituting (4.176) and (4.179) into (4.175) gives
(cid:32) (cid:33)
z∗TSˆ−1z∗ hTz∗z∗Th
det(Sˆ ) = det(Sˆ ) 1+ k k k k k k k
k+1 k gkThk (cid:16)gkThk +z∗TkSˆk−1zk∗(cid:17)(cid:16)hTkSˆkhk(cid:17)
Expanding the second parentheses in the right-hand side of the equation gives,
(cid:32) (cid:33)
gTh +z∗TSˆ−1z∗ hTz∗z∗Th
det(Sˆ ) = det(Sˆ ) k k k k k k k k k
k+1 k gkThk (cid:16)gkThk +z∗TkSˆk−1zk∗(cid:17)(cid:16)hTkSˆkhk(cid:17)
hTz∗z∗Th
= det(Sˆ ) k k k k
k (cid:16) (cid:17)
(gTh ) hTSˆ h
k k k k k
(cid:0)z∗Th (cid:1)2
= det(Sˆ ) k k
k (cid:16) (cid:17)
(gTh ) hTSˆ h
k k k k k
which establishes (4.127).
106
ˆ
Proof of Lemma 10. First it is proved that Tr(S ) is bounded. From
k+1
ˆ
α (cid:107)S h (cid:107)
k k k
−σ ≤ [4.167]
k
c cosϑ (cid:107)h (cid:107)
4 k k
using the matrix norm inequality, the left-hand side of (4.167) is
ˆ ˆ
(cid:107)S h (cid:107) (cid:107)S (cid:107) (cid:107)h (cid:107)
k k k F k
≤
(cid:107)h (cid:107) (cid:107)h (cid:107)
k k
ˆ
≤ (cid:107)S (cid:107) (4.180)
k F
ˆ ˆ
In fact (cid:107)S (cid:107) in (4.180) can be related to Tr(S ). The trace norm of a matrix X
k F k
(in this case X ∈ Rn×n) is deﬁned as
n
(cid:88)
(cid:107)X(cid:107) ≡ |Λ | (4.181)
tr i
i=1
where |Λ | is the absolute value of the ith eigenvalue of X. In [65] it is proved that
i
(cid:112)
(cid:107)X(cid:107) ≤ (cid:107)X(cid:107) ≤ rank(X)(cid:107)X(cid:107) (4.182)
F tr F
ˆ
where (cid:107)·(cid:107) is the Frobenius norm of a matrix. Since S is assumed to be positive
F k
ˆ ˆ
deﬁnite, all its eigenvalues are positive. Thus (cid:107)S (cid:107) is simply Tr(S ). As a result,
k tr k
(4.180) becomes
ˆ
(cid:107)S h (cid:107)
k k ˆ ˆ
≤ (cid:107)S (cid:107) ≤ Tr(S ) (4.183)
k F k
(cid:107)h (cid:107)
k
The substitution of (4.183) into (4.167) yields
α
k ˆ
−σ ≤ Tr(S )
k k
c cosϑ
4 k
or,
α
k ˆ
≤ Tr(S )+σ (4.184)
k k
c cosϑ
4 k
From the trace inequality (4.126),
α
ˆ ˆ k
Tr(S ) ≤ Tr(S )+w +σ − [4.126]
k+1 k 3 k
c cosϑ
4 k
107
and substituting in (4.184) gives
(cid:16) (cid:17)
ˆ ˆ ˆ
Tr(S ) ≤ Tr(S )+w +σ − Tr(S )+σ
k+1 k 3 k k k
which is just
ˆ
Tr(S ) ≤ w (4.185)
k+1 3
ˆ
To prove Lemma 10 it is necessary to ﬁnd the lower bound of det(S ). From
k+1
Lemma 9,
(cid:0)z∗Th (cid:1)2
det(Sˆ ) = det(Sˆ ) k k [4.127]
k+1 k (cid:16) (cid:17)
(gTh ) hTSˆ h
k k k k k
The lower bound of det(Sˆ ) is established by taking the minimum value of z∗Th
k+1 k k
and the maximum values of gTh and hTSˆ h . The lower bound of z∗Th is
k k k k k k k
w (cid:107)h (cid:107)2 ≤ z∗Th [4.114]
1 k k k
and the upper bound of gTh from (4.87) gives
k k
gTh ≤ m (cid:107)h (cid:107)2 [4.87]
k k 2 k
The upper bound of hTSˆ h can be obtained by ﬁrst recalling
k k k
hTSˆ h ≤ (cid:107)Sˆ h (cid:107)(cid:107)h (cid:107) [4.162]
k k k k k k
ˆ
where the upper bound of (cid:107)S h (cid:107) is
k k
ˆ
(cid:107)S h (cid:107) ≤ α (cid:107)d (cid:107)+σ (cid:107)h (cid:107) [4.124]
k k k k k k
ˆ
Substituting the upper bound of (cid:107)S h (cid:107) into (4.162) yields
k k
hTSˆ h ≤ (α (cid:107)d (cid:107)+σ (cid:107)h (cid:107))(cid:107)h (cid:107) (4.186)
k k k k k k k k
Since (cid:107)d (cid:107) can be expressed as
k
(cid:107)h (cid:107)
k
≤ (cid:107)d (cid:107) [4.166]
k
c cosϑ
4 k
108
Substituting (4.166) (4.186) gives
(cid:18) (cid:19)
(cid:107)h (cid:107)
hTSˆ h ≤ α k +σ (cid:107)h (cid:107) (cid:107)h (cid:107)
k k k kc cosϑ k k k
4 k
or
(cid:107)h (cid:107)2
hTSˆ h ≤ α k +σ (cid:107)h (cid:107)2 (4.187)
k k k kc cosϑ k k
4 k
Finally substituting (4.87), (4.114), and (4.187) into (4.127) yields
w2(cid:107)h (cid:107)4
det(Sˆ ) 1 k ≤ det(Sˆ )
k (cid:18)α (cid:107)h (cid:107)2 (cid:19) k+1
m (cid:107)h (cid:107)2 k k +σ (cid:107)h (cid:107)2
2 k k k
c
4
which reduces to
m
ˆ 3 ˆ
det(S ) ≤ det(S ) (4.188)
k (cid:18)α (cid:19) k+1
k
+σ
k
c
4
w2
where m = 1.
3
m
2
ˆ ˆ
Using (4.188) to calculate det(S ) from det(S ) gives,
2 1
m
ˆ 3 ˆ
det(S ) ≤ det(S )
1 (cid:18)α (cid:19) 2
1
+σ
1
c
4
ˆ
A similar calculation can be done for det(S ),
3
m
ˆ 3 ˆ
det(S ) ≤ det(S )
2 (cid:18)α (cid:19) 3
2
+σ
2
c
4
ˆ
Substituting det(S ) to the above equation gives
2
  
ˆ  m3  m3  ˆ
det(S1)(cid:18)α (cid:19)(cid:18)α (cid:19) ≤ det(S3)
1 2
+σ +σ
1 2
c c
4 4
So for the k iteration,
 
k
(cid:89) m
det(Sˆ )  3  ≤ det(Sˆ ) (4.189)
1 αi  k+1
+σ
i=1 i
c
4
109
The geometric/arithmetic mean inequality [73] states that for n nonnegative num-
bers x ,x ,...,x
1 2 n
√ x +x +···+x
1 2 n
n x ·x ···x ≤
1 2 n
n
Since a determinant of a matrix is the product of all its eigenvalues, using the
geometric/arithmetic mean inequality yields
(cid:34) (cid:35)n
ˆ
Tr(S )
ˆ k+1
det(S ) ≤
k+1
n
ˆ
Substituting the inequality (4.185) for Tr(S ) yields,
k+1
(cid:104)w (cid:105)n
ˆ 3
det(S ) ≤ (4.190)
k+1
n
Substituting (4.189) into (4.190) yields
 
k
(cid:89) m (cid:104)w (cid:105)n
det(Sˆ )  3  ≤ 3
1 αi  n
+σ
i=1 i
c
4
The quantity m in the left-hand side can be factored out,
3
 
(cid:89)k 1 wn
(m )kdet(Sˆ )   ≤ 3
3 1 αi  nn
+σ
i=1 i
c
4
so rearranging gives
 
(cid:89)k 1 wn
  ≤ 3 (4.191)
αi +σ  nnmkdet(Sˆ )
i=1 i 3 1
c
4
Because the left hand side of (4.191) is lesser or equal to a constant, then its
reciprocal implies that there is a positive constant c such that
5
k (cid:18) (cid:19)
(cid:89) α
i
c ≤ +σ
5 i
c
4
i=1
for all k ≥ 1 since α , c , and σ are positive.
i 4 i
110
´
(cid:107)H h (cid:107)
k k
Proof of Lemma 11. Using the matrix norm inequality, is described as
(cid:107)h (cid:107)
k
´ ´
(cid:107)H h (cid:107) (cid:107)H (cid:107) (cid:107)h (cid:107)
k k k F k
≤
(cid:107)h (cid:107) (cid:107)h (cid:107)
k k
´
≤ (cid:107)H (cid:107) (4.192)
k F
´ ´
From (4.182) (cid:107)H (cid:107) in (4.192) relates to Tr(H ) as
k F k
(cid:114)
(cid:16) (cid:17)
´ ´ ´ ´
(cid:107)H(cid:107) ≤ (cid:107)H(cid:107) ≤ rank H (cid:107)H(cid:107) (4.193)
F tr F
´
In analogy to (4.183), (4.192) relates to Tr(H ) as
k
´
(cid:107)H h (cid:107)
k k ´ ´
≤ (cid:107)H (cid:107) ≤ Tr(H ) (4.194)
k k
(cid:107)h (cid:107)
k
From Lemma 4 the upper bound of α is
k
hTH´ h
α ≤ c k k k [4.99]
k 4 (cid:107)h (cid:107)2
k
then applying the matrix norm inequality gives
´
(cid:107)H h (cid:107)(cid:107)h (cid:107)
k k k
α ≤ c
k 4 (cid:107)h (cid:107)2
k
´
(cid:107)H h (cid:107)
k k
≤ c
4
(cid:107)h (cid:107)
k
Substituting (4.194) yields
´
α ≤ c Tr(H ) ≡ c (4.195)
k 4 k 6
where c is a constant. Thus the sum of α is
6 i
k k
(cid:88) (cid:88)
α ≤ c = kc
i 6 6
i=1 i=1
and rearanging gives
k
(cid:88) α
i
≤ c (4.196)
6
k
i=1
111
Applying the geometric/arithmetic mean inequality to the left side of (4.196),
(cid:32) (cid:33)k
k k
(cid:89) (cid:88) α
α ≤ i ≤ ck
i k 6
i=1 i=1
or
k
(cid:89)
α ≤ ck
i 6
i=1
4.6 Rate of Convergence of the MBFGS method
In this section the linear convergence analysis analogous to the treatment presented
in [8] for the linear convergence of the MBFGS method is presented. Byrd et al. [8]
applies Theorem 6.4 of Dennis and Mor´e [16] to conclude superlinear convergence of
the BFGS-QN approach if admissible α = 1 is employed for all suﬃciently large
k
k. Due to the fact that the MBFGS-QN method yields similar linear convergence
to the BFGS-QN approach, it is reasonably to expect that the MBFGS-QN method
analogously oﬀers superlinear convergence for all suﬃciently large k if admissible
α = 1 is applied.
k
The linear convergence analysis of the MBFGS-QN method can be induced from
(4.93) in Lemma 2 as
Lemma 12. There exists a constant 0 ≤ c < 1 such that
8
F −F∗ ≤ ck(F −F∗) (4.197)
k+1 8 1
for all suﬃciently large k.
Proof. Recall
α
ˆ ˆ k
0 < Tr(S ) ≤ Tr(S )+w +σ − [4.126]
k+1 k 3 k
c cosϑ
4 k
ˆ
Starting from Tr(S ), (4.126) can be expressed as
1
k k
(cid:88) 1 (cid:88) α
ˆ ˆ i
0 < Tr(S ) ≤ Tr(S )+w k + σ −
k+1 1 3 i
c cosϑ
4 i
i=1 i=1
112
As a result
k
(cid:88) α
i
≤ c k (4.198)
7
cosϑ
i
i=1
From the geometric/arithmetic mean equality, (4.198) can be rewritten as
k
(cid:89) α
i ≤ ck (4.199)
cosϑ 7
i
i=1
From Lemma 11, the upper bound of (cid:81)k α is
i=1 i
k
(cid:89)
α ≤ ck [4.129]
i 6
i=1
Then substituting (4.129) into (4.199) yields
(cid:18)c (cid:19)k (cid:89)k
6
≤ cosϑ (4.200)
i
c
7
i=1
Starting from the objective function F , (4.93) is expressed as
1
k
(cid:89)(cid:0) (cid:1)
F −F∗ ≤ 1−c m c cos2ϑ (F −F∗) (4.201)
k+1 1 1 3 i 1
i=1
Applying the geometric/arithmetic mean inequality gives
(cid:34) (cid:35)k
k
1 (cid:88)(cid:0) (cid:1)
F −F∗ ≤ 1−c m c cos2ϑ (F −F∗)
k+1 1 1 3 i 1
k
i=1
Using the geometric/arithmetic mean inequality again,
 (cid:32) (cid:33)1/kk
k
(cid:89)
Fk+1 −F∗ ≤ 1−c1m1c3 cos2ϑi  (F1 −F∗) (4.202)
i=1
Substituting in (4.200) yields
F −F∗ ≤ ck(F −F∗)
k+1 8 1
where
(cid:34) (cid:35)
(cid:18)c (cid:19)1/k
6
c = 1−c m c
8 1 1 3
c
7
113
Since the linear convergence analysis of the MBFGS-QN algorithm yields results
analogous to the BFGS-QN approach [8], it can be reasonably hypothesized that the
same reasoning and proof for the superlinear convergence presented in [8, 16, 28] can
be directly applied to the MBFGS-QN method.
In [8] Broyden’s class formula is proved to yield superlinear convergence if the
following additional assumption is applied,
Assumption 5. The Hessian matrix H is H¨older continuous at θ∗ in which there
exists nonnegative real constants p,L such that
(cid:107)H(θ)−H(θ∗)(cid:107) ≤ L(cid:107)θ−θ∗(cid:107)p (4.203)
for all θ in a neighborhood of θ∗
Hence, [8] proved in their Theorem 4.1 that if the BFGS-QN algorithm, including
Broyden’s class formula when κ ∈ [0,1), satisﬁes (4.81)-(4.82) and employs α = 1
k
whenever it is permissible, i.e., satisfying (4.81)-(4.82) when Assumption 1,2 and
(4.203) hold, it produces the sequence θ that q-superlinearly converges to θ∗. The
k
analysis in [8] further implies that
(cid:107)(Hˆ −H∗)h (cid:107)
k k
lim = 0 (4.204)
k→∞ (cid:107)hk(cid:107)
which is the proposition proved by Griewank and Toint [28]. Byrd et al. [8] used
Theorem 6.4 of Dennis and Mor´e [16] to conclude that α = 1 “is admissible for all
k
suﬃciently large k and that the rate of convergence is superlinear.”
Because the convergence analysis of the MBFGS-QN algorithm is analogously
derived and yields results similar to the BFGS-QN method, it is reasonably assumed
that the MBFGS-QN algorithm, which satisﬁes Assumptions 1, 2, 3, 4, and 5 as
well as the Wolfe conditions (4.81)-(4.82), is expected to generate the sequence θ
k
that superilearly converges to θ∗. Therefore, it is rational to hypothesize that the
proposition (4.204) proved by Griewank and Toint [28] can be directly implied and
114
the conclusion of Byrd et al. [8] using Theorem 6.4 of Dennis and Mor´e [16] can be
analogously applied to the MBFGS-QN algorithm. Consequently, it is hypothesized
that if the MBFGS-QN algorithm produces the sequence θ of which α = 1 is
k k
employed for suﬃciently large k, the rate of convergence is reasonably expected to
be superlinear. Since the proof of the superlinear convergence is too involved, it is
not included in this analysis. However, the details of aforementioned theorems can
be found in [16, 28].
4.7 Switching MBFGS-DB Algorithm
Although the developed algorithms are motivated to improve the performance of a
quasi-Gauss-Newton method on the large residual case, as the procedure proceeds the
residual S should ideally converge to zero or at least become relatively small for which
the quasi-Gauss-Newton method should perform well. Consequently, it is not always
ˆ ˆ
necessary to include S into the Hessian H . Due to the fact that all of the proposed
k k
methods (the approaches presented in Sections 4.4.1-4.4.3, NL2SOL in [17, 20], and
ˆ ˆ
the algorithm proposed in [25]) recursively update S from S , the approximation
k k−1
of Sˆ may not go to zero even if f and z∗ become zero. For this reason NL2SOL
k k k−1
[17, 20] sometimes applies the Gauss-Newton method for small ﬁnal residuals while
ˆ
using their novel algorithm for approximating S when the residual is large since a
k
quasi-Gauss-Newton method tends to work well for the zero- or small-residual case
ˆ
[17, 19]. It is suggested in [17, 20] to multiply a scaling factor ς to S before each
k−1
ˆ
update so that the approximated S accurately accommodates to the small- or zero-
k
residual case. This scaling method is inspired by direct modiﬁcation of the self-scaling
ˆ ˆ
technique presented in [51] so that the approximation of S is updated from ςS
k k−1
ˆ
rather than S . The scaling factor ς is calculated as
k−1
(cid:40) (cid:41)
z∗T h
ς = min k−1 k−1 ,1 (4.205)
hT Sˆ h
k−1 k−1 k−1
AsimilarideaisintroducedbyNazareth[48]asreviewedinSection4.2.1inwhicha
115
hybrid weighted average between the quasi-Newton and the Gauss-Newton directions
is proposed through controlling a weighting parameter φ as
(cid:104) (cid:105)
φ JTJ +(1−φ )Hˆ h = −JTf [4.16]
k k k k k k k k
where 0 ≤ φ ≤ 1 is adaptively chosen according to how well the Gauss-Newton
k
model can be trusted.
Furthermore, Nazareth [49] also recommended using a similar hybrid as in (4.16)
for the DGW Hessian approximation (the earlier development of NL2SOL) as
JTJ +(1−φ )S (4.206)
k k k k
where the update of S satisﬁes the following secant equation
k
S h = z∗
k k−1 k−1
z∗ = JTf −JT f
k−1 k k k−1 k
Although the details of this idea are not presented in [49], it is assumed that the
selection of φ is the same as mentioned in (4.16).
k
To have the improved capability of the proposed algorithms in the large-residual
caseyetattainingfastconvergenceofthequasi-GaussNewtonmethodwhentheresid-
ual becomes relatively small, a similar hybrid method to those presented in [48, 49] is
developed. This development is motivated by observations made during the compar-
ative simulations between the DGN-PBM algorithm in Chapter 3 and the algorithms
in Section 4.4.1-4.4.3. It is observed that the proposed algorithms, especially the
MBFGS algorithm, yield signiﬁcant improvement over the DGN-PBM algorithm by
oﬀering faster convergence if the initial error is substantial. Furthermore, the trajec-
tory of the EE motion moving from its initial conﬁguration to reach the steady-state
tracking conﬁguration is more direct compared to the quasi-Gauss-Newton method
(theDGN-PBMalgorithm). However, theRMStrackingerrorduringthesteadystate
is signiﬁcant. If the initial error between the EE initial conﬁguration and the target
116
is small, the DGN-PBM algorithm generates steps that rapidly converge to the target
with higher reliability and outperforms the MBFGS method, which in the worse case
diverges. Moreover, during steady-state tracking the DGN-PBM algorithm always
performs better than the MBFGS algorithm.
InstabilityoccursinsimulationswhenutilizingtheMBFGSalgorithmforthezero-
or small-residual problem may be explained through the fact that the approximation
ˆ
of S is included into the Hessian even though the actual residual term is zero or
k
ˆ ˆ
become small. Because the update residual S is recursively calculated from S , it
k k−1
maynotgotozeroeveniff becomeszero. Furthermore, sincetheuncalibratedvisual
k
servoing application assumes no knowledge about the robot and camera models, the
ˆ ˆ
approximation of the residual S is done using the approximated Jacobian J which is
obtained from the dynamic Broyden estimator. Hence the estimated Jacobian does
not represent the actual Jacobian matrix but in some sense only a partial Jacobian
since it is only able to update the Jacobian in the “direction” of the trajectory. Thus
ˆ
the updated residual S only partially represents the actual residual S term. As a
result, redundant inclusion of the residual term may signiﬁcantly deteriorate tracking
performance in the small image error norm case.
These observedresultsagreewithDennis etal. [17] notingthattheGauss-Newton
method performs better than the inclusion of the residual approximation into the
ˆ
Hessian due to inadequate capability of the S update to converge to zero for the
k
ˆ
zero- or small-residual problems. Thus the approximation of the residual S should
k
ˆ
only be employed only when necessary, i.e., for the large residual case where the S
k
is signiﬁcant. As a result, a hybrid between the DGN-PBM algorithm and a residual
ˆ
approximationalgorithm(forexample,theMBFGSmethodisusedtoapproximateS
k
and is integrated into the full-Newton method) is developed. Then the approximated
´
H becomes
k
H´ = JˆTJˆ +ϕ Sˆ (4.207)
s,k k k k k
117
where ϕ is the switching parameter and is either zero or one. This method is referred
k
as the switching method. Unlike (4.16) and (4.206) in which 0 ≤ φ ≤ 1 or S can be
k k
ˆ
scaled as proposed in [17, 19], the switching algorithm either includes or excludes S .
k
A proper switching criterion for determining ϕ is crucial to the performance of
k
these algorithms. An inappropriate value can lead to tracking failure. For example,
if the criterion is too small, more steps are calculated using the MBFGS algorithm
though the residual is small at the time. On the other hand, if the criterion is too
great, inadequate steps from the MBFGS algorithm may be generated so slower or
evenunsuccessfultrackingmayoccur. Sincetheobjectiveofthedevelopedalgorithms
is to calculate the commanded robot joint angles θ for large residual tracking case,
k
the initial image error is assumed to be maximum, the switching criterion sw is
crit
chosen to be a speciﬁed percentage υ of the initial error norm (cid:107)f (cid:107) as
1
sw = υ(cid:107)f (cid:107) (4.208)
crit 1
Thentheswitchingparameterϕ isdeterminedwiththefollowingcondition,
k
if (cid:107)f (cid:107) < υ(cid:107)f (cid:107) then
k 1
ϕ = 0
k
else
ϕ = 1
k
end if
In this study υ is heuristically selected in which the eﬀect of the switching crite-
ria sw is discussed and compared to other hybrid methods including the scaling
crit
method in [17, 19] and the hybrid algorithms in [49] in Chapter 6.
ˆ
WhentheMBFGSalgorithmisutilizedtoapproximateS intheswitchingmethod,
k
this algorithm is referred as the switching MBFGS-DB algorithm and it is summa-
rized as shown in the pseudo-code in Figure 4.5. In fact, the DBFGS and DFN-BFGS
algorithms are similarly implemented into switching schemes as well and are referred
118
to as the switching DBFGS-DB and the switching DFN-BFGS-DB algorithms re-
spectively. Tracking performance of each switching algorithm is then evaluated and
discussed in Chapter 6.
4.8 Summary
Since the major disadvantage of the DBM-RLS and the DGN-PBM algorithms pre-
sented in Chapter 3 are their application to the zero- or small-residual cases, various
algorithms are presented in this chapter for solving the large-residual visual servoing
problem. It appears in [25] that an algorithm implementing NL2SOL [17, 20] with
a trust region method and the LMA shows an improvement over the quasi-Gauss
Newton method when dealing with the large-residual problem. However, this algo-
rithm is mainly developed for static target tracking in an eye-to-hand conﬁguration,
yet an algorithm for moving target tracking in an eye-in-hand conﬁguration for the
large-residual cases does not seem to have appeared in literature. Inspired by [25],
three novel algorithms are proposed in this chapter:
1. Approximation of the whole Hessian H using the DBFGS update
k
The DBFGS update is used to approximate H
k−1
g∗ g∗ T Hˆ h hT Hˆ
Hˆ = Hˆ + k−1 k−1 − k−1 k−1 k−1 k−1 [4.59]
k k−1 g∗ Th hT Hˆ h
k−1 k−1 k−1 k−1 k−1
where
(cid:18) (cid:19) (cid:18) (cid:19)
∂f ∂f
g∗ = JˆT f + kh −JˆT f + k−1h
k−1 k k ∂t t k−1 k−1 ∂t t
h = θ −θ
k−1 k k−1
Then
(cid:18) (cid:19)
(cid:16) (cid:17)−1 ∂f (t)
θ = θ − Hˆ JˆT f + k h
k+1 k k k k ∂t t
2. Approximation of the residual S using the BFGS update
k
ˆ
The BFGS method is used to approximate S ,
k
z∗ z∗ T Sˆ h hT Sˆ
Sˆ = Sˆ + k−1 k−1 − k−1 k−1 k−1 k−1 [4.64]
k k−1 z∗ Th hT Sˆ h
k−1 k−1 k−1 k−1 k−1
119
Pseudo-code: The Switching MBFGS-DB Algorithm
Given: Rn → Rm ; θ ,θ ∈ Rn ; Jˆ ∈ Rm×n,P ∈ Rn×n,λ ∈ (0,1)
0 1 0 0
ˆ
Initialize: J , θ , θ , H and P
0 0 1 0 0
for k = 1,... do
ˆ
Calculate: J using a Jacobian estimation in the DGN-PBM algorithm [59]
k
∆f = f −f ; h = θ −θ
k k−1 k−1 k k−1
(cid:20) (cid:21)
(θ −θ )
h˜ = k k−1
(t −t )
k k−1
(cid:104) (cid:16) (cid:17) (cid:105)
J˜ = Jˆ fˆ
k−1 k−1 t
k−1
(cid:16) (cid:17)−1(cid:16) (cid:17)
J˜ = J˜ + λ+h˜TP˜ h˜ ∆f −J˜ h˜ h˜TP˜
k k−1 k−1 k−1 k−1
(cid:18) (cid:19)
1 (cid:16) (cid:17)−1(cid:16) (cid:17)
P˜ = P˜ − λ+h˜TP˜ h˜ P˜ h˜h˜TP˜
k k−1 k−1 k−1 k−1
λ
Calculate the switching parameter ϕ
k
if (cid:107)f (cid:107) < υ(cid:107)f (cid:107) then
k 1
ϕ = 0
k
else
ϕ = 1
k
ˆ
Update the residual S
k
z∗ z∗ T Sˆ h hT Sˆ
Sˆ = Sˆ + k−1 k−1 − k−1 k−1 k−1 k−1
k k−1 g Th hT Sˆ h
k−1 k−1 k−1 k−1 k−1
z∗ = JˆTf −JˆT f ; g = JˆTf −JˆT f
k−1 k k k−1 k k−1 k k k−1 k−1
end if
´
Calculate H
s,k
H´ = JˆTJˆ +ϕ Sˆ
k k k k k
Calculate: θ using the dynamic full quasi-Newton method
k+1
(cid:18) (cid:19)
(cid:16) (cid:17)−1 ∂f (t)
θ = θ − H´ JˆT f + k h
k+1 k k k k ∂t t
end for
Figure 4.5: Pseudo-code for the switching MBFGS-DB algorithm
120
where
z∗ = JˆTf −JˆT f
k−1 k k k−1 k
ˆ ´
S from (4.64) is used to approximate H as
k k
H´ = JˆTJˆ +Sˆ
k k k k
Then the dynamic full quasi-Newton method is utilized to estimate θ as
k+1
(cid:18) (cid:19)
(cid:16) (cid:17)−1 ∂f (t)
θ = θ − H´ JˆT f + k h
k+1 k k k k ∂t t
This algorithm is called the dynamic full Newton method with BFGS algorithm or
DFN-BFGS.
3. Approximation of the residual S using the modiﬁed BFGS update
k
The MBFGS method is used for estimating the residual S ,
k
z∗ z∗ T Sˆ h hT Sˆ
Sˆ = Sˆ + k−1 k−1 − k−1 k−1 k−1 k−1 [4.67]
k k−1 gT h hT Sˆ h
k−1 k−1 k−1 k−1 k−1
where
z∗ = JˆTf −JˆT f
k−1 k k k−1 k
g = JˆTf −JˆT f
k−1 k k k−1 k−1
ˆ ´
S from (4.67) is used to approximate H as
k k
H´ = JˆTJˆ +Sˆ
k k k k
Then θ is given by,
k+1
(cid:18) (cid:19)
(cid:16) (cid:17)−1 ∂f (t)
θ = θ − H´ JˆT f + k h
k+1 k k k k ∂t t
For the case that Sˆ is relatively large compared to JTJ , the MBFGS method is
k k k
ˆ
the same as using the unmodiﬁed BFGS method (4.64) for approximating S .
k
121
For all algorithms the Jacobian is estimated using the DGN-PBM algorithm as
∆f = f −f
k k−1
h = θ −θ
k−1 k k−1
h = t −t
t k k−1
 
(θ −θ )
h˜ =  k k−1 
 
(t −t )
k k−1
(cid:20) (cid:21)
(cid:16) (cid:17)
J˜ = Jˆ fˆ
k−1 k−1 t
k−1
(cid:16) (cid:17)−1(cid:16) (cid:17)
J˜ = J˜ + λ+h˜TP˜ h˜ ∆f −J˜ h˜ h˜TP˜
k k−1 k−1 k−1 k−1
(cid:18) (cid:19)
1 (cid:16) (cid:17)−1(cid:16) (cid:17)
P˜ = P˜ − λ+h˜TP˜ h˜ P˜ h˜h˜TP˜
k k−1 k−1 k−1 k−1
λ
Since the ﬁrst and the second algorithms use the BFGS method, which provides
superlinear convergence under reasonable assumptions, a convergence proof is only
required to validate the MBFGS algorithm. Consequently, the convergence analysis
of the MBFGS method is studied in analogy to the convergence analysis of Broyden’s
class formula (including the BFGS method) presented in [8]. As a result, the novel
MBFGS algorithm assumably yields superlinear convergence if the speciﬁed assump-
tions hold. Finally the criteria for switching between the MBFGS algorithm and
the DGN-PBM algorithm is discussed to optimally handle the large-residual problem
eﬀectively. The summary of the switching MBFGS-DB algorithm is shown in the
pseudo-code in Figure 4.5.
122
CHAPTER V
DYNAMIC ADAPTIVE FORGETTING FACTOR
ALGORITHM
Since the switching MBFGS-DB algorithm is developed from the the dynamic-Gauss-
Newton algorithms with partitioning for Broyden’s method (DGN-PBM), it inherits
the same diﬃculties presented in the DGN-PBM algorithm including, 1) the selection
of an optimal forgetting factor λ and, 2) a proper action dealing with a singular or ill-
conditionedHessianmatrixapproximation. Thischapterdiscussesvariousapproaches
for adaptively selecting an appropriate forgetting factor at each iteration. For the
singular Hessian problem the Levenberg-Marquardt algorithm (LMA) is investigated
in Chapter 6.
The organization of this chapter is as follow. Section 5.1 brieﬂy reviews the
eﬀect of the forgetting factor λ on the DGN-PBM algorithm presented in previous
studies. Due to the fact that variable forgetting factor (VFF) algorithms are mostly
developed to improve the performance of the RLS algorithm, Section 5.2 presents
fundamental background for the RLS algorithm. Then various VFF algorithms that
have been widely studied in RLS adaptive ﬁltering are discussed in Section 5.3. Since
the existing VFF algorithms propose complex mathematic models that require a
number of parameters to be selected by the user, a novel adaptive forgetting factor
approach called the dynamic adaptive forgetting factor (DAFF) method is developed
in Section 5.4. Finally concluding remarks for this chapter are presented in Section
5.5.
123
5.1 Introduction
Although the dynamic Gauss-Newton algorithms, the DBM-RLS and the DGN-PBM
algorithms presented in Chapter 3, oﬀer eﬃcient approaches to recursively estimate
ˆ
the Jacobian J from the previous information, these algorithms utilize the recursive
k
least-squares (RLS) algorithm in which the performance is dependent on the expo-
nential weighting factor or forgetting factor λ [53]. The kth iteration of the Jacobian
ˆ
J is estimated as
k
(cid:18) (cid:19)
∂f (t)
∆f −Jˆ h − k h hTP
k−1 θ ∂t t θ k−1
ˆ ˆ
J = J +
k k−1 λ+hTP h
θ k−1 θ
1 (cid:18) P h hTP (cid:19)
P = P − k−1 θ θ k−1
k λ k−1 λ+hTP h
θ k−1 θ
where
∆f = f −f
k k−1
h = θ −θ
θ k k−1
and P is a full rank weighting matrix. The forgetting factor λ has the range
0 < λ ≤ 1
The inverse of 1−λ roughly represents the memory of the RLS-based algorithm,
1
n = (5.1)
memory
1−λ
ˆ
When λ = 1 the memory is inﬁnite and J is estimated by equally averaging all past
k
information so the RLS algorithm becomes the ordinary least-squares algorithm. If
ˆ
λ < 1, old data is deweighted so that the calculation of J relies more on recent data
k
and forgets older data.
AlthoughtheRLSalgorithmwithaconstantforgettingfactorhasfastconvergence
withasmallmeansquareerror(MSE)instationaryenvironments[41],itdoesnotoﬀer
124
the optimal performance in time-varying environments. There exists a compromise
between applying small and large values of the forgetting factor λ in a RLS-based
algorithm. A small value of λ results in large steady-state error but improves tracking
while a greater value of λ yields slower convergence but provides lower steady-state
error and good stability [53].
The eﬀect of the forgetting factor λ on the dynamic Gauss-Newton algorithms
was brieﬂy investigated in [57]. Simulation results show that a lower λ improves
convergence time but hurts the steady-state tracking performance. In contrast, a
higher λ enhances steady-state tracking capability but increase diﬃculties in target
acquisition. A switching scheme that utilizes a lower λ when the image error norm is
relatively large and then switches to a higher λ when the image error norm is lower
than a certain criterion provides improved performance of the DGN-PBM algorithm
for both transient and steady-state tracking. However, [57] only alternates λ between
two constants, i.e., low and high values of λ that need to be selected.
In an adaptive ﬁltering context an algorithm that automatically tunes the forget-
ting factor λ according to the squared error is known as a variable forgetting factor
or VFF algorithm. Various studies such as [55, 71, 41] propose diﬀerent schemes for
varying λ with respect to the corresponding squared error demonstrate diverse levels
of improvement over a constant λ algorithm. Due to the fact that a great number
of VFF algorithms are variants of the RLS algorithm, it is appropriate to brieﬂy re-
view the classical RLS algorithm used in an adaptive ﬁltering context to establish a
fundamental understanding of the VFF developments in the next section.
5.2 RLS Adaptive Filters Overview
The RLS algorithm is an iterative least-squares scheme that recursively calculates an
updated estimation of a model as new data arrives. The RLS algorithm presented
in this section reviews classical RLS adaptive ﬁlters fundamentals discussed in [32].
125
The cost function (cid:15) to be minimized is deﬁned as
n
(cid:88)
(cid:15)(n) = λn−i|e(i)|2 (5.2)
i=1
where n is number of observable data, (cid:15)(n) denotes the cost function (cid:15) at incremental
time n, and e(i) is deﬁned as
e(i) = d(i)−y(i) (5.3)
where d(i) is the desired signal and y(i) is the output signal obtained from a transver-
sal ﬁlter,
y(i) = wH(n)u(i) (5.4)
where w(n) is the weighting vector and u(i) is the signal input vector. To be consis-
tent with adaptive ﬁltering literature in which the signal inputs and the weights are
assumed to be complex valued [32], variables used in this section are complex number
and the superscript H in (5.4) is referred to as Hermitian transposition. Both vectors
contain the M most recent data of w(n) and u(n) respectively so at time i the input
signal u(i) is deﬁned as
u(i) = [u(i),u(i−1),...,u(i−M +1)]T
and at incremental time n the weight vector w(n) is deﬁned as
w(n) = [w (n),w (n),...,w (n)]T
0 1 M−1
During the observation interval 1 ≤ i ≤ n the transversal ﬁlter contains a ﬁxed length
of data n. An example of a transversal ﬁlter is shown in Figure 5.1.
Substituting (5.4) into (5.3) gives
e(i) = d(i)−wH(n)u(i) (5.5)
Theoptimalvalueofw(n)forwhichthecostfunction(cid:15)in(5.2)isminimizedisdeﬁned
as
Φ(n)w(n) = z(n) (5.6)
126
Figure 5.1: Transversal ﬁlter [32].
This equation is referred as the normal equation [32] where Φ(n) is the M × M
correlation matrix of the signal input u(i) which is deﬁned as
n
(cid:88)
Φ(n) = λn−iu(i)uH(i) (5.7)
i=1
and z(n) is the M ×1 cross-correlation vector that relates the signal inputs u(i) to
the desired signal d(i) as
n
(cid:88)
z(n) = λn−iu(i)d#(i) (5.8)
i=1
where # denotes complex conjugation.
From [32] the correlation matrix Φ can be recursively updated as
Φ(n) = λΦ(n−1)+u(n)uH(n) (5.9)
where Φ(n − 1) is the previous correlation matrix Φ at incremental time n − 1.
Similarly, the cross-correlation vector z(n) can be updated as
z(n) = λz(n−1)+u(n)d#(n) (5.10)
In order to solve (5.6) for w(n) it is required to invert Φ. The correlation matrix
Φ is assumed to be positive deﬁnite and its inverse is deﬁned as
P(n) ≡ Φ−1(n) (5.11)
= λ−1P(n−1)−λ−1k(n)uH(n)P(n−1) (5.12)
127
where P(n) is known as the inverse correlation matrix [32] and k(n) is the gain vector
or the Kalman gain vector [41] that is given recursively as
P(n−1)u(n)
k(n) = (5.13)
λ+uH(n)P(n−1)u(n)
Rearranging (5.13) yields
k(n) = λ−1P(n−1)u(n)−λ−1k(n)uH(n)P(n−1)u(n)
or
(cid:2) (cid:3)
k(n) = λ−1P(n−1)−λ−1k(n)uH(n)P(n−1) u(n)
= P(n)u(n) (5.14)
Rearranging (5.6) gives
w(n) = P(n)z(n) (5.15)
Substituting (5.10) for z(n) into (5.15) yields
w(n) = λP(n)z(n−1)+P(n)u(n)d#(n) (5.16)
Then substituting (5.12) for only the ﬁrst P(n) term in the right-hand side of (5.16)
gives
w(n) = w(n−1)−k(n)uH(n)w(n−1)+P(n)u(n)d#(n) (5.17)
Using k(n) = P(n)u(n) from (5.17) and rearranging yields the recursive update of
the weight vector w(n) as
w(n) = w(n−1)+k(n)ξ#(n) (5.18)
where
ξ(n) = d(n)−uH(n)w#(n−1)
128
Pseudo-code: The RLS Algorithm
Initialize: P(0) = δ−1I, δ =small positive constant, and w(0) = 0
for each instant time n = 1,... do
P(n−1)u(n)
k(n) =
λ+uH(n)P(n−1)u(n)
ξ(n) = d(n)−wH(n−1)u(n)
w(n) = w(n−1)+k(n)ξ#(n)
1
(cid:2) (cid:3)
P = P(n−1)−k(n)uH(n)P(n−1)
k
λ
e(n) = d(n)−wH(n)u(n)
end for
Figure 5.2: A pseudo-code for the RLS algorithm [32].
or
ξ(n) = d(n)−wH(n−1)u(n) (5.19)
ξ(n) is referred as the a priori estimation error [32] since its value is calculated from
thepreviousleast-squaresestimationoftheweightvectorwH(n−1)u(n)attimen−1.
Then the a posteriori estimation error is computed as
e(n) = d(n)−wH(n)u(n) (5.20)
The summary of the RLS algorithm is shown in Figure 5.2.
5.3 Variable Forgetting Factor (VFF) Algorithms in Adap-
tive Filtering
Adaptive or variable forgetting factor (VFF) schemes are developed to adaptively
tune the optimal value of λ in each iteration of RLS algorithms and are widely used
in adaptive ﬁlters. Due to a great number of studies for VFF algorithms only the
three most often mentioned algorithms are reviewed in this section:
129
1. RLS Algorithm with Adaptive Memory [32]
2. Gradient-Based VFF RLS Algorithm (GVFF-RLS) [41]
3. Gauss-Newton VFF RLS Algorithm (GN-VFF-RLS) [71]
These algorithms require selection of various constants determined by the user.
The eﬀect of these parameter values on each algorithm performance is investigated
in Section 6.5.1.
5.3.1 RLS Algorithm with Adaptive Memory
In [32] it is suggested to select the forgetting factor λ so that the gradient of the cost
function with respect to λ is zero. In this case the cost function is deﬁned as
1
Q(n) = E(cid:2)|ξ(n)|2(cid:3) (5.21)
2
where E[·] is the expected value of (·) and the a priori estimation error ξ is
k
ξ(n) = d(n)−wH(n−1)u(n) [5.19]
In order to ﬁnd a proper value of λ that optimizes (5.21), [32] takes the partial
derivative of (5.21) with respect to λ, denoted as ∇ (n), to give
λ
∂Q(n)
∇ (n) ≡
λ
∂λ
1 (cid:20)∂ξ(n) ξ#(n) (cid:21)
= E ξ#(n)+ ξ(n) (5.22)
2 ∂λ ∂λ
1
(cid:2) (cid:3)
= − E ψH(n−1)u(n)ξ#(n)+uH(n)ψ(n−1)ξ(n)
2
where
∂w(n)
ψ(n) =
∂λ
(cid:2) (cid:3)
= I −k(n)uH(n) ψ(n−1)+S(n)u(n)ξ#(n) (5.23)
130
and S(n) is the partial derivative of P(n) with respect to λ and is deﬁned as
∂P(n)
S(n) =
∂λ
1 1 1
(cid:2) (cid:3) (cid:2) (cid:3)
= I −k(n)uH(n) S(n−1) I −u(n)kH(n) + k(n)kH(n)− P(n)
λ λ λ
(5.24)
Then the adaptive exponential forgetting factor λ(n) can be recursively computed
as
∂Q(n)
λ(n) = λ(n−1)−η (5.25)
1
∂λ
= (cid:8)λ(n−1)+η Re(cid:2)ψH(n−1)u(n)ξ#(n)(cid:3)(cid:9)λ+ (5.26)
1 λ−
whereη isasmallpositiveparameterandisreferredtoasthelearning-rate parameter
1
in [32, 29]. However, the detail deﬁnition of this parameter is not presented in either
reference. The forgetting factor λ(n) is truncated with λ and λ indicating the
+ −
allowable range of the forgetting factor λ(n). The maximum forgetting factor λ
+
could be close to unity while the minimum forgetting factor λ may be obtained
−
from experiment. This VFF method is referred as the RLS algorithm with adaptive
memory in [32] and its summary is presented in the pseudo code in Figure 5.3.
5.3.2 Gradient-Based VFF RLS Algorithm (GVFF-RLS)
In [70, 41] the gradient-based VFF RLS algorithm or GVFF-RLS is presented. The
forgetting factor λ(n) is computed based on the gradient of the MSE instead of the
gradient of squared error as in (5.22). This study presents an improved mean square
error analyses where the gradient of the new MSE equation is formulated so that
its value becomes positive if the error is large and is negative if the error reaches
steady state. The forgetting factor λ(n) is then recursively computed by minimizing
the gradient of the dynamic MSE equation resulting in improved performance of fast
tracking with small MSE for a variety of signal-to-noise ratios (SNRs).
131
Pseudo-code: The RLS Algorithm with Adaptive Memory
Initialize: P(0), w(0), λ(0), S(0), ψ(0), and η is a small positive constant
1
for each instant time n = 1,... do
P(n−1)u(n)
k(n) =
λ(n−1)+uH(n)P(n−1)u(n)
ξ(n) = d(n)−wH(n−1)u(n)
w(n) = w(n−1)+k(n)ξ#(n)
1
(cid:2) (cid:3)
P(n) = P(n−1)−k(n)uH(n)P(n−1)
λ(n−1)
λ(n) = (cid:8)λ(n−1)+η Re(cid:2)ψH(n−1)u(n)ξ#(n)(cid:3)(cid:9)λ+
1 λ−
1
(cid:2) (cid:3) (cid:2) (cid:3)
S(n) = I −k(n)uH(n) S(n−1) I −u(n)kH(n)
λ(n)
1 1
+ k(n)kH(n)− P(n)
λ(n) λ(n)
ψ(n) = I −k(n)uH(n)ψ(n−1)+S(n)u(n)ξ#(n)
end for
Figure 5.3: A pseudo-code for the RLS algorithm with adaptive memory [32].
The RLS algorithm used in [41] is referred as the time-variable error weighting
RLS or TWRLS algorithm in which the cost function is deﬁned as
n
(cid:88)λn−i(n)(cid:2)d(i)−wT(n)u(i)(cid:3)2 (5.27)
i=0
The update of the weight vector w(n) and the error signal e(n) are
w(n+1) = w(n)+k(n)e(n) (5.28)
e(n) = d(n)−wT(n)u(n) (5.29)
And the desired signal d(n) is described as
d(n) = wT(n)u(n)+χ(n) (5.30)
0
132
where w is the desired weight vector and χ is a Gaussian measurement noise with
0
zero mean and variance σ2. In [41] the desired weight vector w(n) is assumably time-
χ
varying and is perturbed by a random vector g(n). The update of the consecutive
desired weight vector w (n+1) is
0
w (n+1) = w (n)+g(n) (5.31)
0 0
where g(n) is assumed to be independent Gaussian vector with zero mean and its
covariance matrix is denoted as G. This study also assumes that u(n),χ(n),g(n) are
mutually independent.
The correlation matrix Φ(n) is deﬁned as
n
(cid:88)
Φ(n) = λn−iu(i)uT(i)+λn(n)νI (5.32)
i=0
where ν is referred as the initial value in [41] with no further explanation. However,
similar formulation (5.32) appears in [32] where ν is a positive real number called the
regularization parameter, which is added to avoid singularity of Φ(n). The Kalman
gain k(n) and the inverse of the correlation matrix P(n) are similarly formulated as
in the RLS algorithm with adaptive memory [32] (Figure 5.3),
P(n−1)u(n)
k(n) =
λ(n−1)+uH(n)P(n−1)u(n)
1
(cid:2) (cid:3)
P(n) = P(n−1)−k(n)uH(n)P(n−1)
λ(n−1)
The novelty of this algorithm is attributed to an improved MSE analysis in which
the MSE σ2(n) is expressed as a sum of the variance of the measurement noise σ2
e χ
and the mean square term σ2 (n), known as the excess mean square error or EMSE,
ex
(cid:2) (cid:3)
σ2(n) = E e2(n)
e
= σ2 +σ2 (n) (5.33)
χ ex
where σ2 is the MSE caused by the weight errors w(n)−w (n). The equation of the
ex 0
MSE σ2(n+1) is
e
σ2(n+1) = α σ2(n)+h σ2(n+1)+Tr{R G} (5.34)
e n e n χ uu
133
where TR{·} is the matrix trace operation and R is the correlation matrix of the
uu
data vector u(n). The coeﬃcients α and h are deﬁned as
n n
2[(M +1)ρ˜ +ρ2]−(M +2)ρ
α = 1− n n n (5.35)
n ρ [(M +1)ρ˜ +ρ2]
n n n
2 2
h = − (5.36)
n ρ [(M +1)ρ˜ +ρ2]
n n n
where
ρ = 1+λ(n−1)ρ
n n−1
ρ˜ = 1+λ2(n−1)ρ˜
n n−1
Using the dynamic equation of the MSE (5.34) the GVFF algorithm is developed
to optimally adjust λ(n) so that the gradient of the MSE σ2(n) with respect to the
e
forgetting factor λ is minimized. The gradient of σ2(n) with respect to λ is
e
∂σ2(n+1) ∂σ2(n) ∂α ∂h
e = α e + nσ2(n)+ nσ2 (5.37)
∂λ n ∂λ ∂λ e ∂λ χ
∂α ∂h
n n
where and are deﬁned as
∂λ ∂λ
(cid:20) (cid:21)
∂α 2 ∂ρ M +2 ∂ρ˜ ∂ρ
n n n n
= − × (M +1) +2ρ (5.38)
∂λ ρ2 ∂λ [(M +1)ρ˜ +ρ2]2 ∂λ n ∂λ
n n n
(cid:20) (cid:21)
∂h 2 ∂ρ 2 ∂ρ˜ ∂ρ
n n n n
= − − × (M +1) +2ρ (5.39)
∂λ ρ2 ∂λ [(M +1)ρ˜ +ρ2]2 ∂λ n ∂λ
n n n
where
∂ρ
n
= ρ
n−1
∂λ
∂ρ˜
n
= 2λ(n−1)ρ˜
n−1
∂λ
In practice, the MSE σ2(n) can be estimated from e2(n) [41] as
e
σ2(n) = βσ2(n−1)+(1−β)e2(n) (5.40)
e e
where β is a positive constant selected by the user. The variance of the measurement
noise σ2 in (5.37) is calculated from σ2(n) as
χ e
σ2(n) = κσ2(n−1)+(1−κ)e2(n) (5.41)
χ χ
134
where κ > β is also a positive constant selected by the user. Using (5.37) an update
of forgetting factor λ(n) is proposed in [41] as
(cid:20) µ ∂σ2(n+1)(cid:21)λ⊕
λ(n) = λ(n−1)− e (5.42)
1−λ(n−1) ∂λ
2λ(cid:9)
where λ⊕ and λ(cid:9) are the upper and the lower bounds of forgetting factor λ. The
upper bound λ⊕ is analytically selected so that the GVFF-RLS algorithm achieves
a minimum steady-state excess mean square error (EMSE). To ensure stability the
minimum value of λ is required to be greater than 2λ(cid:9) where λ(cid:9) is calculated as
(cid:104) √ (cid:105)
(M −2)ρ + D
n−1
λ(cid:9) = (5.43)
(cid:2) (cid:3)
4 (M +1)ρ˜ +ρ2
n−1 n−1
and
D = (M −2)2ρ2 −8(M +2)(cid:2)(M +1)ρ˜ +ρ2 (cid:3)
n−1 n−1 n−1
where the scalar M is the M most recent data of w(n). The pseudo-code shown in
Figure 5.4 is the summary of the GVFF-RLS algorithm.
To evaluate the eﬃciency of the GVFF-RLS algorithm [41] performs simulations
using the GVFF-RLS algorithm in comparison to other VFF-RLS approaches such as
those presented in [69, 54] in identiﬁcation of a switching system. Simulation results
show that the GVFF-RLS algorithm yields smaller steady-state EMSE and oﬀers
better tracking capability for diﬀerent SNRs. However, the GVFF-RLS algorithm
seems to be somewhat sensitive to β, κ, and µ which are are experimentally obtained
in these studies.
5.3.3 Gauss-Newton VFF RLS Algorithm (GN-VFF-RLS)
The other often mentioned VFF algorithm in the literature was developed by Song
et al. [71] and is known as the Gauss-Newton variable forgetting factor recursive
least-squares or GN-VFF-RLS algorithm. This method is motivated by a desire to
improve the RLS algorithm with the adaptive memory reviewed in Section 5.3.1
135
Pseudo-code: The GVFF-RLS Algorithm
Initialize: P(0), w(0), λ(0), ρ , ρ˜ , and µ,β,κ ∈ R where κ > β
0 0
for each instant time n = 1,... do
d(n) = wT(n)u(n)+χ(n)
0
e(n) = d(n)−wT(n)u(n)
P(n−1)u(n)
k(n) =
λ(n−1)+uH(n)P(n−1)u(n)
w(n+1) = w(n)+k(n)e(n)
1
(cid:2) (cid:3)
P(n) = P(n−1)−k(n)uH(n)P(n−1)
λ(n−1)
(cid:20) (cid:18) µ (cid:19)(cid:18)∂σ2(n)(cid:19)(cid:21)λ⊕
λ(n) = λ(n−1)− e
1−λ(n−1) ∂λ
2λ(cid:9)
∂σ2(n+1) ∂σ2(n) ∂α ∂h
e = α e + nσ2(n)+ nσ2
∂λ n ∂λ ∂λ e ∂λ χ
∂ρ
n
ρ = 1+λ(n−1)ρ ; = ρ
n n−1 n−1
∂λ
∂ρ˜
ρ˜ = 1+λ2(n−1)ρ˜ ; n = 2λ(n−1)ρ˜
n n−1 n−1
∂λ
2[(M +1)ρ˜ +ρ2]−(M +2)ρ
α = 1− n n n
n ρ [(M +1)ρ˜ +ρ2]
n n n
2 2
h = −
n ρ [(M +1)ρ˜ +ρ2]
n n n
(cid:20) (cid:21)
∂α 2 ∂ρ M +2 ∂ρ˜ ∂ρ
n n n n
= − × (M +1) +2ρ
∂λ ρ2 ∂λ [(M +1)ρ˜ +ρ2]2 ∂λ n ∂λ
n n n
(cid:20) (cid:21)
∂h 2 ∂ρ 2 ∂ρ˜ ∂ρ
n n n n
= − − × (M +1) +2ρ
∂λ ρ2 ∂λ [(M +1)ρ˜ +ρ2]2 ∂λ n ∂λ
n n n
σ2(n) = βσ2(n−1)+(1−β)e2(n)
e e
σ2(n) = κσ2(n−1)+(1−κ)e2(n)
χ χ
Calculating the lower bound of the forgetting factor λ(cid:9)
(cid:104) √ (cid:105)
(M −2)ρ + D
n−1
λ(cid:9) =
(cid:2) (cid:3)
4 (M +1)ρ˜ +ρ2
n−1 n−1
D = (M −2)2ρ2 −8(M +2)(cid:2)(M +1)ρ˜ +ρ2 (cid:3)
n−1 n−1 n−1
end for
Figure 5.4: A pseudo-code for the GVFF-RLS algorithm [41].
136
which only works well in the slow time varying environments. The authors proposed
to adaptively compute the forgetting factor λ(n) using a Gauss-Newton-liked method
so that the calculation of λ(n) is obtained by solving the second partial derivative of
the cost function with respect to λ when it equated to zero. Simulation results in
[71] shows improvement of the GN-VFF-RLS algorithm over the RLS algorithm with
adaptive memory [32] and the ﬁxed forgetting factor algorithms by oﬀering smaller
mean square deviation (MSD) with a wide range of SNRs for autoregressive (AR)
parameter estimation.
In [71] the cost function Q (n) is deﬁned as
GN
1
Q (n) = E(cid:2)|e(n)|2(cid:3) (5.44)
GN
2
The desired signal d(n) is described as
d(n) = wH(n)u(n)+ϕ(n) (5.45)
where ϕ(n) is a stationary white noise process with zero mean and variance σ . The
ϕ
error between the desired signal d(n) and its estimation is
e(n) = d(n)−wH(n)u(n) (5.46)
The Kalman gain k(n) and the inverse of correlation matrix P(n) are the same as in
the RLS algorithm with adaptive memory [32] (Figure 5.3),
P(n−1)u(n)
k(n) =
λ(n−1)+uH(n)P(n−1)u(n)
1
(cid:2) (cid:3)
P(n) = P(n−1)−k(n)uH(n)P(n−1)
λ(n−1)
and the weight vector w(n) is recursively updated as
w(n) = w(n−1)+k(n)e#(n) (5.47)
There are two main diﬀerences between the GN-VFF-RLS algorithm and the RLS
algorithm with adaptive memory in Section 5.3.1: i) the cost function is deﬁned using
137
the a posteriori estimation error e(n) instead of the a priori estimation error ξ(n);
ii) the forgetting factor λ is calculated by minimizing the second partial derivative
of (5.44) with respect to λ, denoted as ∇(cid:48) (n), instead of the gradient of the cost
λ
function Q(n) with respect to λ (∇ (n)) as in (5.22). In [71] the RLS algorithm
λ
with adaptive memory [32] is referred to as the steepest descent VFF-RLS algorithm
while the proposed method is called the Gauss-Newton approach due to the analogous
derivation of the method to Gauss-Newton method in optimization. The ∇(cid:48) (n) term
λ
is expressed in [71] as
∂2Q (n)
∇(cid:48) (n) ≡ GN
λ ∂λ2
= (1−η )∇(cid:48) (n−1)+η ψH(n−1)u(n)uH(n)ψ(n−1) (5.48)
2 λ 2
Although a small positive number η in this context is referred as the convergence
2
rate, its deﬁnition is the same as η in (5.26). The forgetting factor is recursively
1
computed as
(cid:2) (cid:3)
Re ψH(n−1)u(n)e#(n)
λ(n) = λ(n−1)+η (5.49)
2 ∇(cid:48) (n)
λ
where ψ(n) is similar to (5.23),
∂w(n)
ψ(n) =
∂λ
(cid:2) (cid:3)
= I −k(n)uH(n) ψ(n−1)+S(n)u(n)e#(n) (5.50)
and S(n) is the same as (5.24)
1 1 1
(cid:2) (cid:3) (cid:2) (cid:3)
S(n) = I −k(n)uH(n) S(n−1) I −u(n)kH(n) + k(n)kH(n)− P(n)[5.24]
λ λ λ
To evaluate the estimation accuracy the time varying autoregressive (AR) pa-
rameter estimation is simulated using diﬀerent SNR ranges with a ﬁxed frequency.
The performance of the exponentially windowed recursive least squares (EW-RLS)
algorithm with an optimal ﬁxed forgetting factor, the RLS algorithm with adaptive
memory [32], and the GN-VFF-RLS algorithm are compared in [71]. The GN-VFF-
RLS algorithm results in the smallest MSD for a wide range of SNRs. In tracking
138
Pseudo-code: The GN-VFF-RLS Algorithm
Initialize: P(0), w(0), λ(0), S(0), ψ(0), and η is a small positive constant
2
for each instant time n = 1,... do
d(n) = wH(n)u(n)+ϕ(n)
e(n) = d(n)−wH(n)u(n)
P(n−1)u(n)
k(n) =
λ(n−1)+uH(n)P(n−1)u(n)
w(n) = w(n−1)+k(n)e#(n)
1
(cid:2) (cid:3)
P(n) = P(n−1)−k(n)uH(n)P(n−1)
λ(n−1)
(cid:2) (cid:3)
Re ψH(n−1)u(n)e#(n)
λ(n) = λ(n−1)+η
2 ∇(cid:48) (n)
λ
∇(cid:48) (n) = (1−η )∇(cid:48) (n−1)+η ψH(n−1)u(n)uH(n)ψ(n−1)
λ 2 λ 2
1
(cid:2) (cid:3) (cid:2) (cid:3)
S(n) = I −k(n)uH(n) S(n−1) I −u(n)kH(n)
λ(n)
1 1
+ k(n)kH(n)− P(n)
λ(n) λ(n)
ψ(n) = I −k(n)uH(n)ψ(n−1)+S(n)u(n)e#(n)
end for
Figure 5.5: A pseudo-code for the GN-VFF-RLS algorithm [71].
capability testing in which the AR parameter estimation is tested at a ﬁxed SNR
with varying frequency, the GN-VFF-RLS algorithm also outperforms the other al-
gorithms to provide smallest MSD. The summary of the GN-VFF-RLS algorithm is
shown in the pseudo-code in Figure 5.5.
5.4 Dynamic Adaptive Forgetting Factor (DAFF) Algorithms
for Visual Guide Control
Due to the complexities of the formulations of the existing VFF algorithms where
their performances rely on a number of constant selections such as η , κ, and β, a
1
139
novel VFF scheme called the dynamic adaptive forgetting factor (DAFF) method is
developed in this section.
5.4.1 Previous Work on a VFF Algorithm for Uncalibrated Visual Ser-
voing
In literature there are few studies of uncalibrated visual servoing using a VFF algo-
rithm. An interesting work implementing the RLS algorithm with adaptive memory
into a model-free uncalibrated visual servoing algorithm is presented in [29]. This
method combines a classical adaptive least squares (ARLS) algorithm similar to the
RLS algorithm with adaptive memory [32] in Section 5.3.1 into the DGN-PBM algo-
rithm [59] and is referred as an uncalibrated visual servoing using adaptive recursive
least squares (VS-ARLS) algorithm. Since the DGN-PBM algorithm is the RLS al-
gorithm, there exists parameter equivalencies between the two algorithms [29] and is
presented herein as Table 5.1.
Table 5.1: The RLS and the DGN-PBM Parameter Equivalencies [29].
The VS-ARLS algorithm can be derived by merely substituting the DGN-PBM
parameters into the ARLS algorithm for forgetting factor calculation and then in-
tegrated into the original DGN-PBM algorithm. One important note is that in the
140
original adaptive ﬁltering context such as one presented in [32] d(n) and ξ(n) are
scalars whereas w(n) is a vector. However, for the DGN-PBM algorithm ∆f and
˜ ˜ ˜
∆f −J h are vectors and J is a matrix. The summary of the VS-ARLS algorithm
k−1 k
is shown in the pseudo-code in Figure 5.6.
To evaluate tracking performance of the VS-ARLS algorithm a 6-DOF, eye-in-
hand Puma 560 robot is used in [29] for simulation. The results obtained from the
VS-ARLS algorithm are compared with results from the standard RLS algorithm1 for
staticanddynamictracking. SimulationresultsshowthattheaverageMSEfromboth
algorithms are nearly the same in static tracking but the VS-ARLS algorithm oﬀers a
lower average MSE than the standard RLS algorithm in the dynamic target tracking.
It is mentioned in [29] that the uncalibrated visual servoing is a highly nonlinear
system that is vulnerable to system modeling and noises. So there exists a trade-
oﬀ between using more information to improve noise resistance and minimizing the
image error. Consequently, [29] recommends to explicitly construct a mathematical
model relating the error and noise to the forgetting factor calculation to improve
performance of the VS-ARLS algorithm.
5.4.2 DAFF Method
Although various VFF algorithms show improved results compared to a ﬁxed for-
getting factor, the mathematical formulas are complicated and the performances of
these algorithms are dependent on one or more variables. For example, the adaptive
memory scheme [32], the VS-ARLS [29], and the GN-VFF-RLS [71] algorithm per-
formances rely on the learning rate η and η , while the GVFF-RLS [41] depends on
1 2
µ, β, and κ. Due to the complexities of the formulations, the eﬀects of these vari-
ables to these existing VFF algorithms are diﬃcult to determine and have not been
thoroughly presented. As a result, a simpler approach of adaptively calculating the
1It is not clear what exactly is the standard RLS algorithm used in [29], but it is most likely
referred to the DGN-PBM algorithm with a ﬁxed forgetting factor λ.
141
Pseudo-code: The VS-ARLS Algorithm
(cid:16) (cid:17)
Given: f : Rn → Rm ; θ ,θ ∈ Rn ; Jˆ ∈ Rm×n; fˆ ∈ Rm×1; P ∈ Rn+1×n+1 ;
0 1 0 t 0
0
λ ∈ (0,1)
(cid:16) (cid:17)
ˆ
Initialize: J , θ , θ , f , P , S , ψ , and η is a small positive constant
0 0 1 t 0 0 0 1
0
for k = 1,... do
∆f = f −f
k k−1
h = θ −θ
θ k k−1
h = t −t
t k k−1
(cid:20) (cid:21)
(θ −θ )
h˜ = k k−1
(t −t )
k k−1
(cid:104) (cid:16) (cid:17) (cid:105)
J˜ = Jˆ fˆ
k−1 k−1 t
k−1
Calculate: λ
k
(cid:26) (cid:16) (cid:17)T (cid:27)λ+
˜ ˜ ˜
λ = λ +η ∆f −J h ψ h
k k−1 1 k−1 k−1
λ−
1 (cid:104) (cid:105) (cid:104) (cid:105)
S = I −k˜ h˜T S I −h˜k˜T
k λ k k−1 k
k
1 1
+ k˜ k˜T − P˜
λ k k λ k
k k
(cid:104) (cid:105) (cid:16) (cid:17)(cid:16) (cid:17)T
ψ = I −k˜ h˜T ψ + ∆f −J˜ h˜ S h˜
k k k−1 k−1 k
˜
Calculate: J
k
(cid:16) (cid:17)−1(cid:16) (cid:17)
J˜ = J˜ + λ +h˜TP˜ h˜ ∆f −J˜ h˜ h˜TP˜
k k−1 k k−1 k−1 k−1
(cid:16) (cid:17)−1(cid:16) (cid:17)
k˜ = λ +h˜TP˜ h˜ P˜ h˜
k k k−1 k−1
1 (cid:16) (cid:17)
P˜ = P˜ −k˜ h˜TP˜
k k−1 k k−1
λ
k
Calculate: θ
k+1
(cid:18) (cid:19)
(cid:16) (cid:17)−1 ∂f (t)
θ = θ − JˆTJˆ JˆT f + k h
k+1 k k k k k ∂t t
end for
Figure 5.6: A pseudo-code for the VS-ARLS algorithm [29]
142
forgetting factor λ is investigated.
It is desirable to achieve fast convergence in transience and high accuracy in
steady-state tracking. To achieve fast convergence a robot is expected to move in the
most direct path from its initial conﬁguration θ to reach steady-state tracking. The
0
value of the forgetting factor, where
1
n = [5.1]
memory
1−λ
roughlyrepresentsthememoryoftheRLS-basedalgorithm, shouldberelativelysmall
(less memory) in the transient state so that the updated forgetting factor λ invokes
more dependence on the current image error, i.e., less past information is included
ˆ ˆ
in approximating the Jacobian J and the Hessian H . Moreover, at the beginning
k k
of tracking there is not enough information for uncalibrated visual servoing to quan-
titatively understand the tracking behaviors of the robot in relation to its current
ˆ ˆ
environment. So it is desired to update the Jacobian J and the Hessian H based
k k
on the most recent data, i.e., using less memory for calculation. In contrast, λ should
be relatively high, i.e. closer to unity, once the robot reaches steady-state tracking.
ˆ
The higher λ value results in increasing the memory so that the current Jacobian J
k
ˆ
and the Hessian H are estimated by averaging down more past information.
k
Since the image error is typically large in the transient state, especially at the
beginning of the tracking process, and becomes relatively small during the steady
state, it can be hypothesized that the forgetting factor λ should be small (less mem-
ory) when the image error is large during transience, and λ should get closer to unity
(more memory) when the image error becomes small in steady-state tracking. In the
case that the current image error abruptly becomes substantially larger than the past
few errors, which may be caused by sudden changes of the environment or the target
velocity, either changes in direction, speed, or the combination of both, it is hypoth-
ˆ
esized that the past and current models used to estimate the Jacobian J and the
k
ˆ
Hessian H no longer represent the actual behaviors of the current system. Thus, the
k
143
ˆ ˆ
calculation of J and H should include less memory (smaller value of the forgetting
k k
factor λ). Regardless of cause, the forgetting factor λ is somewhat inversely related
to the current image error norm (cid:107)f (cid:107).
k
For an uncalibrated visual servoing system, it is desired to study how λ responds
k
to the image error norm (cid:107)f (cid:107). However, the analytical calculation of adaptive λ with
k k
respect to (cid:107)f (cid:107) is challenging due to the complexity of the mathematical formulation
k
presented in Section 5.3. For good tracking, the robot is expected to quickly reach
the desired target trajectory. Thus image error norm (cid:107)f (cid:107), in analogy to a continuous
k
function in the time domain, could be expected to exponentially decay to zero as the
robot reaches steady-state tracking. This behavior is in fact similar to the response of
a ﬁrst-order diﬀerential dynamic system as shown in Figure 5.7a. In contrast, values
of λ , also in analogy to a ﬁrst-order system, could be expected to exponentially
k
increase as shown in Figure 5.7b since λ is assumed to be in reversely related to
k
(cid:107)f (cid:107). Inspired by these observations, a novel adaptive forgetting factor called the
k
dynamic adaptive forgetting factor or DAFF method is presented.
The idea is to heuristically select λ based on (cid:107)f (cid:107) in analogy to the response of
k k
a ﬁrst-order dynamic system. From the relationship between λ and n in (5.1),
k memory
rearranging gives
1
λ = 1−
k
n
memory,k
Denoting
1
Λ ≡
n
memory
then
Λ = 1−λ (5.51)
k k
For a large value of (cid:107)f (cid:107), λ should be small and Λ large. On the contrary, a
k k k
small (cid:107)f (cid:107) should result in large a λ and small Λ . Unlike λ , Λ is adjusted indirect
k k k k k
144
l
0.25 1
max
|| f ||
k
0.2 0.95
0.15 0.9
k
l
0.1 0.85
0.05 0.8
0 0.75
0 5 10 15 20 25 30 0 5 10 15 20 25 30
Time (s) Time (s)
(a) Expected (cid:107)f (cid:107) vs. Time (b) Hypothesized λ vs. Time
k k
Figure 5.7: The expected (cid:107)f (cid:107) values for ideal tracking performance and the hypoth-
k
esized λ values in corresponding to (cid:107)f (cid:107) with respect to time (s).
k k
to (cid:107)f (cid:107). Thus the changes of Λ value with respect to (cid:107)f (cid:107) could be treated in an
k k k
analogous way to a ﬁrst order diﬀerential system. Consequently, the input function
F(s) is the image error norm (cid:107)f(t)(cid:107) and the output function Λ(s) is Λ(t) in the time
domain. Then the transfer function G(s) in the Laplace domain is expressed as
Λ(s) 1
G(s) = = (5.52)
F(s) τs+1
where τ is a time constant. In fact the input function F(s) is the normalized form of
ˇ
the image error norm f where
k
(cid:107)f (cid:107)
ˇ k
f = (5.53)
k
f
max
and f is the maximum error norm of all the previous errors f(θ,t),
max
f = max{(cid:107)f (cid:107),(cid:107)f (cid:107),...,(cid:107)f (cid:107)} (5.54)
max 1 2 k
ˇ
The normalization of the image error f is necessary to limit the calculated forgetting
k
factor λ within the allowable range λ ∈ (0,1]. As a large residual problem is
k k
assumed, f = (cid:107)f (cid:107) is applied.
max 1
DuetothefactthatallvariablesusedintheswitchingMBFGS-DBvisualservoing
algorithm are available only at a ﬁxed sampling time T, (5.52) is transformed into the
145
transfer function of a discrete system, G(z). Using the z-transform analysis with the
trapezoid rule substitution, also known as Tustin’s method or the Binary transform
[24], the transfer function of a continuous time system is approximately converted
into the discrete time domain by substituting s in (5.52) by
(cid:18) (cid:19)
2 z −1
s ≈ (5.55)
T z +1
where T is the sampling time. Then substituting (5.55) into (5.52) yields
Λ(z) T (1+z−1)
G(z) = = (5.56)
F(z) (2τ +T)+z−1(T −2τ)
so the discretized model of the forgetting factor λ can be expressed as
k
(cid:0)ˇ ˇ (cid:1)
T f +f +(2τ −T)Λ
k k−1 k−1
Λ = (5.57)
k
2τ +T
where 2τ > T to ensure that Λ is positive.
k
There exists an optimal range of the forgetting factor λ for which the value of
k
the forgetting factor λ cannot be too small to achieve steady-state tracking, while
k
inﬁnite memory where λ = 1 can lead to instabilities and divergence for dynamic
k
environments [32]. For this reason, the calculation of λ in (5.51) is modiﬁed into a
k
form,
λ = {λ (1−Λ )}λmax (5.58)
k max k λmin
where λ and λ are the maximum and the minimum allowable values of the
max min
forgetting factor λ . Although it is often recommended to choose λ closer to unity,
k max
there are not many guidelines for determining the minimum value of the forgetting
factor or to properly select the optimal range. The eﬀect of the λ range on tracking
performance is investigated in Section 6.5.1. A summary of the DAFF method with
the DGN-PBM algorithm is shown in the pseudo-code in Figure 5.8.
Besides the selection of the forgetting factor range, the performance of the DAFF
algorithm is also aﬀected by the time constant τ. For a dynamic system analysis, the
146
Pseudo-code: The DAFF Method with the Switching MBFGS-DB Algorithm
Given: Rn → Rm ; θ ,θ ∈ Rn ; Jˆ ∈ Rm×n,P ∈ Rn×n,λ ∈ (0,1)
0 1 0 0
ˆ
Initialize: J , θ , θ , H , P , λ , λ , and τ
0 0 1 0 0 max min
for k = 1,... do
∆f = f −f ; h = θ −θ
k k−1 k−1 k k−1
˜ (cid:2) (cid:3)(cid:48)
h = (θ −θ ) (t −t )
k k−1 k k−1
(cid:104) (cid:16) (cid:17) (cid:105)
J˜ = Jˆ fˆ
k−1 k−1 t
k−1
Calculate: the forgetting factor λ
k
(cid:0)ˇ ˇ (cid:1)
T f +f −(T −2τ)Λ
k k−1 k−1
Λ =
k
2τ +T
λ = {λ (1−Λ )}λmax
k max k λmin
(cid:107)f (cid:107)
ˇ k
f =
k
f
max
ˆ ˜
Calculate: J and P
k k
(cid:16) (cid:17)−1(cid:16) (cid:17)
J˜ = J˜ + λ+h˜TP˜ h˜ ∆f −J˜ h˜ h˜TP˜
k k−1 k−1 k−1 k−1
(cid:18) (cid:19)
1 (cid:16) (cid:17)−1(cid:16) (cid:17)
P˜ = P˜ − λ+h˜TP˜ h˜ P˜ h˜h˜TP˜
k k−1 k−1 k−1 k−1
λ
if (cid:107)f (cid:107) < 0.1(cid:107)f (cid:107) then
k 1
ϕ = 0
k
else
ϕ = 1
k
ˆ
Update: the residual S
k
z∗ z∗ T Sˆ h hT Sˆ
Sˆ = Sˆ + k−1 k−1 − k−1 k−1 k−1 k−1
k k−1 g Th hT Sˆ h
k−1 k−1 k−1 k−1 k−1
z∗ = JˆTf −JˆT f ; g = JˆTf −JˆT f
k−1 k k k−1 k k−1 k k k−1 k−1
end if
´
Calculate Hs,k H´ = JˆTJˆ +ϕ Sˆ
s,k k k k k
Calculate: θ using the dynamic full quasi-Newton method
k+1
(cid:18) (cid:19)
(cid:16) (cid:17)−1 ∂f (t)
θ = θ − H´ JˆT f + k h
k+1 k k k k ∂t t
end for
Figure 5.8: Pseudo-code for the DAFF method with the switching MBFGS-DB algo-
rithm
147
time constant τ determines how quickly the system reaches steady state. Likewise,
a direct interpretation of the time constant τ for the DAFF algorithm should, in
theory, identify how fast λ gets close to steady-state, i.e., reaching λ . However,
k max
for this application, the output of interest is the time-varying image error f that is
k
ˆ ˆ
inﬂuenced by accuracy of the Jacobian J and the Hessian H approximation, which
k k
are in fact dependent on a proper value of λ . Therefore, the time constant τ used in
k
the DAFF method does not directly impact the reduction of the image error f for
k
this algorithm. In this study τ is heuristically selected so that the value of λ does
k
not increase too slowly or too rapidly. The eﬀects of the forgetting factor range and
the time constant τ on the performance of the DAFF method are discussed in Section
6.5.1.
5.5 Summary
Since the switching MBFGS-DB algorithm utilizes the RLS method for Jacobian
approximation, its performance is dependent on the forgetting factor λ. Various
VFF algorithms developed for adaptive ﬁltering are reviewed in Section 5.3. Due
to mathematical formulations of existing VFF algorithms that require a number of
parameter selections, a novel method called the dynamic adaptive forgetting factor
(DAFF) method is developed in Section 5.4. The behavior of λ is reviewed in
k
analogy to the transient response of a ﬁrst-order dynamic system. In this case, the
input function is Λ ≡ 1−λ and the output function is the normalized (cid:107)f (cid:107). Unlike
k k k
other existing VFF algorithms this method is more simple yet eﬀectively calculates λ
k
accordingly to (cid:107)f (cid:107) with only one parameter, the time constant τ. The performance
k
evaluations of the presented VFF algorithms are discussed in Chapter 6.
148
CHAPTER VI
SIMULATION
A theoretical foundation for the various switching algorithms have been presented.
This chapter evaluates the novel uncalibrated visual servoing algorithms as compared
to the dynamic quasi-Gauss-Newton algorithms either with or without partitioning
forBroyden’smethod(theDBM-RLSandtheDGN-PBMalgorithms)withaﬁxedλ .
k
Simulation results demonstrate the switching MBFGS-DB with the DAFF algorithm
signiﬁcantly improves transient and steady-state tracking for the large residual error
case. Furthermore, thecontrolschemeoﬀersbettertrackingcapabilityinthepresence
of measurement and processing noise for a variety of target trajectories using diﬀerent
robot conﬁgurations and degrees-of-freedom.
The organization of this chapter is as follows. Section 6.1 overviews the diﬀerent
algorithms evaluated in this study. Section 6.2 gives a summary of simulation setups
with a variety of robots and target trajectories. Various switching algorithms are
evaluated for the proposed residual approximations integrated with the DGN-PBM
algorithmforlargeresidualtrackingprobleminSection6.3. SincetheLMAalgorithm
is expected to improve the conditioning of the Hessian approximation, in Section 6.4
it is implemented with the switching algorithms from Section 6.3. All the switching
algorithms utilize the recursive least-squares (RLS) algorithm and its performance
is dependent on the forgetting factor λ. Various variable forgetting factor (VFF)
algorithms reviewed in Chapter 5 are presented in Section 6.5. These are integrated
into the MBFGS-DB algorithm which oﬀers the best tracking performance compared
to the other proposed switching algorithms. VFF improves tracking, especially in
the presence of measurement and processing noise. In Section 6.6 the switching
149
MBFGS-DB and DGN-PBM algorithms with various VFF algorithms are compared
with/without implementation of LMA for a cycloidal trajectory tracking using the
PUMA 560 robot with an eye-in-hand camera. Section 6.7 summarized the results.
6.1 Overview
The proposed uncalibrated visual control is built upon the dynamic quasi-Gauss-
Newton algorithms developed by Piepmeier et al. [57, 59] to improve:
1. Large initial error for dynamic target tracking
2. A singular or ill-conditioned Hessian matrix F = JTJ +S
θθ k k k
3. Selection of an optimal forgetting factor λ
The algorithms for improving each diﬃculty are summarized in Table 6.1.
The DBM-RLS and the DGN-PBM algorithms [57, 59] provide stable and con-
vergent tracking for zero- or small-residual cases where the Gauss-Newton method
∂JT
assumes that the residual S = k f can be neglected. This assumption is true
k k
∂θ
when the initial robot conﬁguration θ is in the neighborhood of the target acquisition
0
conﬁguration θ∗. Otherwise the residual S may be signiﬁcant and the Gauss-Newton
k
is less appropriate. Instead, the dynamic BFGS, the DFN-BFGS, and the MBFGS
algorithms approximate the residual S is discussed in Chapter 4. These are used in a
k
switching scheme so the residual S is only utilized when the average error norm (cid:107)f (cid:107)
k k
is larger than a speciﬁed criterion. Otherwise the DGN-PBM algorithm is employed.
The proposed schemes are referred to as the switching DBFGS-DB, the switching
DFN-BFGS-DB, and the switching MBFGS-DB algorithms.
Two diﬀerent robots and several target trajectories are used to validate these
switching algorithms for large residual tracking. To study the eﬀect of the residual
ˆ
S approximation, a ﬁxed forgetting factor is used without the Levenberg-Marquardt
k
algorithm (LMA). Then the performance of each large residual algorithm is compared
150
Table 6.1: A summary of methods to improve the dynamic quasi-Gauss Newton
algorithms.
to the DBM-RLS and the DGN-PBM algorithms. Noise is not present in this set of
simulations.
Then the switching algorithms are used with the LMA to improve the condition-
ing of the Hessian approximations. The LMA is well-known for solving nonlinear
unconstrained optimizations problems if the Hessian matrix becomes ill-conditioned
or singular. Though the LMA appears in various forms in the literature, such as
[50, 47], the implementation of [47] is utilized. The switching algorithms with and
without the LMA are compared to the DBM-RLS and the DGN-PBM algorithms
using a ﬁxed forgetting factor without added noise.
Finally various switching algorithms with and without the LMA are investigated
with diﬀerent VFF algorithms to improve tracking performance, especially in the
presence of measurement and process noise. The robot conﬁgurations and camera
conﬁgurations used to perform the tests are reviewed in the next section.
151
6.2 System Description
6.2.1 Robot System
Two robot systems are used, a spatial RRR robot and a 6 DOF robot as shown in
Figure 6.1a. The RRR robot model is similar to the robot system described in [25]
and its Denavit-Hartenberg (DH) parameters are summarized in Table 6.2. The ﬁrst
revolute joint is vertical and the second and third joints are horizontal. The 6 DOF
robot kinematic model used for all simulations is the PUMA 560 kinematics provided
in the Robotic Toolbox by Corke [10].
Table 6.2: The DH parameters of a RRR robot.
6.2.2 Camera System
All cameras used in this study have the same intrinsic parameters given in Table 6.3.
The camera transformation matrix for the given intrinsic and extrinsic parameters is
obtained using functions provided in the Machine Vision Toolbox by Corke [11].
In Table 6.3 f is the focal length, cp.px and cp.py are the horizontal and vertical
pixel pitches of the sensor, and cp.u and cp.v are principal point or the image center.
Diﬀerent camera systems aﬀect tracking performance and two representative cam-
era settings are used:
1. Eye-to-hand camera setting - one or more cameras are ﬁxed at stationary loca-
tions. Two camera arrangements are investigated.
152
(a)
(b)
Figure 6.1: (a)The RRR robot, (b) The PUMA 560 robot.
153
Table 6.3: Camera parameters.
2. Eye-in-hand camera setting - one or more cameras are attached to the EE of
the robot and the optical axis is assumed to be coincident (for one camera case)
or nearly parallel (for multiple camera case) with the z axis of the ﬁnal frame
of the manipulator.
6.2.3 Target Trajectories
Various target trajectories are used:
1. Circular trajectory - a simple translational, circular path generated on either
the X-Y or the Y-Z plane
2. Square trajectory - a more diﬃcult path due to velocity discontinuities at the
corners
3. Cycloid trajectory - a complex trajectory where both direction and speed of the
target are changed over its cycle
4. Helical trajectory - an out-of-a-plane trajectory
Note that these trajectories are all translational. Examples of the RRR robot with
two eye-to-hand cameras and the Puma 560 robot with an eye-in-hand camera are
154
shown tracking circular trajectories in Figure 6.1a and Figure 6.1b respectively.
6.2.4 Assumptions
All simulations presented in this chapter are generated under the following assump-
tions:
1. The robot joint positions reach the commanded locations within the speciﬁed
time increment.
2. The dynamics of the robot are not considered and is assumed to have no eﬀect
on the tracking performance as long as the ﬁrst assumption is applied
3. The vision acquisition data at each update represents the changes in features
from the most recently commanded motion.
4. For the eye-to-hand camera setting the target position y∗ is only a function of
time t and is independent of the robot joint angles θ.
5. The EE position y is only a function of robot joint angles θ and is independent
of time t.
For almost all tests a sampling time of h = 0.05 sec (20 Hz) is used and the
t
maximum increment of each joint is limited to ±5◦ to ensure reasonably small motion
Jacobian-based control.
6.3 Performance Evaluation of the Switching Algorithms
for Large Residual Tracking
AsmentionedinChapter4thedynamicquasi-Gauss-Newtonalgorithmsalreadywork
ˆ
well for the zero- or small-residual cases. The approximation of the residual S is only
k
recommendedwhentheaverage(cid:107)f (cid:107)islargesoitisimplementedintoahybridswitch-
k
ing algorithm. The approximation of the residual term using the dynamic BFGS,
155
the DFN-BFGS, and the MBFGS algorithms become the switching DBFGS-DB, the
switching DFN-BFGS-DB, and the switching MBFGS-DB algorithms respectively.
In addition, the Fu algorithm in [25] (reviewed in Section 4.3.2) is compared
with the switching algorithms. Although a trust region method is used with residual
estimation, only the residual portion is employed for comparison. The method de-
teriorates when the image error becomes small so it is implemented into a switching
scheme.
ˆ
A summary of the residual S algorithms are listed in Table 6.4. The switching
k
schemes are summarized by the pseudo-code in Figure 6.2.
ˆ
To isolate the residual S approximation, the forgetting factor λ held constant
k
and the LMA is not used. Since noise compensation requires a proper selection of
the forgetting factor value, the eﬀect of noise disturbance is deferred so no noise is
added. The initial Jacobian is estimated by successively perturbing each joint by a
small angle.
Forallapproachestheﬁxedforgettingfactorλ = 0.5isuseddespitethehypothesis
made in Chapter 5 that a small value of λ should be applied if image error is large
and a large λ should be employed if the image error becomes small. For this reason,
a mean value λ = 0.5 seems to be a reasonable choice. A study of λ on tracking
performance is presented in Section 6.5.
The critical parameter for switching algorithms is the switching criterion sw
crit
which determines when the residual approximation is included. Too great a value
yields slower convergence while too small a value sometimes leads to divergence as
discussed in Section 6.3.3. In this study sw is determined by heuristically as a
crit
percentage of the initial error norm f which is assumed to be the largest,
1
sw = υ(cid:107)f (cid:107)
crit 1
The υ = 0.3 or equivalently sw is 30% of (cid:107)f (cid:107) is utilized for all switching
crit 1
schemes except for the switching Fu-DB algorithm where υ = 0.5 is used to avoid
156
ˆ
Table 6.4: A summary of methods for estimating residual S : Dynamic BFGS, DFN-
k
BFGS, MBFGS, and Fu’s Method
157
divergence.
The settling time t is deﬁned as the time required to move the EE from its
s
initial conﬁguration θ to reach and remain within a given range of the image error
0
(the cut-oﬀ steady-state error). In this study the cut-oﬀ steady-state error value is
approximately 1% of the initial average error norm (cid:107)f (cid:107) and in this particular case
1
the cut-oﬀ are 0.3348 pixels and 0.2883 for camera 1 and camera 2 respectively.
The switching schemes are compared with the DBM-RLS and DGN-PBM algo-
ˆ
rithms in which the residual S term is ignored. Two robot systems with diﬀerent
k
camera conﬁgurations are used:
1. The spatial RRR robot with two eye-to-hand cameras for tracking one feature
point
2. The PUMA 560 robot with an eye-in-hand camera conﬁguration for tracking
four feature points
6.3.1 The RRR robot with a circular trajectory
First, the RRR robot with two eye-to-hand cameras is used to test the switching
MBFGS algorithm for large error residual tracking. A single point target is moving
in the circular trajectory
x = 300+Rsin(ωkT) mm
y = 500+Rcos(ωkT) mm
z = 500 mm (6.1)
where R = 100 mm is the radius of the circular path, T = 0.05 s is the sampling
period, k is the iteration number, and ω = 0.45 rad/s is the angular speed. The
starting robot joint angles are θ = [60◦,70◦,50◦]T. The two camera conﬁgurations
0
are shown in Figure 6.1a and located by the homogeneous matrices in an arrangement
158
similar to [25]
 
1 0 0 0.4453
 
 
0 0.9988 0.0499 0.4307
T =   (6.2)
1  
0 −0.0499 0.9988 −2 
 
 
0 0 0 1
 
1 0 0 0.4453
 
 
0 0.9988 −0.0499 0.6307
T =   (6.3)
2  
0 0.0499 0.9988 −2 
 
 
0 0 0 1
To compare tracking performance of all switching algorithms with the dynamic-
Gauss-Newton based algorithms (the DBM-RLS and the DGN-PBM ) the EE and
feature points in the image plane, the task space view of one camera, and the error
norm of each algorithm are shown in Figure 6.3, Figure 6.4, and Figure 6.5 respec-
tively.
ˆ
Table 6.5: The RMS error and the settling time comparison of various residual S ap-
k
proximation schemes for θ = [60◦,70◦,50◦]T, λ = 0.5, and υ = 0.3 for all algorithms.
0
Figure 6.4 demonstrates that the initial EE location is far from the target trajec-
tory to ensure large residual to start. The MBFGS-DB algorithms oﬀers the fastest
159
Pseudo-code: The Switching DBFGS-DB, DFN-BFGS-DB, MBFGS-DB , and
Fu-DB Algorithms
Given: Rn → Rm ; θ ,θ ∈ Rn ; Jˆ ∈ Rm×n,P ∈ Rn×n,λ ∈ (0,1)
0 1 0 0
ˆ
Initialize: J , θ , θ , H and P
0 0 1 0 0
for k = 1,... do
ˆ
Calculate: J using a Jacobian estimation in the DGN-PBM algorithm [59]
k
∆f = f −f ; h = θ −θ
k k−1 k−1 k k−1
(cid:20) (cid:21)
(θ −θ )
h˜ = k k−1
(t −t )
k k−1
(cid:104) (cid:16) (cid:17) (cid:105)
J˜ = Jˆ fˆ
k−1 k−1 t
k−1
(cid:16) (cid:17)−1(cid:16) (cid:17)
J˜ = J˜ + λ+h˜TP˜ h˜ ∆f −J˜ h˜ h˜TP˜
k k−1 k−1 k−1 k−1
(cid:18) (cid:19)
1 (cid:16) (cid:17)−1(cid:16) (cid:17)
P˜ = P˜ − λ+h˜TP˜ h˜ P˜ h˜h˜TP˜
k k−1 k−1 k−1 k−1
λ
Calculate the switching parameter ϕ
k
if (cid:107)f (cid:107) < sw (= υ(cid:107)f (cid:107)) then
k crit 1
ϕ = 0
k
else
ϕ = 1
k
ˆ
Select algorithms for update the residual S
k
ALG 1: DBFGS (switching DBFGS-DB)
ALG 2: DFN-BFGS (switching DFN-BFGS-DB)
ALG 3: MBFGS (switching MBFGS-DB)
ALG 4: Fu Method (switching Fu-DB)
end if
´
Calculate H
s,k
H´ = JˆTJˆ +ϕ Sˆ
k k k k k
Calculate: θ using the dynamic full quasi-Newton method
k+1
(cid:18) (cid:19)
(cid:16) (cid:17)−1 ∂f (t)
θ = θ − H´ JˆT f + k h
k+1 k k k k ∂t t
end for
Figure 6.2: Pseudo-code for the switching DBFGS-DB, DFN-BFGS-DB, MBFGS-
DB, and Fu-DB algorithms
160
settlingtimet butahigherRMStrackingerrorcomparedtotheDBM-RLSalgorithm
s
as shown in Table 6.5. One important observation is that all algorithms initially move
the EE away from the desired trajectory due to insuﬃcient information available at
the time for the control system to properly learn about its environment. This is the
nature of uncalibrated visual control since neither the robot kinematics nor the cam-
era models are known. The EE motion on the image space and task space views in
Figure 6.3e and Figure 6.4e shows that the MBFGS-DB algorithm quickly converges
to the desired target compared to other algorithms. This result is conﬁrmed in Figure
6.5 in which the MBFGS-DB algorithm starts moving toward the desired target at
a lower image error norm. Furthermore, the MBFGS-DB method yields the largest
step size and that in fact results in a faster settling time.
6.3.2 The Eﬀect of Partitioned and Non-Partitioned Broyden’s Estimator
for Approximating the Jacobian
The DBM-RLS algorithm in which the non-partitioned (NP) Broyden’s estimator
ˆ
is used to approximate J generates better results than the DGN-PBM algorithm
k
with the partitioned (P) Broyden’s method. The NP-Jacobian estimator residual
approximation in Table 6.5 is compared to the P-Jacobian estimation in Table 6.6.
Results from the switching algorithms using NP-Jacobian estimation are shown in
Table 6.6.
Thepreﬁx“NP”isusedtodistinguishtheswitchingalgorithmsusingnon-partitioned
ˆ ˜
Broyden’s estimator to calculate J the partitioned are where Jacobian J is utilized.
k
Figure 6.6 compares the switching MBFGS-DB and the switching NP-MBFGS-DB
algorithms. Results for the other switching algorithms are similar.
The NP Jacobian estimation provides better RMS tracking error with faster set-
tling time for most residual approximations except the switching NP-MBFGS-DB
algorithm where the settling time t is slightly longer. Since these algorithms provide
s
similar results, a faster angular speed ω = 0.9 rad/s of the circular target trajectory
161
Camera Space Camera Space
70    
80
60 70 Init Pos
50 60
50
40
X X40
30
30
20 Init Pos
20
EE Cam1 EE Cam1
10 EE Cam2 10 EE Cam2
Target Cam1 Target Cam1
0 Target Cam2 0 Target Cam2
   
−10 0 10 20 30 40 50 60 70 0 20 40 60 80
Y Y
(a) DBM-RLS (b) DGN-PBM
Camera Space Camera Space
   
50 EE Cam1 70
EE Cam2
45 TTaarrggeett  CCaamm12 60
40
50
35
40
X30 X
30
Init Pos
25 Init Pos
20
20
10 EE Cam1
15 EE Cam2
Target Cam1
10  0  Target Cam2
−20 −10 0 10 20 30 −10 0 10 20 30 40 50 60 70
Y Y
(c) DBFGS-DB (d) DFN-BFGS-DB
Camera Space Camera Space
   
EE Cam1 50
55
EE Cam2
45
50 Target Cam1
Target Cam2 40
45
35
40
30
35
25
X30 X
20
25 Init Pos
15
20
10
15 Init Pos EE Cam1
5
10 EE Cam2
0 Target Cam1
5 Target Cam2
   
−10 0 10 20 30 40 −20 −10 0 10 20 30 40
Y Y
(e) MBFGS-DB (f) Fu-DB
Figure 6.3: The camera space of the RRR manipulator with two eye-to-hand camera
conﬁgurations tracks a circular target trajectory moving at ω = 0.45 rad/s. The
forgetting factor is λ = 0.5 and υ = 0.3 for all algorithms except the switching Fu-DB
where υ = 0.5 is used.
162
Cartesian Space
Cartesian Space  
 
1 1
Init Pos
0.9 0.9
0.8 z0.8
z Init Pos
0.7
0.7
EE
target 0.6
0.6 EE
0.5 target
0.5 0.6
0.6 0.4 0.4 0.30.4
0.4 0.3 0.2
  0.2 0.2   0.2 0.1
y x y x
(a) DBM-RLS (b) DGN-PBM
Cartesian Space Cartesian Space
   
EE
target EE
target
1
0.8 Init Pos 0.9
0.7 0.8
Init Pos
0.6 z0.7
z 0.6
0.5
0.5
0.4 Target
0.4
0.3 0.4 0.6 0.4
0.3
0.6  0.5 0.4 0.2 x   0.4y 0.2 0.2 x
y
(c) DBFGS-DB (d) DFN-BFGS-DB
Cartesian Space Cartesian Space
   
EE
EE target
target
0.9 0.9
0.85 0.85
0.8 0.8
0.75 0.75Init Pos
Init Pos
z 0.7 0.7
z
0.65 0.65
0.6 0.6
Target
0.55 0.55
00..56 0.4 0.5 0.4
0.5 0.3 0.45 0.3
  0.4 0.2 0.6  0.5 0.4 0.2
y x x
y
(e) MBFGS-DB (f) Fu-DB
Figure 6.4: The task space view showing one camera and one target point for clar-
ity (the others are similar) for the RRR manipulator with two eye-to-hand cameras
tracking a circular target trajectory moving at ω = 0.45 rad/s. The forgetting factor
is λ = 0.5 and υ = 0.3 for all algorithms except the switching Fu-DB where υ = 0.5
is used.
163
Error Norm Error Norm
90   120  
80
100
70
els)60 els) 80
x x
Norm (pi4500 Norm (pi 60
or  or 
Err30 Err 40
20
20
10
0  0 
0 5 10 15 20 25 30 0 5 10 15 20 25 30
Time (s) Time (s)
(a) DBM-RLS (b) DGN-PBM
Error Norm Error Norm
45   100  
40 90
35 80
els)30 els) 70
Norm (pix2205 Norm (pix 5600
or  or  40
Err15 Err 30
10 20
5 10
0  0 
0 5 10 15 20 25 30 0 5 10 15 20 25 30
Time (s) Time (s)
(c) DBFGS-DB (d) DFN-BFGS-DB
Error Norm Error Norm
70   60  
60
50
els)50 els)40
x x
pi40 pi
orm ( orm (30
N30 N
or  or 
Err20 Err20
10
10
0  0 
0 5 10 15 20 25 30 0 5 10 15 20 25 30
Time (s) Time (s)
(e) MBFGS-DB (f) Fu-DB
Figure 6.5: The error norm of the RRR manipulator with two eye-to-hand camera
conﬁgurations tracks a circular target trajectory moving at ω = 0.45 rad/s. The
forgetting factor is λ = 0.5 and υ = 0.3 for all algorithms except the switching Fu-DB
where υ = 0.5 is used.
164
Camera Space Camera Space
   
55 55
50 50
45 45
40 40
35 35
X30 X30
25 25
20 20
15 15
10 10
5 5
   
−10 0 10 20 30 40 −10 0 10 20 30 40
Y Y
(a) MBFGS-DB (b) NP-MBFGS-DB
Cartesian Space Cartesian Space
   
EE
target
0.9
0.85 0.9 Init Pos
0.8 0.85
0.75 0.8
Init Pos
z 0.7 0.75
0.65 z 0.7
EE
0.6 0.65 target
Target
0.55 0.6
00..56 0.4 0.55 0.4
0.3
0.5 0.3 0.5
  0.4 0.2 0.6  0.5 0.4 0.2
y x x
y
(c) MBFGS-DB (d) NP-MBFGS-DB
Error Norm Error Norm
70   60  
Cam1 Cam1
Cam2 Cam2
60
50
els)50 els)40
x x
pi40 pi
orm ( orm (30
N30 N
or  or 
Err20 Err20
10
10
0  0 
0 5 10 15 20 25 30 0 5 10 15 20 25 30
Time (s) Time (s)
(e) MBFGS-DB (f) NP-MBFGS-DB
Figure 6.6: The performance comparison between the switching MBFGS-DB and
NP-MBFGS-DB algorithms (a)-(b) the image plane, (c)-(d) the task space view, and
(e)-(f) error norm of the RRR manipulator using two eye-to-hand cameras tracking a
circular target trajectory moving at ω = 0.45 rad/s. The forgetting factor is λ = 0.5
and υ = 0.3
165
ˆ
Table 6.6: The RMS error and the settling time comparison of various residual S
k
approximation schemes using NP-Jacobian estimation for θ = [60◦,70◦,50◦]T, ω =
0
0.45 rad/s, λ = 0.5, and υ = 0.3 for all algorithms except the Fu-DB algorithm where
υ = 0.5 is used.
is tested with the NP-Jacobian estimation. The RMS error and settling time are
summarized in Table 6.7.
ˆ
Table 6.7: The RMS error and the settling time comparison of various residual S
k
approximation schemes using NP-Jacobian estimation for θ = [60◦,70◦,50◦]T, ω =
0
0.9 rad/s, λ = 0.5, and υ = 0.3 for all algorithms.
Results from Table 6.7 show that all switching algorithms using the NP-Jacobian
approximation generate similar tracking performances. However, for an eye-in-hand
∂f
k
camera conﬁguration the dynamic error term cannot be estimated using a simple
∂t
ﬁrstorderdiﬀerenceasintheeye-to-handcameracasesincethemovingtargetfeatures
166
y∗ is now a function of both robot joint angles θ and time t. Thus the dynamic term
can only be approximated using the partitioned Broyden’s method. In that case the
switching MBFGS-DB algorithm is necessay. To validate tracking performance of the
eye-in-hand camera case the switching algorithms are tested using the PUMA 560
robot in Section 6.3.4.
6.3.3 The Eﬀect of Switching Criterion
The eﬀectiveness ofeach switching algorithmis considerablyinﬂuencedbythe switch-
ing criterion sw . This value determines when the residual approximation is in-
crit
cluded into the controller. Too great a value leads to an insuﬃcient number of iter-
ations with the inclusion of the residual calculation causing a small step size and a
longer settling time. Too small a value creates redundancy in inclusion of a residual
term that often leads to a longer settling time and divergence in the worse case.
Instabilityoccurswhentherobotjointanglesθ arecalculatedusingtheresidual
k+1
approximation algorithm for the small image error case. This is because residual
ˆ ˆ
approximation S is recursively calculated from the previous value S , and the
k k−1
ˆ
current S may not be diminished even if the actual residual is zero or becomes
k
relatively small. Thus, the estimation of θ is calculated with extraneous information
k
that does not represent the true nature of the system and results in deteriorated
tracking performance. One solution to this problem is the switching approach in
ˆ
which the residual approximation S is only included into the calculation of θ if
k k+1
the error norm (cid:107)f (cid:107) is greater than a speciﬁed switching criterion,
k
sw = υ(cid:107)f (cid:107)
crit 1
where υ ≥ 0.
ˆ
Newton’s method with residual S approximation has been proposed by Dennis et
k
ˆ ˆ
al. [17, 19] who suggest updating S from a scaled ςS where ς ≤ 1 (this algorithm
k k−1
is used in Fu’s method [25] and the switching Fu-DB algorithm.) The scaling factor ς
167
is introduced so that the residual term is properly terminated when f becomes zero,
k
(cid:40) (cid:41)
z∗T h
ς = min k−1 k−1 ,1
hT Sˆ h
k−1 k−1 k−1
so that
ˆ ˆ
S = ςS
k−1 k−1
ˆ
Then S is updated as
k
z∗ z∗ T Sˆ h hT Sˆ
Sˆ = Sˆ + k−1 k−1 − k−1 k−1 k−1 k−1
k k−1 g Th hT Sˆ h
k−1 k−1 k−1 k−1 k−1
where
z∗ = JˆTf −JˆT f
k−1 k k k−1 k
g = JˆTf −JˆT f
k−1 k k k−1 k−1
This strategy is implemented into the NL2SOL algorithm and details are presented in
[20]. This strategy is implemented into the switching MBFGS-DB algorithm shown
in the pseudo-code in Figure 6.7 and is referred to as the MBFGS-DB Scheme 1.
Unlike switching algorithms in which the residual term is either included into
or excluded from the controller, [49] proposed a hybrid method to systematically
calculate a weighted average between the Gauss-Newton (JˆTJˆ) and the residual
k k
ˆ ´
(S ) terms for Hessian H approximation (Section 4.7),
k k
H´ = JTJ +(1−κ )Sˆ
k k k k k
This hybrid method is only brieﬂy mentioned, without details, in [49] that κ is
k
updated based on how well the current quadratic model of the objective function F
k
can be trusted. Inspired by this idea, an analogous algorithm is used to readjust the
trust-region size presented in [25] for calculating κ .
k
168
Pseudo-code: The MBFGS-DB Scheme 1
Given: Rn → Rm ; θ ,θ ∈ Rn ; Jˆ ∈ Rm×n,P ∈ Rn×n,λ ∈ (0,1)
0 1 0 0
ˆ
Initialize: J , θ , θ , H and P
0 0 1 0 0
for k = 1,... do
ˆ
Calculate: J using a Jacobian estimation in the DGN-PBM algorithm [59]
k
∆f = f −f ; h = θ −θ
k k−1 k−1 k k−1
(cid:20) (cid:21)
(θ −θ )
h˜ = k k−1
(t −t )
k k−1
(cid:104) (cid:16) (cid:17) (cid:105)
J˜ = Jˆ fˆ
k−1 k−1 t
k−1
(cid:16) (cid:17)−1(cid:16) (cid:17)
J˜ = J˜ + λ+h˜TP˜ h˜ ∆f −J˜ h˜ h˜TP˜
k k−1 k−1 k−1 k−1
(cid:18) (cid:19)
1 (cid:16) (cid:17)−1(cid:16) (cid:17)
P˜ = P˜ − λ+h˜TP˜ h˜ P˜ h˜h˜TP˜
k k−1 k−1 k−1 k−1
λ
Calculate the scaling ς
(cid:40) (cid:41)
z∗T h
ς = min k−1 k−1 ,1
hT Sˆ h
k−1 k−1 k−1
ˆ
Update S
k−1
ˆ ˆ
S = ςS
k−1 k−1
ˆ
Update the residual S
k
z∗ z∗ T Sˆ h hT Sˆ
Sˆ = Sˆ + k−1 k−1 − k−1 k−1 k−1 k−1
k k−1 g Th hT Sˆ h
k−1 k−1 k−1 k−1 k−1
z∗ = JˆTf −JˆT f ; g = JˆTf −JˆT f
k−1 k k k−1 k k−1 k k k−1 k−1
´
Calculate H
s,k
H´ = JˆTJˆ +Sˆ
k k k k
Calculate: θ using the hybrid method proposed by [49]
k+1
(cid:18) (cid:19)
(cid:16) (cid:17)−1 ∂f (t)
θ = θ − H´ JˆT f + k h
k+1 k k k k ∂t t
end for
Figure 6.7: Pseudo-code for the MBFGS-DB Scheme 1 using a similar scaling method
presented in [17, 19]
169
Thevalueofκ isdeterminedaccordingtotheratior betweentheactualreduction
k
of the function F and the predicted value obtained from the quadratic model q , is
k k
1 1
q = fTf +(cid:0)JTf (cid:1)T h + hT (cid:0)JTJ (cid:1)h
k 2 k k k k k−1 2 k−1 k k k−1
The actual reduction of the objective function is
∆F = F −F
k−1 k
while, the predicted reduction is
∆q = F −q
k k+1
yielding the ratio r as
∆F
r =
∆q
Based on the value of r, κ is determined as
k


0 if r ≤ 0.25




κk = 1 if r ≥ 0.75





0.5 if otherwise
This method is integrated with the MBFGS algorithm and is referred to as the
MBFGS-DB Scheme 2. A summary of MBFGS-DB Scheme 2 is shown in the pseudo-
code in Figure 6.8.
To investigate the eﬀectiveness of these two schemes, they are compared with
the switching MBFGS-DB algorithm. Since the NP Broyden’s method demonstrates
better RMS tracking error with fast convergence compared to the partitioned Ja-
cobian approximation as discussed in Section 6.3.2, both partitioned (P) and the
non-partitioned (NP) Jacobian approximations are tested with MBFGS-DB Schemes
1 and 2.
Since all tests use the MBFGS method to, the “MBFGS” term is dropped. Table
6.8showsasummaryofthealgorithmsbeingtestedinthissection. TheRMStracking
170
Pseudo-code: The MBFGS-DB Scheme 2
Given: Rn → Rm ; θ ,θ ∈ Rn ; Jˆ ∈ Rm×n,P ∈ Rn×n,λ ∈ (0,1)
0 1 0 0
ˆ
Initialize: J , θ , θ , H and P
0 0 1 0 0
for k = 1,... do
ˆ
Calculate: J using a Jacobian estimation in the DGN-PBM algorithm [59]
k
∆f = f −f ; h = θ −θ
k k−1 k−1 k k−1
(cid:20) (cid:21)
(θ −θ )
h˜ = k k−1
(t −t )
k k−1
(cid:104) (cid:16) (cid:17) (cid:105)
J˜ = Jˆ fˆ
k−1 k−1 t
k−1
(cid:16) (cid:17)−1(cid:16) (cid:17)
J˜ = J˜ + λ+h˜TP˜ h˜ ∆f −J˜ h˜ h˜TP˜
k k−1 k−1 k−1 k−1
(cid:18) (cid:19)
1 (cid:16) (cid:17)−1(cid:16) (cid:17)
P˜ = P˜ − λ+h˜TP˜ h˜ P˜ h˜h˜TP˜
k k−1 k−1 k−1 k−1
λ
Calculate the ratio r between the actual and the predicted
reduction of the function
1 1
q = fTf +(cid:0)JTf (cid:1)T h + hT (cid:0)JTJ (cid:1)h
k 2 k k k k k−1 2 k−1 k k k−1
1
F = fTf
k 2 k k
∆F = F −F
k−1 k
∆q = F −q
k k
∆F
r =
∆q
Calculate the weighting average φ
k

0 if r ≤ 0.25


κ = 1 if r ≥ 0.75
k

0.5 if otherwise
ˆ
Update the residual S using the MBFGS method
k
´
Calculate H
s,k H´ = JTJ +(1−κ )Sˆ
k k k k k
Calculate: θ using the hybrid method proposed by [49]
k+1
(cid:18) (cid:19)
(cid:16) (cid:17)−1 ∂f (t)
θ = θ − H´ JˆT f + k h
k+1 k k k k ∂t t
end for
Figure 6.8: Pseudo-code for the MBFGS-DB Scheme 2 using a hybrid method similar
to [49]
171
error and the settling time t are compared as shown in Table 6.9. The camera space
s
and the task space views are shown in Figure 6.9 and Figure 6.10 respectively.
Table 6.8: A summary of the MBFGS algorithm varying in Jacobian approximation
ˆ
and strategies for S inclusion using the RRR robot with two eye-to-hand cameras
k
starting at θ = [60◦,70◦,50◦]T with λ = 0.5.
0
From Table 6.9 the NP Jacobian estimator yields a smaller RMS error compared
to the partitioned one. Although the RMS error and settling time of the NP-Scheme
1 is similar to the NP-Switching algorithms, Figure 6.10 shows that both P- and NP-
Scheme 1 generate EE motion that deviates from the desired target plane. However,
the NP-Scheme 1 causes less deviation compared to the P-Scheme 1. The NP-Scheme
2 gives about the same RMS error but longer settling time compared to others as can
be seen on Figure 6.9. From these results, the switching algorithm either using P- or
NP-Jacobian approximation yields more desirable results compared to the Schemes 1
and 2.
The results of using the RRR robot with two eye-to-hand cameras to track one
feature point of the circular trajectory target suggest that the switching DFN-BFGS-
DB and the MBFGS-DB algorithms are the most eﬀective methods over the other
172
schemes. These results are improved if the NP-Jacobian approximation is utilized.
The heuristic selection of the switching criterion υ demonstrates better RMS tracking
error and settling time as compared to the other existing algorithms (Schemes 1 and
2). To further investigate the performance of the switching algorithms a 6 DOF robot
is used in Section 6.3.4.
Table 6.9: The RMS error and the settling time comparison between the switching,
Scheme 1, and Scheme 2 MBFGS-DB algorithms with/without partitioned Broyden’s
method.
6.3.4 The PUMA 560 Robot
A six DOF Puma 560 manipulator with one eye-in-hand camera (using the MATLAB
Robotics and Machine Vision Toolboxes [10]) is used in this section for validating the
proposed switching algorithms with diﬀerent camera conﬁgurations. The intrinsic pa-
rametersofthecameraarethesameasinTable6.3. Thetargetconsistsoffourfeature
pointsattheverticesofa50mmsquare. Tomaketheend-eﬀectorandtargettrajecto-
ries visually distinct they are oﬀset by a constant vector [−393.7,19.9,142]T mm. The
startingrobotjointanglesareθ = [15.73◦,132.5◦,−135.6◦,−4.27◦,−108.75◦,14.27◦]T
0
for all tests simulated in this section. The end-eﬀector camera has a 10 mm focal
length and is coincident with the ﬁnal frame of the robot. The sampling time is
173
Camera Space Camera Space
   
55 EE Cam1 55
EE Cam2
50 Target Cam1 50
Target Cam2
45 45
40 40
35 35
X30 X30 Init Pos
25 25
20 20
15 Init Pos 15 EE Cam1
10 10 EE Cam2
Target Cam1
5 5 Target Cam2
   
−10 0 10 20 30 40 −10 0 10 20 30 40
Y Y
(a) P-Switching (b) NP-Switching
Camera Space Camera Space
   
55 55
50 50
45 45
Init Pos
40 40
35 35
X30 X30
25 25 Init Pos
20 20
15 EE Cam1 15 EE Cam1
10 EE Cam2 10 EE Cam2
Target Cam1 Target Cam1
5 Target Cam2 5 Target Cam2
   
−10 0 10 20 30 40 −20 −10 0 10 20 30 40
Y Y
(c) P-Scheme 1 (d) NP-Scheme 1
Camera Space Camera Space
  70  
80
70 Init Pos 60
60 50
50
40
X40 X
30
30 Init Pos
20
20
EE Cam1 EE Cam1
10 EE Cam2 10 EE Cam2
Target Cam1 Target Cam1
0 Target Cam2 0 Target Cam2
   
0 20 40 60 80 −10 0 10 20 30 40 50 60 70
Y Y
(e) P-Scheme 2 (f) NP-Scheme 2
Figure 6.9: The camera space of the RRR manipulator with two eye-to-hand cameras
using (a) P-Switching (υ = 0.3), (b) NP-Switching (υ = 0.3), (c) P-Scheme 1, (d)
NP-Scheme 1, (e) P-Scheme 2, and (f) NP-Scheme 2. A circular target trajectory is
moving at ω = 0.45 rad/s. The forgetting factor is λ = 0.5.
174
Cartesian Space Cartesian Space
   
EE
target
0.9
0.85 0.9 Init Pos
0.8 0.85
0.75 0.8
Init Pos
z 0.7 0.75
0.65 z 0.7
EE
0.6 0.65 target
Target
0.55 0.6
00..56 0.4 0.55 0.4
0.3
0.5 0.3 0.5
  0.4 0.2 0.6  0.5 0.4 0.2
y x x
y
(a) P-Switching (b) NP-Switching
Cartesian Space Cartesian Space
   
EE EE
0.9 target 0.9 target
0.85
0.85
0.8
0.8
0.75 Init Pos
0.7 0.75 Init Pos
z0.65 z 0.7
0.6 0.65
0.55 EE motion is out
0.6 of the target plane
0.5
0.55
0.45
0.5
0.4   
0.4 0.5 0.6 0.35 0.4 0.45 0.5 0.55 0.6
y y
(c) P-Scheme 1 (d) NP-Scheme 1
Cartesian Space Cartesian Space
   
EE 1 EE
1 target target
0.9
0.9 0.8
0.7
0.8 Init Pos
z z0.6
0.7 0.5
Init Pos
0.6 0.4
0.3
0.5
0.4 0.4
0.2   00..32  
0.6 0.5 0.4 0.3 0.2 0.1 0.6 0.4 0.2
x y x y
(e) P-Scheme 2 (f) NP-Scheme 2
Figure 6.10: The task space view showing one camera and one target point using (a)
P-Switching (υ = 0.3), (b) NP-Switching (υ = 0.3), (c) P-Scheme 1, (d) NP-Scheme
1, (e) P-Scheme 2, and (f) NP-Scheme 2. A circular target trajectory is moving at
ω = 0.45 rad/s. The forgetting factor is λ = 0.5
175
h = 50 ms. The initial Jacobian is estimated by successively perturbing each joint
t
by a small angle.
Three translational target trajectories are investigated in this section,
1. Circular trajectory
2. Cycloidal trajectory
3. Helical trajectory
Circular Trajectory
A circular trajectory has the radius of R = 100 mm with an angular velocity of
ω = 0.45 rad/s and is generated by
x = 600 mm
y = −150+Rsin(ωkT) mm
z = 400+Rcos(ωkT) mm (6.4)
where k is the iteration number and T = 50 ms is the sampling period. The target
motion starts from the top of the circle and moves counterclockwise.
For each switching scheme the image view, the task space view, and the error
norm are shown in Figure 6.11, Figure 6.12, and Figure 6.13 respectively. These are
generated by using a ﬁxed forgetting factor λ = 0.5 and υ = 0.3 for all switching algo-
rithmsexceptfortheswitchingDBFGS-DBalgorithmwhereυ = 0.55isusedtoavoid
tracking failure. The RMS tracking error and the settling time t are summarized in
s
Table 6.10.
TheswitchingMBFGS-DB,DFN-BFGS-DB,andFu-DBalgorithmsgeneratesim-
ilar EE trajectories on the camera and task space as shown in Figure 6.11 and Figure
6.12 and have signiﬁcantly better RMS error and settling time values over the DGN-
PBM algorithm (Table 6.10). Although the DBFGS-DB gives a longer settling time
176
Camera Space
300
Target
200
100
0
−100
X Init Pos
−200
−300
−400
−500
−600
−200 −150 −100 −50 0 50 100 150 200 250
Y
(a) DGN-PBM
Camera Space Camera Space
220 200
200 Target 180
180 160 Target
160
140
140
X X120
120
100
100
80
80
60 60
Init Pos Init Pos
40 40
0 20 40 60 80 100 120 140 160 180 0 20 40 60 80 100 120 140 160 180
Y Y
(b) DBFGS-DB (c) DFN-BFGS-DB
Camera Space Camera Space
200 220
Target Target
180 200
180
160
160
140
140
X120 X Init Pos
120
100
100
80
80
60 60
Init Pos
40 40
0 20 40 60 80 100 120 140 160 180 0 20 40 60 80 100 120 140 160 180
Y Y
(d) MBFGS-DB (e) Fu-DB
Figure 6.11: The camera space of the PUMA 560 manipulator with an eye-in-hand
camera conﬁguration tracking four feature points of a circular target trajectory mov-
ing at ω = 0.45 rad/s. The forgetting factor is λ = 0.5 and υ = 0.3 (except the
DBFGS-DB υ=0.55).
177
 
0.7
0.6
0.5
z Init Pos
0.4
0.3 0.5
0.4
0.3
0 0.1 0.2
−0.1 0
  −0.2 −0.1
x
y
(a) DGN-PBM
   
0.8
0.7 0.7
0.6 0.6
z0.5 Init Pos z0.5 Init Pos
0.4 0.5 0.4 0.5
0.4 0.4
0.3 0.3
0.2 0.2
−0.05 0.1 −0.05 0.1
−−00. 1.1−5−00.2.25 −0.1 0 x −−00 .1.1−50.2 −0.1 0 x
y y
(b) DBFGS-DB (c) DFN-BFGS-DB
   
0.7 0.7
0.6 0.6
z0.5 Init Pos z0.5 Init Pos
0.4 0.5 0.4 0.5
0.4 0.4
0.3 0.3
0.2 0.2
−0.05 0.1 −0.05 0.1
−−0 0.1.1−50.2 −0.1 0 x −−00. 1.1−50.2 −0.1 0 x
y y
(d) MBFGS-DB (e) Fu-DB
Figure 6.12: The task space view showing camera and one target point for clarity
(the others are similar) for the PUMA 560 manipulator with an eye-in-hand camera
conﬁguration tracking four feature points of a circular target trajectory moving at
ω = 0.45 rad/s. The forgetting factor is λ = 0.5 and υ = 0.3 (except the DBFGS-DB
υ=0.55).
178
Error Norm
700
600
s)500
el
x
pi400
m (
or
N300
or 
Err200
100
0
0 10 20 30 40 50
Time (s)
(a) DGN-PBM
Error Norm Error Norm
140 140
120 120
s)100 s)100
el el
x x
pi 80 pi 80
m ( m (
or or
N 60 N 60
or  or 
Err 40 Err 40
20 20
0 0
0 10 20 30 40 50 0 10 20 30 40 50
Time (s) Time (s)
(b) DBFGS-DB (c) DFN-BFGS-DB
Error Norm Error Norm
140 140
120 120
s)100 s)100
el el
x x
pi 80 pi 80
m ( m (
or or
N 60 N 60
or  or 
Err 40 Err 40
20 20
0 0
0 10 20 30 40 50 0 10 20 30 40 50
Time (s) Time (s)
(d) MBFGS-DB (e) Fu-DB
Figure 6.13: The error norm of the PUMA 560 manipulator with an eye-in-hand cam-
era conﬁguration tracking four feature points of a circular target trajectory moving at
ω = 0.45 rad/s. The forgetting factor is λ = 0.5 and υ = 0.3 (except the DBFGS-DB
υ=0.55).
179
ˆ
Table 6.10: The RMS error and the settling time comparison of various residual S
k
approximation schemes for tracking the circular trajectory using a ﬁxed forgetting
factor λ = 0.5.
than the other switching methods, it provides improved tracking performance com-
pared to the DGN-PBM algorithm as shown in Figure 6.13.
Note that for an eye-in-hand camera conﬁguration the image error f is a function
k
∂f
k
of both robot joint angles θ and time t in which the dynamic term can only
k
∂t
be estimated using the partitioned Broyden’s estimator. Therefore, the DBM-RLS
algorithm and the switching algorithms using the NP Broyden’s estimator are not
included in this section.
ˆ
To investigate alternative methods for including the residual S , Scheme 1 and
k
Scheme 2 are tested with the residual approximation methods. The image view and
the task space view of the EE motion of the DBFGS-DB, DFN-BFGS-DB, MBFGS-
DB, and Fu-DB using Scheme 1 and 2 are shown in Figure 6.14, Figure 6.15, Figure
6.16, and Figure 6.17 respectively.
With all approaches Scheme 1 fails to converge if λ = 0.5 is used. Therefore, an
alternating forgetting factor method is utilized in which λ = 0.5 is applied during the
transient state and λ = 0.98 is employed if the EE reaches the steady-state tracking.
The forgetting factor λ = 0.5 is applied for all residual approximations with Scheme
2.
180
Camera Space
220  
200 Target
180
0.8
160
0.7
140
X
0.6
120
z Init Pos
0.5
100
80 0.4 0.5
0.4
EE 0.3
60 target 0.2
400 20 40 60 80Init P1o0s0 120 140 160 180 −0.0−5−00. 1.1−5−00.2.25 −0.1 0 0x.1
Y y
(a) Switching DBFGS-DB (b) Switching DBFGS-DB
Camera Space
250  
Target
200 EE
target
150
0.7
100
X 0.6
50 z
0.5 Init Pos
0 Init Pos 0.4
0.5
0.4
−50 0.3
0 0.1 0.2
−0.1 0
−100   −0.2 −0.1
0 50 100 150 200 250 300 350 400 450 x
Y y
(c) DBFGS-DB Scheme 1 (d) DBFGS-DB Scheme 1
Camera Space
300  
Target
200
100
0.7
X 0 0.6
z0.5 Init Pos
−100 Init Pos
0.4
0.5
0.4
−200 EE 0.3
0 target 0.1 0.2
−0.1 0
−3−00200 −150 −100 −50 0 50 100 150 200   −0.2 −0.1 x
Y y
(e) DBFGS-DB Scheme 2 (f) DBFGS-DB Scheme 2
Figure 6.14: The camera space (left column) and the task space (right column) views
of the PUMA 560 robot tracking four feature points of a circular trajectory using the
DBFGS-DB with Scheme 1 and 2.
181
Camera Space
200  
180 EE
target
160 Target
140 0.7
X120 0.6
100 z0.5 Init Pos
80 0.4 0.5
0.4
0.3
60 0.2
Init Pos −0.05 0.1
400 20 40 60 80 100 120 140 160 180 −−00 .1.1−50.2 −0.1 0 x
Y y
(a) Switching DFN-BFGS-DB (b) Switching DFN-BFGS-DB
Camera Space
200  
Target
180 EE
target
160
140 0.7
X120 0.6
100 z0.5 Init Pos
80 0.4 0.5
0.4
0.3
60 0.2
Init Pos −0.0−5−00.1.15 0 0.1
40   −0.2 −0.1
0 20 40 60 80 100 120 140 160 180 −0.25 x
Y y
(c) DFN-BFGS-DB Scheme 1 (d) DFN-BFGS-DB Scheme 1
Camera Space
300  
Target
200
100 0.7
0.6
X 0
z0.5
Init Pos
−100 Init Pos 0.4
0.5
−200 0.1 EE 0.3 0.4
0 target 0.1 0.2
−0.1 0
−300   −0.2 −0.1
−200 −150 −100 −50 0 50 100 150 200 250 x
Y y
(e) DFN-BFGS-DB Scheme 2 (f) DFN-BFGS-DB Scheme 2
Figure 6.15: The camera space (left column) and the task space (right column) views
of the PUMA 560 robot tracking four feature points of a circular trajectory using the
DFN-BFGS-DB with Scheme 1 and 2.
182
Camera Space
200  
Target
180 EE
target
160
140 0.7
X120 0.6
100 z0.5 Init Pos
80 0.4 0.5
0.4
0.3
60 0.2
400 20 40 60 80Init P1o0s0 120 140 160 180 −0.0−5−0 0.1.1−50.2 −0.1 0 0x.1
Y y
(a) Switching MBFGS-DB (b) Switching MBFGS-DB
Camera Space
200  
Target
180 EE
target
160
140 0.7
X120 0.6
100 z0.5 Init Pos
80 0.4 0.5
0.4
60 0.3 0.2 0.3
400 20 40 60 80Init P1o0s0 120 140 160 180 −0.0−5−00 .1.1−50.2 −0.1 0 0x.1
Y y
(c) MBFGS-DB Scheme 1 (d) MBFGS-DB Scheme 1
Camera Space
200  
Target
150
EE
100 target
50
0.7
0
X −50 0.6
−100 z0.5 Init Pos
Init Pos
−150 0.4
0.5
−200 0.4
0.3
0.2
−250 0 0.1
−0.1 0
−3−00200 −150 −100 −50 0 50 100 150 200   −0.2 −0.1 x
Y y
(e) MBFGS-DB Scheme 2 (f) MBFGS-DB Scheme 2
Figure 6.16: The camera space (left column) and the task space (right column) views
of the PUMA 560 robot tracking four feature points of a circular trajectory using the
MBFGS-DB with Scheme 1 and 2.
183
Camera Space
220  
Target
200 EE
target
180
160
0.7
140
X Init Pos 0.6
120
z0.5 Init Pos
100
0.4 0.5
80 0.4
0.3
60 0.2
−0.05 0.1
400 20 40 60 80 100 120 140 160 180 −−00. 1.1−50.2 −0.1 0 x
Y y
(a) Switching Fu-DB (b) Switching Fu-DB
Camera Space
600  
500 Target
400 0.8
0.7
300
0.6
X z
200 0.5
Init Pos
0.4
100
EE
0 target 0.6
0 0.4
Init Pos −0.2 0.2
−100   −0.4 0
−100 0 100 200 300 400 500 600 700 y x
Y
(c) Fu-DB Scheme 1 (d) Fu-DB Scheme 1
Camera Space
200  
Target
150 EE
target
100
50 Init Pos
0.7
0
0.6
X −50
z0.5
−100 Init Pos
−150 0.4
0.5
−200 0.3 0.4
0.3
−250 0 0.1 0.2
−0.1 0
−3−00200 −150 −100 −50 0 50 100 150 200 250   −0.2 −0.1 x
Y y
(e) Fu-DB Scheme 2 (f) Fu-DB Scheme 2
Figure 6.17: The camera space (left column) and the task space (right column) views
of the PUMA 560 robot tracking four feature points of a circular trajectory using the
Fu-DB with Scheme 1 and 2.
184
ˆ
Table 6.11: The RMS error and the settling time comparison of various residual S
k
approximation schemes with ALT Scheme 1 and 2.
Table 6.11 summarizes the results. The DBFGS-DB with Scheme 1, the Fu-DB
with the both Scheme 1 and 2 generate tracking failure (TF). As seen in Figure 6.14,
the DBFGS-DB Scheme 1 initially moves the EE toward the desired trajectory but
fails to follow the desired path and the robot eventually stops. The DBFGS-DB
Scheme 2, on the other hand, converges and follows the target trajectory but its EE
path is not as direct as the switching algorithm.
The DFN-BFGS-DB and MBFGS-DB with Scheme 1 and 2 oﬀer similar tracking
results where Scheme 1 generates a more direct path from the robot starting location
to the target compared to Scheme 2 as shown in Figure 6.15 and Figure 6.16. Never-
theless, Scheme 1 has worse tracking accuracy than Scheme 2. The switching scheme
delivers the most desirable RMS error and convergence time over Scheme 1 and 2.
1Tracking failure
185
From Figure 6.17 neither Scheme 1 nor Scheme 2 succeed in tracking even though
both methods initially move the EE toward the target. In contrast, the switching
method has the fastest convergence and the smallest RMS tracking errors compared
to Scheme 1 and Scheme 2.
Since the switching DFN-BFGS-DB, DBFGS-DB, and MBFGS-DB algorithms
give similar results a the faster angular speed ω = 0.9 rad/s is used. Table 6.12
summarizes the RMS error and t of each switching algorithm using λ = 0.5 while
s
diﬀerentvaluesofυ arerequiredforconvergence. Thetaskspaceviewandtheaverage
error norm are shown in Figure 6.18 and Figure 6.19 respectively.
ˆ
Table 6.12: The RMS error and the settling time comparison of various residual S
k
approximationschemesfortrackingfourfeaturepointsofacirculartrajectorymoving
at ω = 0.9 rad/s using a ﬁxed λ = 0.5 and υ selected to ensure convergence.
The switching DFN-BFGS-DB and MBFGS-DB provide similar results and out-
performs the other algorithms. A more diﬃcult path is then used to investigate the
eﬀectiveness of these algorithms.
186
Task Space
 
0.7
0.6
z0.5 Init Pos
0.4 0.5
0.4
0.3
0.2
−0.05 0.1
−−0 0.1.1−50.2 −0.1 0 x
y
(a) DGN-PBM
Task Space Task Space
   
0.7 0.7
0.6 0.6
Init Pos
z0.5 z0.5
0.6
0.4 EE 0.4 0.4 0.4 0.5
target 0.2 0.2 0.3
−0.0−5−0 0.1.1−5−00.2.25 −0.2 0 x −0.0−5−0 0.1.1−50.2 −0.1 0 0x.1
y y
(b) DBFGS-DB (c) DFN-BFGS-DB
Task Space Task Space
   
0.7 0.7
0.6 0.6
z0.5 Init Pos z0.5 Init Pos
0.4 0.5 0.4 0.5
0.4 0.4
0.3 0.3
0.2 0.2
−0.05 0.1 −0.05 0.1
−−00.1.15 0 −−00.1.15 0
  −−00.2.25 −0.1 x   −−00.2.25 −0.1 x
y y
(d) MBFGS-DB (e) Fu-DB
Figure 6.18: The task space view showing camera and one target point for clarity
(the others are similar) for the PUMA 560 manipulator with an eye-in-hand camera
conﬁgurationtrackingfourfeaturepointsofacirculartargettrajectorymovingatω =
0.90 rad/s. The forgetting factor is λ = 0.5 and υ is selected to ensure convergence.
187
Error Norm
350
300
s)250
el
x
pi200
m (
or
N150
or 
Err100
50
0
0 10 20 30 40 50
Time (s)
(a) DGN-PBM
Error Norm Error Norm
180 140
160
120
140
els)120 els)100
x x
m (pi100 m (pi 80
Nor 80 Nor 60
or  or 
Err 60 Err 40
40
20
20
0 0
0 10 20 30 40 50 0 10 20 30 40 50
Time (s) Time (s)
(b) DBFGS-DB (c) DFN-BFGS-DB
Error Norm Error Norm
140 200
180
120
160
s)100 s)140
el el
pix 80 pix120
orm ( orm (100
N 60 N
or  or  80
Err 40 Err 60
40
20
20
0 0
0 10 20 30 40 50 0 10 20 30 40 50
Time (s) Time (s)
(d) MBFGS-DB (e) Fu-DB
Figure 6.19: The error norm of the PUMA 560 manipulator with an eye-in-hand
camera conﬁguration tracking four feature points of a circular target trajectory mov-
ing at ω = 0.90 rad/s. The forgetting factor is λ = 0.5 and υ is selected to ensure
convergence.
188
Cycloidal Trajectory
To further investigate the performance of the switching algorithms a more complex
cycloid trajectory is generated in the Z-Y plane of Cartesian space,
x = 600 mm
π
y = −150+100sin(kT)+200sin(0.25kT + ) mm
2
π
z = 400+100sin(kT + )+200sin(0.25kT) mm (6.5)
2
The same PUMA 560 robot with the eye-in-hand camera conﬁguration used for
the circular trajectory is also used in these simulations. The sampling period is
T = 50 ms. The initial robot conﬁguration is also the same as in the circular trajec-
tory with θ = [15.73◦,132.5◦,−135.6◦,−4.27◦,−108.75◦,14.27◦]T. To make the end-
0
eﬀector and target trajectories visually distinct they are oﬀset by a constant vector
[400,−18.09,−141.3]T mm. The forgetting factor λ = 0.5 is used for all algorithms.
Since the switching method employing the heuristic switching value results in
better tracking performance compared to Schemes 1 and 2 in the circular trajectory,
only the switching method is implemented with a variety of residual approximation
algorithms. However, diﬀerent values of the switching parameter υ are required for
each residual approximation approach to achieve convergence. The camera view, the
task space view, and the RMS tracking error are presented in Figure 6.20, Figure
6.21, and Figure 6.22 respectively.
Table 6.13 reveals that the switching MBFGS-DB algorithm gives the fastest con-
vergence with an RMS tracking error similar to the other algorithms. This result is
clearly seen in Figure 6.21 where the MBFGS-DB algorithm moves the EE directly
to the target plane.
189
Camera Space
300
250 Target
200
150
100
X
50
0
Init Pos
−50
−100
−150
−200 −150 −100 −50 0 50 100 150 200 250
Y
(a) DGN-PBM
Camera Space Camera Space
350 250
Target
300
200
250
150
200
X X
150
100
100
50
50
Init Pos Init Pos
0 0
−200 −150 −100 −50 0 50 100 150 200 250 −150 −100 −50 0 50 100 150 200 250
Y Y
(b) DBFGS-DB (c) DFN-BFGS-DB
Camera Space Camera Space
250 300
Target
250 Target
200
200
150
X X150
100
100
50
50
Init Pos Init Pos
0 0
−150 −100 −50 0 50 100 150 200 −200 −150 −100 −50 0 50 100 150 200 250
Y Y
(d) MBFGS-DB (e) Fu-DB
Figure 6.20: The camera space of the PUMA 560 manipulator with an eye-in-hand
camera conﬁguration tracks four feature points of a cycloid target trajectory. The
forgetting factor is λ = 0.5 and υ is selected to ensure convergence.
190
 
0.8
0.7
0.6
z0.5
0.4 Init Pos
0.3
0.2
0.6
EE
0 target 0.4
−0.2 0.2
  −0.4 0
y x
(a) DGN-PBM
   
0.8
0.8
0.7
0.7
0.6
0.6
z0.5 z0.5
0.4 0.4 Init Pos
0.3 Init Pos 0.3
0.2 0.2
0.6
EE 0.4 EE 0.6
0 target 0.2 0 target 0.4
−0.2 0 −0.2 0.2
  −0.4 −0.2   −0.4 0
y x y x
(b) DBFGS-DB (c) DFN-BFGS-DB
   
0.8
0.7 0.8
0.6 0.7
z0.5 0.6
0.4 Init Pos z0.5
0.4
0.3
0.3
0.2 EE 0.6
0.2 target 0.4
EE 0.6 0.2
0 target 0.4 0 0
  −0.2 −0.4 0 0.2   −0.2−0.4 −0.6 −0.4 −x0.2
y x y
(d) MBFGS-DB (e) Fu-DB
Figure 6.21: The task space view showing camera and one target point for clarity
(the others are similar) for the PUMA 560 manipulator with an eye-in-hand camera
conﬁgurationtrackingfourfeaturepointsofacycloidtargettrajectory. Theforgetting
factor is λ = 0.5 and υ is selected to ensure convergence.
191
Error Norm
350
300
s)250
el
x
pi200
m (
or
N150
or 
Err100
50
0
0 10 20 30 40 50
Time (s)
(a) DGN-PBM
Error Norm Error Norm
350 300
300
250
els)250 els)200
x x
pi200 pi
orm ( orm (150
N150 N
or  or 
Err100 Err100
50
50
0 0
0 10 20 30 40 50 0 10 20 30 40 50
Time (s) Time (s)
(b) DBFGS-DB (c) DFN-BFGS-DB
Error Norm Error Norm
300 300
250 250
els)200 els)200
x x
pi pi
orm (150 orm (150
N N
or  or 
Err100 Err100
50 50
0 0
0 10 20 30 40 50 0 10 20 30 40 50
Time (s) Time (s)
(d) MBFGS-DB (e) Fu-DB
Figure 6.22: The error norm of the PUMA 560 manipulator with an eye-in-hand
camera conﬁguration tracks four feature points of a cycloid target trajectory. The
forgetting factor is λ = 0.5 and υ is selected to ensure convergence.
192
ˆ
Table 6.13: The RMS error and the settling time comparison of various residual S
k
approximation schemes for tracking the cycloidal trajectory using a ﬁxed forgetting
factor λ = 0.5 and υ selected to ensure convergence.
A faster speed of cycloidal trajectory is also tested,
x = 725 mm
π
y = −260+100sin(3kT)+300sin(0.3kT + ) mm
2
π
z = 220+100sin(3kT + )+300sin(0.3kT) mm (6.6)
2
Only the switching DFN-BFGS-DB and MBFGS-DB are tested due to their sim-
ilar performances that are better than the other algorithms. Due to the complexity
and speed of this trajectory, a smaller sampling period T = 25 ms is used while for
the alternating forgetting factor λ = 0.5 is utilized during the transient portion and
λ = 0.95 is applied during steady-state tracking. These results are compared with
the DGN-PBM algorithm in Table 6.14. The task space view and average error norm
are shown in Figure 6.23.
The switching MBFGS-DB algorithm yields the smallest RMS error with less
large-error spikes as compared to the switching DFN-BFGS-DB and the DGN-PBM
193
Task Space Error Norm
  300
250
Large error
0.6
els)200
0.4 pix
z0.2 Init Pos orm (150
N
0 Error 100
EE
0 target 0.6 50
−0.2 0.4
−0.4 0.2
  y −0.6 0 x 00 5 10 Tim1e5 (s) 20 25 30
(a) DGN-PBM Task Space (b) DGN-PBM Avg Error Norm
Task Space Error Norm
  300
250
0.6 els)200 Large error
x
0.4 pi
z0.2 Init Pos orm (150
N
0 Error 100
0 EtaErget 0.6 50
−0.2 0.4
−0.4 0.2
  y −0.6 0 x 00 5 10 Tim1e5 (s) 20 25 30
(c) DFN-BFGS-DB Task Space (d) DFN-BFGS-DB Avg Error Norm
Task Space Error Norm
  300
250
0.6
0.4 xels)200
pi
z0.2 orm (150 Large error
N
0 or 
Err100
0 EE 50
−0.2 target 0.6
−0.4 0.2 0.4
  y −0.6 0 00 5 10 15 20 25 30
x Time (s)
(e) MBFGS-DB Task Space (f) MBFGS-DB Avg Error Norm
Figure 6.23: The camera space (left column) and the task space (right column) views
of the PUMA 560 robot tracking four feature points of a fast cycloidal trajectory.
194
ˆ
Table 6.14: The RMS error and the settling time comparison of various residual S
k
approximation schemes for tracking the cycloidal trajectory using a ﬁxed forgetting
factor λ = 0.5 and υ selected to ensure convergence.
algorithms as seen in Figure 6.23.
Helical Trajectory
To verify applicability of the switching MBFGS-DB algorithm for out-of-plane track-
ing a helical path is used with the same exact setup as described for the cycloidal
trajectory, the translational helix trajectory is
x = 600+v kT mm
x
y = −150+Rsin(ωkT) mm
z = 400+Rcos(ωkT) mm (6.7)
where R = 100 mm, v = 5 mm/s is the speed in the x direction, ω = 0.45 rad/s is
x
the angular velocity, k is the iteration number, and T = 50 ms is the sampling period.
Although v seems to be small, the helical path can be generated within the robot
x
working space for a longer period. A faster v is tested later. The target motion starts
x
from the top of the helix and moves counterclockwise in the positive x direction.
Tracking performance of the helical trajectory using the switching DFN-BFGS-
DB, MBFGS-DB, and Fu-DB are similar to one another and signiﬁcantly better
195
ˆ
Table 6.15: The RMS error and the settling time comparison of various residual S
k
approximation schemes for tracking the helical trajectory using a ﬁxed forgetting
factor λ = 0.5, v = 5 mm/s, and υ selected to ensure convergence.
x
than the DGN-PBM algorithm. In fact the helical trajectory tracking performance is
similar to the circular (in a plane) case.
Although the switching MBFGS-DB algorithm does not distinctively outperform
the switching DFN-BFGS-DB or the Fu-DB algorithms, it yields a smaller RMS
tracking error for the faster speed v = 10 mm/s as shown in Table 6.16. The
x
resultant task space views of the switching DFN-BFGS-DB, MBFGS-DB, and Fu-
DB algorithm with v = 10 mm/s are shown in Figure 6.27.
x
6.3.5 Conclusion
ˆ
A variety of residual S approximations improve tracking performance for large-
k
residual problems. The switching DFN-BFGS-DB and the MBFGS-DB algorithms
converge for a variety of trajectories using two distinct robots and diﬀerent camera
conﬁgurations. However, for the faster and the more complex trajectories the switch-
ing MBFGS-DB algorithm provides the best stability with RMS tracking errors and
196
Camera Space
300
Target
200
100
0
X−100
Init Pos
−200
−300
−400
−500
−150 −100 −50 0 50 100 150 200
Y
(a) DGN-PBM
Camera Space Camera Space
200 200
Target
180 180
160 160
140 140 Target
X120 X120
100 100
80 80
60 60
Init Pos Init Pos
40 40
0 20 40 60 80 100 120 140 160 180 0 20 40 60 80 100 120 140 160 180
Y Y
(b) DBFGS-DB (c) DFN-BFGS-DB
Camera Space Camera Space
200 200
Target Target
180 180
160 160
140 140
X120 X120
100 100
80 80
60 60
Init Pos Init Pos
40 40
0 20 40 60 80 100 120 140 160 180 0 20 40 60 80 100 120 140 160 180
Y Y
(d) MBFGS-DB (e) Fu-DB
Figure 6.24: The camera space of the PUMA 560 manipulator with an eye-in-hand
camera conﬁguration tracks four feature points of a helical target trajectory. The
forgetting factor is λ = 0.5, v = 5 mm/s, and υ is selected to ensure convergence.
x
197
Task Space
 
0.7
0.6
0.5
z Init Pos
0.4 0.8
0.3 0.6
0.4
0 0.2
−0.1 0
  −0.2 x
y
(a) DGN-PBM
Task Space Task Space
   
0.7 0.7
0.6 0.6
z0.5 Init Pos 0.8 z0.5 Init Pos 0.8
0.4 0.6 0.4 0.6
0.4 0.4
0.2 0.2
−0.0−−500. 1.1−50.2 0 x −0.0−−500. 1.1−50.2 0 x
y y
(b) DBFGS-DB (c) DFN-BFGS-DB
Task Space Task Space
   
EE
target
0.7 0.7
0.6 0.6
z0.5 Init Pos 0.8 z0.5 Init Pos 0.8
0.4 0.6 0.4 0.6
0.4 0.4
0.2 0.2
−0.05 −0.05
−−00 .1.1−50.2 0 x −−00. 1.1−50.2 0 x
y y
(d) MBFGS-DB (e) Fu-DB
Figure 6.25: The task space view showing camera and one target point for clarity
(the others are similar) for the PUMA 560 manipulator with an eye-in-hand camera
conﬁguration tracking four featurepoints of a helical target trajectory. Theforgetting
factor is λ = 0.5, v = 5 mm/s, and υ is selected to ensure convergence.
x
198
Error Norm
700
600
s)500
el
x
pi400
m (
or
N300
or 
Err200
100
0
0 10 20 30 40 50
Time (s)
(a) DGN-PBM
Error Norm Error Norm
140 140
120 120
s)100 s)100
el el
x x
pi 80 pi 80
m ( m (
or or
N 60 N 60
or  or 
Err 40 Err 40
20 20
0 0
0 10 20 30 40 50 0 10 20 30 40 50
Time (s) Time (s)
(b) DBFGS-DB (c) DFN-BFGS-DB
Error Norm Error Norm
140 140
120 120
s)100 s)100
el el
x x
pi 80 pi 80
m ( m (
or or
N 60 N 60
or  or 
Err 40 Err 40
20 20
0 0
0 10 20 30 40 50 0 10 20 30 40 50
Time (s) Time (s)
(d) MBFGS-DB (e) Fu-DB
Figure 6.26: The error norm of the PUMA 560 manipulator with an eye-in-hand
camera conﬁguration tracks four feature points of a helical target trajectory. The
forgetting factor is λ = 0.5, v = 5 mm/s, and υ is selected to ensure convergence.
x
199
Task Space Task Space
   
0.7
0.7
0.6
0.6
z0.5
0.4 Init Pos 0.8 z0.5 Init Pos 0.8
0.6 0.4 0.6
0.4 0.4
0.1 0 0.2 −0.05 0.2
  −0.1−0.2 0 x −−00. 1.1−50.2 0 x
y y
(a) DGN-PBM (b) DFN-BFGS-DB
Task Space Task Space
   
0.7 0.7
0.6 0.6
z0.5 0.8 z0.5 0.8
0.4 0.6 0.4 0.6
0.4 0.4
0.2 0.2
−0.05 −0.05
−−00. 1.1−50.2 0 x −−00. 1.1−50.2 0 x
y y
(c) MBFGS-DB (d) Fu-DB
Figure 6.27: The task space view showing one target point for clarity (the others are
similar) for the PUMA 560 manipulator with an eye-in-hand camera conﬁguration
tracking four feature points of a helical target trajectory moving with a faster speed
in x direction. The forgetting factor is λ = 0.5, v = 10 mm/s, and υ is selected to
x
ensure convergence.
200
ˆ
Table 6.16: The RMS error and the settling time comparison of various residual S
k
approximation schemes for tracking the helical trajectory using a ﬁxed forgetting
factor λ = 0.5, v = 10 mm/s, and υ selected to ensure convergence.
x
convergence times that are either the best or reasonably close to the best. These
performance depends on the selection of the switching parameter υ, which is heuris-
tically chosen in this study. The switching algorithms oﬀer better tracking stability
with smaller RMS error and settling time as compared to Schemes 1 and 2.
6.4 Performance Evaluation of the switching MBFGS-DB
Algorithm with LMA
TheswitchingMBFGS-DBalgorithmrequiresaninvertibleHessianmatrixforﬁnding
the robot joint angles θ at each iteration. An ill-conditioned or singular Hessian
k
ˆ
matrix H can lead to numerical problems resulting in slow or no convergence.
k
ˆ
In robotic tracking applications a singular Hessian matrix H can occur at a
k
kinematic singularity. The robot angles θ is a solution of
k
(cid:18) (cid:19)
∂f (t)
Hˆ h = −JˆT f + k h
k k k k ∂t t
ˆ
where h = θ −θ . If H is singular, there may exist an inﬁnite number of solutions
k k+1 k k
h and thus an inﬁnite number of robot conﬁgurations giving the same EE location.
k
201
This phenomenal occurs if the robot is at a kinematic singularity conﬁguration where
the robot loses one or more degrees of freedom. This problem may lead to to solutions
with unbounded joint velocities.
To improve upon Hessian ill-conditioning various switching algorithms are imple-
mented with the well-known LevenbergMarquardt algorithm (LMA). The LMA oﬀers
an alternate method for solving nonlinear optimization problems when the Hessian
ˆ
H or H is not positive deﬁnite or becomes ill-conditioning. This method modiﬁes
k k
theHessianmatrixtoensurepositivedeﬁnitenesstoovercomethisdeﬁciency. Though
this introduces nonphysical artifacts, it can improve eﬀectiveness near singularities.
The idea is to utilize a trust-region strategy for unconstrained optimization where
the Hessian is modiﬁed (see Section 2.3),
H = H +µ D
d,k k k k
where H is known as the modiﬁed Hessian matrix, µ is called the damping or the
d,k k
Levenberg-Marquardt parameter, and D is a diagonal matrix.
k
In this study the Hessian is approximated using the quasi-dynamic Broyden’s
ˆ ˆ
method for Jacobian J and the MBFGS method for residual S . The modiﬁed
k k
´
Hessian matrix H becomes
d,k
H´ = JˆTJˆ +ϕ Sˆ +µ D (6.8)
d,k k k k k k k
and the quadratic model q of the objective function F(θ,t) becomes
k
1 1
q = fTf +(cid:0)JTf (cid:1)T (θ−θ )+ (θ−θ )H´ (θ−θ ) (6.9)
k 2 k k k k k 2 k d,k k
The modiﬁed Newton’s method in Section 2.3 is used to solve (6.9) as
(cid:18) (cid:19)
(cid:16) (cid:17)−1 ∂f (t)
θ = θ − H´ JˆT f + k h (6.10)
k+1 k d,k k k ∂t t
where h = θ −θ satisﬁes
k k+1 k
(cid:107)h (cid:107) ≤ δ (6.11)
k k
202
and δ determines the size of the trust region.
k
The LMA updates µ and D for solutions q satisﬁng(6.11). There are various
k k k
strategies to calculate µ , D , and δ [19, 50]. Inspired by the implementation of the
k k k
LMA for large residual visual servoing in [25], which updates µ and D using Mor´e’s
k k
approach [47], the switching MBFGS-DB algorithm also follows this approach.
To adjust the trust region δ size according to how well the model q approximates
k k
the objective function F , [25] uses the strategy presented in [23]. The size depends
k
on the ratio r between the predicted and the actual reduction of image error. The
actual reduction of the objective function is
∆F = F −F (6.12)
k k−1
while, the predicted reduction is
∆q = F −q (6.13)
k k−1
and
∆F
r = (6.14)
∆q
The closer r is to unity, the better the approximation of F using the current model
k
q . The trust region size δ needs to be adjusted as
k k


0.5(cid:107)Dkhk(cid:107)2 if r ≤ 0.25



δk+1 = 2(cid:107)Dkhk(cid:107)2 if r ≥ 0.75





(cid:107)Dkhk(cid:107)2 if otherwise
To isolate the eﬀect of the LMA the ﬁxed forgetting factor λ = 0.5 is used in this
k
section for all tests.
6.4.1 RRR Robot
The same RRR robot with two eye-to-hand cameras presented in Section 6.3.1 is used
to track one feature point moving in the circular trajectory (6.1) with the starting
203
conﬁguration at θ = [60◦,70◦,50◦]T. Tracking performance is compared for various
0
ˆ
residual approximations with/without the LMA and J is approximated using par-
k
titioned (P-) and non-partitioned (NP-) Broyden’s estimators. The RMS tracking
error and the settling time t of each switching algorithm with/without the LMA im-
s
plementation are summarized in Table 6.17 for P-Broyden’s estimator and in Table
6.18 for NP-Broyden’s estimator.
Table 6.17: The RMS error and the settling time comparison of the RRR robot
ˆ
for various residual S approximation schemes with/without the LMA for θ =
k 0
[60◦,70◦,50◦]T, λ = 0.5, and υ = 0.3. The partitioned Broyden’s estimator is used
ˆ
for Jacobian J approximation.
k
All switching algorithms (except MBFGS-DB) using the P-Jacobian estimation
with the LMA implementation show improvement in faster convergence, and all have
slightly higher RMS tracking errors. In contrast, the LMA with NP-Jacobian estima-
tion generates worse results for both settling time and RMS error compared to not
including the LMA.
204
Table 6.18: The RMS error and the settling time comparison of the RRR robot
ˆ
for various residual S approximation schemes with/without the LMA for θ =
k 0
[60◦,70◦,50◦]T, λ = 0.5, and υ = 0.3. The NP Broyden’s estimator is used for
ˆ
Jacobian J approximation.
k
Various starting robot conﬁgurations listed in Table 6.19 are used to further eval-
uate performance of the switching MBFGS-DB with/without the LMA as shown in
Table 6.20. The camera and task space views are shown in Figure 6.28 and Figure
6.29.
Table 6.19: Various starting RRR robot conﬁgurations.
Implementing the LMA with the switching MBFGS-DB algorithm shows only
small improvement in convergence time for the second starting robot angles in Table
6.19 but it actually degrades the tracking performance for both settling time and the
205
Camera Space Camera Space
   
EE Cam1
55
70 EE Cam2
50 Target Cam1
Target Cam2
60 45
40
50
35
X40 X30
25
30
Init Pos
20
20 EE Cam1 15 Init Pos
EE Cam2 10
10 Target Cam1
Target Cam2 5
   
−10 0 10 20 30 40 50 60 70 −10 0 10 20 30 40
Y Y
(a) Position 1 LMA (b) Position 1 No LMA
Camera Space Camera Space
   
120
120
100
100
80
80
60
X Init Pos X 60
40
40 Init Pos
20
20
0
EE Cam1 EE Cam1
−20 ETaEr gCeatm C2am1 0 ETaEr gCeatm C2am1
Target Cam2 Target Cam2
   
0 20 40 60 80 100 120 140 160 180 −20 0 20 40 60 80 100 120 140 160
Y Y
(c) Position 2 LMA (d) Position 2 No LMA
Camera Space Camera Space
160   150  
140
Init Pos
120
100
100
80
X 60 X 50
40
Init Pos
20
0
0 EE Cam1 EE Cam1
EE Cam2 EE Cam2
−20
Target Cam1 Target Cam1
−40 Target Cam2 −50 Target Cam2
   
0 50 100 150 200 0 50 100 150 200
Y Y
(e) Position 3 LMA (f) Position 3 No LMA
Figure 6.28: The camera space comparison of implementing the switching MBFGS-
DB algorithm with the LMA (left column) and without the LMA (right column) at
various starting RRR robot conﬁgurations.
206
Task Space Cartesian Space
   
1 EE EE
target target
0.9
0.9
0.85
0.8 Init Pos 0.8
z 0.75
0.7 z 0.7 Init Pos
0.6 0.65
0.6
0.5 Target
0.55
0.6
0.5 0.5
0.4 0.4 0.6 0.4
0.3 0.5 0.3
  y 0.2 0.2 x   y 0.4 0.2 x
(a) Position 1 LMA (b) Position 1 No LMA
Task Space Task Space
   
1 1
0.9 Init Pos 0.9
0.8 0.8 Init Pos
z0.7 z0.7
0.6
0.6
0.5
0.5
0.4
0.6
0.4 0.6
0.2 0.4 EE
0 EtaErget 0.2 target
−0.2 0.4 0 0.4
0.2 −0.2 0.2
  y −0.4 0   y 0
x x
(c) Position 2 LMA (d) Position 2 No LMA
Task Space Task Space
   
EE EE
1 target 1 target
0.9 0.9
z0.8 z0.8
0.7 0.7
0.6 0.6 Init Pos
0.5 0.5
0.6 0.6
0.4 Init Pos 0.4
0.2 0.2
0 0
−0.2 0.4 −0.2
−0.4 0.2 −0.4 0.4
  y −0.6 0   y −0.6 0 0.2
x x
(e) Position 3 LMA (f) Position 3 No LMA
Figure 6.29: The camera space comparison of implementing the switching MBFGS-
DB algorithm with the LMA (left column) and without the LMA (right column) at
various starting RRR robot conﬁgurations.
207
Table6.20: TheRMSerrorandthesettlingtimecomparisonoftheswitchingMBFGS-
DB algorithm with/without the LMA using υ = 0.3 and λ = 0.5 at various starting
RRR robot conﬁgurations.
RMS tracking error for the other cases. Overall, the results show little advantage
to including the LMA into the switching algorithm for the large residual tracking
using the simple RRR robot. The PUMA 560 robot with an eye-in-hand camera
conﬁguration is used to further investigate the LMA performance.
6.4.2 PUMA 560 robot
The PUMA 560 robot with the eye-in-hand camera conﬁguration described in Sec-
tion 6.3.4 is used to track the circular trajectory in (6.4) switching algorithms with
the LMA. The settling time t and the RMS tracking error with/without LMA
s
are summarized in Table 6.21. The camera view, task space view, and the av-
erage RMS tracking error are shown in Figure 6.30, Figure 6.31, and Figure 6.32
respectively. All switching algorithms with the LMA employ the switching crite-
rion υ = 0.3 and the forgetting factor λ = 0.5. The starting robot conﬁguration is
θ = [15.73◦,132.5◦,−135.6◦,−4.27◦,−108.75◦,14.27◦]T.
0
AlthoughtheDGN-PBMalgorithmwiththeLMAyieldssmallerRMSerrorandt
s
compared to the DGN-PBM algorithm with/without the LMA in Table 6.21, the EE
motion in the task spaceofFigure 6.31adoes not follow the desired circular trajectory
208
Camera Space
200
Target
180
160
140
X120
100
80
60
Init Pos
40
0 20 40 60 80 100 120 140 160
Y
(a) DGN-PBM
Camera Space Camera Space
220 200
Target Target
200 180
180
160
160
140
140
X X120
120
100
100
80
80
60 60
Init Pos Init Pos
40 40
0 20 40 60 80 100 120 140 160 180 0 20 40 60 80 100 120 140 160
Y Y
(b) DBFGS-DB (c) DFN-BFGS-DB
Camera Space Camera Space
200 220
Target Target
180 200
180
160
160
140
140
X120 X
120
100
100
80
80
60 60
Init Pos Init Pos
40 40
0 20 40 60 80 100 120 140 160 0 20 40 60 80 100 120 140 160 180
Y Y
(d) MBFGS-DB (e) Fu-DB
Figure 6.30: The camera space of the PUMA 560 manipulator with the eye-in-hand
camera conﬁguration using various switching algorithms implemented with the LMA
to track four feature points of the circular target trajectory moving at ω = 0.45 rad/s
and υ = 0.3. The forgetting factor is λ = 0.5.
209
Task Space
 
0.7
0.6
Init Pos
z0.5
0.4 0.5
0.4
0.3
0.2
0.1
−−00.1 .1−50.2 −0.1 0 x
y
(a) DGN-PBM
Task Space Task Space
   
0.7 0.7
0.6 0.6
z0.5 Init Pos z0.5 Init Pos
0.4 0.5 0.4 0.5
0.4 0.4
0.3 0.3
0.2 0.2
−0.05 0.1 −0.05 0.1
−−0 0.1.1−50.2 −0.1 0 x −−0 0.1.1−50.2 −0.1 0 x
y y
(b) DBFGS-DB (c) DFN-BFGS-DB
Task Space Task Space
   
0.7 0.7
0.6 0.6
Init Pos Init Pos
z0.5 z0.5
0.4 0.5 0.4 0.5
0.4 0.4
0.3 0.3
0.2 0.2
−0.05 0.1 −0.05 0.1
−−0 0.1.1−50.2 −0.1 0 x −−0 0.1.1−50.2 −0.1 0 x
y y
(d) MBFGS-DB (e) Fu-DB
Figure 6.31: The task space view showing one target point for clarity (the others are
similar) for the PUMA 560 manipulator with an eye-in-hand camera conﬁguration
using various switching algorithms with the LMA tracking four feature points of a
circular target trajectory moving at ω = 0.45 rad/s. The forgetting factor is λ = 0.5
and υ = 0.3.
210
Error Norm
700
600
s)500
el
x
pi400
m (
or
N300
or 
Err200
100
0
0 10 20 30 40 50
Time (s)
(a) DGN-PBM
Error Norm Error Norm
140 140
120 120
s)100 s)100
el el
x x
pi 80 pi 80
m ( m (
or or
N 60 N 60
or  or 
Err 40 Err 40
20 20
0 0
0 10 20 30 40 50 0 10 20 30 40 50
Time (s) Time (s)
(b) DBFGS-DB (c) DFN-BFGS-DB
Error Norm Error Norm
140 140
120 120
s)100 s)100
el el
x x
pi 80 pi 80
m ( m (
or or
N 60 N 60
or  or 
Err 40 Err 40
20 20
0 0
0 10 20 30 40 50 0 10 20 30 40 50
Time (s) Time (s)
(d) MBFGS-DB (e) Fu-DB
Figure 6.32: The error norm of the PUMA 560 manipulator with an eye-in-hand
camera conﬁguration using various switching algorithms implemented with the LMA
to track four feature points of a circular target trajectory moving at ω = 0.45 rad/s.
The forgetting factor is λ = 0.5 and υ = 0.3.
211
ˆ
Table 6.21: The RMS error and the settling time comparison of various residual S
k
approximationschemesusingthePUMA560robottotrackacirculartrajectoryusing
λ = 0.5 and υ = 0.3.
at all. For the other switching algorithms the inclusion of the LMA yields faster
convergence time while the RMS error is slightly increased, similar to the RRR robot
case. Even though the switching MBFGS-DB and the DFN-BFGS-DB algorithms
with the LMA provide similar tracking performance, in Section 6.3 the switching
MBFGS-DB algorithm is shown as the most eﬀective in handling a diﬀerent of robot
degrees-of-freedom, camera conﬁgurations, and the target trajectory. Consequently
the switching MBGFS-DB algorithm is used to further evaluate the LMA for diﬀerent
robotstartingpositions. Table6.22summarizesthreeinitialrobotconﬁgurationsused
to track the circular trajectory, including the starting point used to generate results
in Table 6.21.
For all tests the switching criterion υ = 0.3 and λ = 0.5 are utilized. A summary
oftheswitchingMBFGS-DBwith/withouttheLMAalgorithmwithavarietyofrobot
starting positions is given in Table 6.23. The image plane and the task space (of one
212
Table 6.22: Various starting PUMA 560 robot conﬁgurations.
feature point) views of the MBFGS-DB with the LMA algorithm at various starting
positions are shown in Figure 6.33 and Figure 6.34.
Table 6.23: The RMS error and the settling time comparison for the switching
MBFGS-DB algorithm with/without the LMA approach using υ = 0.3 and λ = 0.5
at various starting PUMA 560 robot conﬁgurations tracking a circular trajectory.
The LMA only marginally improves the settling time while the RMS tracking
errors are slightly compromised.
FortheﬁnalLMAevaluationthecycloidaltargettrajectoryin(6.5)istestedusing
the switching MBFGS-DB with the LMA algorithm at the diﬀerent starting robot
conﬁgurations of Table 6.22. The switching criterion υ = 0.3 and λ = 0.5 are also
utilized for all robot starting positions.
Table 6.24 shows that the RMS error becomes substantial when the LMA is not
included for the second starting robot position. This is due to instability occurring
213
Camera Space Camera Space
200 200
Target Target
180 180
160 160
140 140
X120 X120
100 100
80 80
60 60
Init Pos Init Pos
40 40
0 20 40 60 80 100 120 140 160 0 20 40 60 80 100 120 140 160 180
Y Y
(a) Position 1 LMA (b) Position 1 No LMA
Camera Space Camera Space
200 260
Target
240
180
220 Target
160 200
180
X140 X
160
120 140
120
100
100
Init Pos Init Pos
80 80
20 40 60 80 100 120 140 160 180 20 40 60 80 100 120 140 160 180
Y Y
(c) Position 2 LMA (d) Position 2 No LMA
Camera Space Camera Space
250 200
Target
200 Target
150
150
100
X100 X
Init Pos
50
50 Init Pos
0
0
−50 −50
0 50 100 150 200 250 300 50 100 150 200 250 300
Y Y
(e) Position 3 LMA (f) Position 3 No LMA
Figure 6.33: The camera space comparison of the switching MBFGS-DB algorithm
with the LMA (left column) and without the LMA (right column) at various start-
ing PUMA 560 robot conﬁgurations tracking four feature points of a circular target
trajectory moving at ω = 0.45 rad/s, υ = 0.3, and λ = 0.5.
214
Task Space
   
0.7 0.7
0.6 0.6
z0.5 Init Pos z0.5 Init Pos
0.4 0.5 0.4 0.5
0.4 0.4
0.3 0.3
0.2 0.2
−0.05 0.1 −0.05 0.1
−−0 0.1.1−50.2 −0.1 0 x −−0 0.1.1−50.2 −0.1 0 x
y y
(a) Position 1 LMA (b) Position 1 No LMA
Task Space Task Space
   
0.7 0.7
0.6 0.6
z0.5 Init Pos z0.5
0.4 0.5 0.4 0.5
0.4 0.4
0.3 0.3
0.2 0.2
−0.0−5−0 0.1.1−50.2 −0.1 0 0.1x −0.0−5−0 0.1.1−50.2 −0.1 0 0.1x
y y
(c) Position 2 LMA (d) Position 2 No LMA
Task Space Task Space
   
0.7 0.7
0.6 0.6
z0.5 Init Pos z0.5 Init Pos
0.4 0.5 0.4 0.5
0.4 0.4
0.3 0.3
0.2 0.2
−0.05 0.1 −0.05 0.1
−−0 0.1.1−50.2 −0.1 0 x −−00 .1.1−50.2 −0.1 0 x
y y
(e) Position 3 LMA (f) Position 3 No LMA
Figure 6.34: The task space view showing one camera and one target point for clarity
for the switching MBFGS-DB algorithm with the LMA (left column) and without
the LMA (right column) at various starting PUMA 560 robot conﬁgurations tracking
four feature points of a circular target trajectory moving at ω = 0.45 rad/s, υ = 0.3,
and λ = 0.5.
215
Camera Space Camera Space
250 250
Target Target
200 200
150 150
X X
100 100
50 50
Init Pos Init Pos
0 0
−150 −100 −50 0 50 100 150 200 −150 −100 −50 0 50 100 150 200
Y Y
(a) Position 1 LMA (b) Position 1 No LMA
Camera Space Camera Space
250 800
Target Instability
700
200
600
500
150
X X400
100 Target
300
200 Init Pos
50
Init Pos
100
0 0
−100 −50 0 50 100 150 200 −100 −50 0 50 100 150 200 250 300
Y Y
(c) Position 2 LMA (d) Position 2 No LMA
Camera Space Camera Space
250 250
Target
Target
200 200
150 150
X100 X100
Init Pos Init Pos
50 50
0 0
−50 −50
0 50 100 150 200 250 300 −50 0 50 100 150 200 250 300
Y Y
(e) Position 3 LMA (f) Position 3 No LMA
Figure 6.35: The camera space comparison of the switching MBFGS-DB algorithm
with the LMA (left column) and without the LMA (right column) at various starting
PUMA 560 robot conﬁgurations tracking four feature points of a cycloidal target
trajectory using υ = 0.3 and λ = 0.5.
216
Task Space
   
0.8 0.8
0.7 0.7
0.6 0.6
z0.5 z0.5
0.4 Init Pos 0.4 Init Pos
0.3 0.3
0.2 0.2
0.6 0.6
EE EE
0 0.4 0 0.4
target target
−0.2 0.2 −0.2 0.2
  −0.4 0   −0.4 0
y x y x
(a) Position 1 LMA (b) Position 1 No LMA
Task Space Task Space
   
0.8 0.8
0.7 0.7
0.6 0.6
z0.5 z0.5
0.4 Init Pos 0.4 Init Pos
0.3 0.3
0.2 0.2
EE 0.6 EE 0.6
0 target 0.4 0 target 0.4
−0.2 0.2 −0.2 0.2
  −0.4 0   −0.4 0
y x y x
(c) Position 2 LMA (d) Position 2 No LMA
Task Space Task Space
   
0.8 0.8
0.7 0.7
0.6 0.6
z0.5 z0.5
0.4 Init Pos 0.4 Init Pos
0.3 0.3
0.2 0.2
0.6 0.6
EE EE
0 0.4 0 0.4
target target
−0.2 0.2 −0.2 0.2
  −0.4 0   −0.4 0
y x y x
(e) Position 3 LMA (f) Position 3 No LMA
Figure 6.36: The task space of the EE motion using the switching MBFGS-DB algo-
rithm with the LMA (left column) and without the LMA (right column) at various
starting PUMA 560 robot conﬁgurations tracking four feature points of a cycloidal
target trajectory using υ = 0.3 and λ = 0.5.
217
Error Norm Error Norm
300 300
250 250
els)200 els)200
x x
pi pi
orm (150 orm (150
N N
or  or 
Err100 Err100
50 50
0 0
0 10 20 30 40 50 0 10 20 30 40 50
Time (s) Time (s)
(a) Position 1 LMA (b) Position 1 No LMA
Error Norm Error Norm
250 600
500
200
els) els)400
pix150 pix
orm ( orm (300
N N
Error 100 Error 200 Instability
50
100
0 0
0 10 20 30 40 50 0 10 20 30 40 50
Time (s) Time (s)
(c) Position 2 LMA (d) Position 2 No LMA
Error Norm Error Norm
250 250
200 200
s) s)
el el
pix150 pix150
m ( m (
or or
N N
or 100 or 100
Err Err
50 50
0 0
0 10 20 30 40 50 0 10 20 30 40 50
Time (s) Time (s)
(e) Position 3 LMA (f) Position 3 No LMA
Figure 6.37: The RMS tracking error comparison of the switching MBFGS-DB algo-
rithm with the LMA (left column) and without the LMA (right column) at various
starting PUMA 560 robot conﬁgurations tracking four feature points of a cycloidal
target trajectory using υ = 0.3 and λ = 0.5.
218
Table 6.24: The RMS error and the settling time comparison for the switching
MBFGS-DB algorithm with/without the LMA using υ = 0.3 and λ = 0.5 at var-
ious starting PUMA 560 robot conﬁgurations tracking a cycloidal trajectory.
toward at the end as seen in Figure 6.35d for camera space view and is conﬁrmed by
average error norm plotted in Figure 6.37d. From this example, the LMA can help
improving tracking stability.
6.4.3 Conclusion
Despite the fact that the LMA shows little improvement in convergence and tracking
stabilityinamorecomplexcycloidaltrajectory,thisisatatrade-oﬀforincreasedRMS
tracking error. Overall performance for both RRR and PUMA 560 robot cases yield
similar results of marginal eﬀect implementing LMA into the switching algorithms
for large residual tracking problems. However, the RMS tracking error is signiﬁcantly
aﬀected by the value of the forgetting factor λ being used. As a result, various
methods are investigated to optimally select λ at each iteration in Section 6.5. Then
k
the eﬀect of the LMA implementation is revisited as it is used in conjunction of a
variable forgetting factor (VFF) algorithm to improve overall tracking performance.
2Instability occurs at the end of tracking
219
6.5 Performance Evaluations of the DAFF Method versus
the Existing VFF Algorithms
Although the switching MBFGS-DB algorithm with/without the LMA implementa-
tion oﬀers an eﬃcient approach to achieve moving target tracking for large residual
problems, this algorithm utilizes the recursive least-squares (RLS) algorithm in which
its performance is dependent on the exponential weighting factor or forgetting factor
λ. Diﬀerent VFF algorithms presented in Chapter 5 are investigated in this sec-
tion to validate tracking improvement, especially in the presence of measurement and
processing noise. These algorithms are:
1. Fixed forgetting factor
2. VS-ARLS
3. GN-VFF-RLS
4. DAFF
5. Alternating between [λ ,λ ]
low high
Due to the complexity of the GVFF-RLS algorithm [41], which requires the selec-
tion of a number of variables, the algorithm is excluded in this study.
Since all VFF algorithms require the selection of one or more parameters and a
range of applicable λ, the eﬀect of these parameters on each VFF algorithm perfor-
mance is studied to reasonably select acceptable parameter ranges for simulation. A
number of factors such as a target trajectory, robot degrees-of-freedom, and noise
disturbance aﬀects these values. To establish a basic understanding the PUMA 560
manipulator with an eye-in-hand camera tracking four feature points of a circular
trajectory is used for an initial study and is presented in Section 6.5.1. Even though
the obtained parameter values are not expected to be optimal due to the speciﬁc
trajectory, a robot degrees-of-freedom, and a limited range of each test parameters,
220
this study helps to determine an applicable range for each parameter used in VFF
algorithms. First no noise is added to the simulation and latter the eﬀect of noise is
investigated.
Each VFF algorithm is integrated into the switching MBFGS-DB algorithm so
that λ is adaptively calculated at each iteration with a constant switching criterion
k
υ for the same testing conditions, i.e., same robot, camera conﬁguration, and target
trajectory, and is presented in Section 6.5.2. A variety of target trajectories including
circular, square, and cycloidal trajectories are used to compare tracking performance.
The eﬀect of measurement and processing noise are studied with diﬀerent camera
arrangements to improve noise compensation.
TheobjectiveofthissectionistocomparetheproposedDAFFalgorithmforlarge-
residual uncalibrated visual servoing with other existing VFF algorithms originally
developed for adaptive ﬁltering applications. Due to the large number of variations
that may aﬀect each algorithm, the study is limited to selected cases to establish
the basic eﬀectiveness of each VFF algorithm on improving tracking performance for
large residual problems.
For simplicity only the name of each VFF algorithm is used. For example, the
DAFF algorithm refers to the switching MBFGS-DB algorithm in which the DAFF
algorithm is utilized for calculating λ using a given υ.
k
6.5.1 Eﬀect of Parameter Values on Each VFF Algorithm
The objective is to obtain an acceptable range of λ for each VFF scheme. In this
k
section all evaluations are performed using the same circular trajectory and without
additionalnoise. AllVFFalgorithmsareimplementedintotheswitchingMBFGS-DB
algorithm without the LMA. The switching criterion υ = 0.3 is used for all tests.
The circular translational target trajectory in (6.4) is used to examine transient
and steady-state behavior. The target consists of four feature points at the vertices
221
of a 50 mm square. To make the end-eﬀector and target trajectories visually dis-
tinct they are oﬀset by a constant vector [−393.7,19.9,142]T mm. The starting robot
joint angles are θ = [15.73◦,132.5◦,−135.6◦,15.73◦,−58.75◦,14.27◦]T for all tests
0
simulated in this section. The end-eﬀector camera has a 10 mm focal length and is
coincident with the ﬁnal frame of the robot. The sampling time is h = 50 ms. The
t
initial Jacobian is estimated by successively perturbing each joint by a small angle.
Eﬀect of λ on the ﬁxed forgetting factor (FFF) scheme
Since the switching MBFGS-DB algorithm originally applies a ﬁxed value of the
forgetting factor λ, various values of λ are investigated with a circular trajectory.
As shown in Table 6.25 a small value of λ, such as λ = 0.2, generates a high RMS
steady-state error, yet oﬀers a small settling time t . In contrast, a higher value of
s
λ yields a smaller RMS steady-state error with a higher t . Too small (λ = 0.10) or
s
too great a value (λ = 0.95) of λ results in a longer settling time with greater RMS
steady-state error and thus deteriorates the overall tracking performance.
Table 6.25: RMS error and t and settling time t for λ values in the FFF strategy.
s s
222
Table 6.25 shows that a range of λ ∈ [0.20,0.90] could be used for tracking a cir-
cular trajectory for the FFF strategy. The forgetting factor range [λ ,λ ] plays
min max
an important role in determining the settling time t while achieving steady-state
s
tracking.
Eﬀect of η on the VS-ARLS algorithm
1
Table 6.26 shows the eﬀect of the parameter η on the VS-ARLS algorithm. There
1
ˆ ˆ
exist singularity problems in the J and H calculation unless the minimum λ is
k k
greater than 0.6 so a range of λ ∈ [0.60,0.95] is used. Although varying η values
k 1
only show little eﬀect on RMS error and no eﬀect on settling time t (except for
s
η = 0.01), η = 0.05 oﬀers the smallest RMS error value. For this value of η ,
1 1 1
diﬀerent ranges of [λ ,λ ] yield distinct RMS tracking errors and settling time
min max
t .
s
Table 6.26: RMS error and t comparison of the VS-ARLS algorithm for diﬀerent
s
values of η with λ ∈ [0.60,0.95].
1 k
The overall performance, shown in Table 6.27, is similar for all tested λ ranges.
k
This study shows that varying η values and λ ranges yield only a small aﬀect on
1 k
the VS-ARLS algorithm. Therefore any combination is expected to give about the
223
Table 6.27: RMS error and t comparison of the VS-ARLS algorithm with η = 0.05
s 1
for various ranges of [λ ,λ ].
min max
same result. However, η = 0.05 and λ ∈ [0.6,0.95] are chosen due to slightly better
1
performance.
Eﬀect of η on the GN-VFF-RLS algorithm
2
Table 6.28 shows the eﬀect of the parameter η on the GN-VFF-RLS algorithm with
2
ˆ ˆ
λ ∈ [0.85,0.95] to avoid J and H singularities.
k k k
Table 6.28: RMS error and t comparison of the GN-VFF-RLS algorithm for various
s
values of η with λ ∈ [0.85,0.95].
2 k
TheRMSerrorandt insigniﬁcantlydiﬀerforvaryingvaluesofη . Sinceη = 0.01
s 2 2
generates the smallest RMS error with the fastest t , it is used to investigate diﬀerent
s
ranges of forgetting factor in Table 6.29. For η = 0.01, diﬀerent λ ranges give similar
2
results. Thus any presented range of λ can be selected. For this study η = 0.01 with
2
224
λ ∈ [0.85,0.95] is selected for comparison with other VFF algorithms.
Table 6.29: RMS error and t comparison of the GN-VFF-RLS algorithm for various
s
ranges of [λ ,λ ] with η = 0.01.
min max 2
Eﬀect of τ on the DAFF method
Table 6.30 shows the eﬀect of τ with λ ∈ [0.2,0.95]. Even though the RMS error
value and the settling time t are insensitive to τ, the value τ = 0.1 generates the
s
smallest RMS tracking error and t .
s
Since the DAFF method is dependent on the maximum λ, the range of λ ∈
[0.2,0.90] is investigated as shown in Table 6.31 .
Table 6.30: RMS error and t comparison of the DAFF method for various values of
s
τ with λ ∈ [0.2,0.95].
k
To study the eﬀect of the upper bound λ ∈ [0.50,0.90] and λ ∈ [0.50,0.95] are
k k
tested with τ = (0.05,0.10,0.50,1) with the RMS error and t shown in Table 6.32
s
and Table 6.33 respectively.
225
Table 6.31: The RMS error and t comparison of the DAFF method with various
s
values of τ with λ ∈ [0.20,0.90].
k
Table 6.32: RMS error and t comparison of the DAFF method for various values of
s
τ with λ ∈ [0.50,0.90].
k
Table 6.33: RMS error and t comparison of the DAFF method for various values of
s
τ with λ ∈ [0.50,0.95].
k
From these simulation results τ ∈ [0.05,1] oﬀers approximately the same the aver-
ageRMSerrorandthesettlingtimet fordiﬀerentrangesofλ . Sincetheobjectiveof
s k
the DAFF scheme is to adaptively calculate λ based on the current error norm (cid:107)f (cid:107),
k k
226
the widest range of permissible λ should be used. Therefore, the range λ ∈ [0.2,0.95]
k
with τ = 0.1 is selected.
Performance evaluation of the Alternating (Alt) method
In the Alternating (Alt) scheme λ = λ if the error norm (cid:107)f (cid:107) < e and
k low k criterion
λ = λ if(cid:107)f (cid:107) ≥ e . Inthisstudye ≈ 0.01(cid:107)f (cid:107)isselectedsinceitis
k high k criterion criterion max
reasonably assumed that the steady-state error is approximately 1% of the maximum
transient error. Diﬀerent sets of [λ ,λ ] are tested and shown in Table 6.34. The
low high
set [0.50,0.90] oﬀers the lowest RMS error and the settling time t .
s
Table 6.34: RMS error and t for the Alt scheme between λ and λ .
s low high
Conclusion
The performance of each VFF algorithm is insensitive to variation of parameter
values, thustrackingperformanceofeachVFFalgorithmcanbereasonablycompared
for selected values. Since selecting a minimal value of the RMS error usually yields a
longer settling time t , proper parameter selection relies on the speciﬁed task objec-
s
tive. In this case the RMS error and t are equally weighted for their signiﬁcance to
s
227
achieve fast tracking with the maximum steady-state tracking accuracy. Table 6.35
summaries selected parameter values for each forgetting factor scheme.
Table 6.35: Selected parameters values for each forgetting factor scheme.
6.5.2 Performance Evaluation of Various VFF Algorithms
The RRR and the PUMA 560 robots are used to track feature points moving in a va-
riety of trajectories to evaluate the eﬀects of the switching MBFGS-DB implemented
with each VFF algorithm, using the parameters in Table 6.35.
6.5.2.1 The RRR Robot
The same RRR robot used from Section 6.3.1 with the two eye-to-hand cameras is
usedfortrackingthecirculartrajectoryin(6.1)ataangularspeedω = 0.9rad/s. The
starting robot joint angles are θ = [60◦,70◦,50◦]T. The two camera arrangements
0
are the same as shown in Figure 6.1a in which the locations are described by the
homogeneous matrices in (6.2) and (6.3).
From Section 6.3.2 the NP-Jacobian yields better results than the P-Jacobian
approximation and is utilized with the MBFGS-DB algorithm and υ = 0.3 in this
section. For each of the VFF algorithms the camera space view, the task space
view, and average error norm are plotted in Figure 6.38, Figure 6.39, and Figure 6.40
228
respectively. To show the diﬀerence in forgetting factors, λ plots are also shown in
k
Figure 6.40. The settling time t and the RMS steady-state error of each forgetting
s
factor are summarized in Table 6.36.
Table 6.36: The RMS error and the settling time comparison for VFF schemes using
the RRR robot with two eye-to-hand cameras tracking one feature point of a circular
target moving at ω = 0.9 rad/s and υ = 0.3 for the no additional noise scenario.
As seen on the camera space in Figure 6.38 and the task space in Figure 6.39
the DAFF algorithm moves the EE to the desired target in the most direct path and
has the fastest settling time. The DAFF scheme and the Alt algorithm calculate λ
k
similarly.
The eﬀects of measurement noise
±1 pixel uniform quantization noise is added to the target and EE feature points.
2
Since it is recommended in [57] to select λ (cid:29) 0 to prevent excessive estimation
k
229
Camera Space
90  
80
70
60
50
X
40
Init Pos
30
20 EE Cam1
EE Cam2
10 Target Cam1
Target Cam2
 
−10 0 10 20 30 40 50 60 70 80
Y
(a) FFF
Camera Space Camera Space
   
80 70
Init Pos
70
60
60
50
50
40
X X
40
30
Init Pos
30
20
20 EE Cam1 EE Cam1
EE Cam2 10 EE Cam2
10 Target Cam1 Target Cam1
Target Cam2 0 Target Cam2
   
0 20 40 60 80 −10 0 10 20 30 40 50 60 70 80
Y Y
(b) VS-ARLS (c) GN-VFF-RLS
Camera Space Camera Space
55   55 EE Cam1  
50 Init Pos 50 ETaEr gCeatm C2am1
Target Cam2
45 45
40 40
35 35
X30 X30
25 25 Init Pos
20 20
15 EE Cam1 15
EE Cam2
10 Target Cam1 10
  Target Cam2 5 
−10 0 10 20 30 40 −10 0 10 20 30 40
Y Y
(d) DAFF (e) Alt
Figure6.38: ThecameraspaceoftheRRRmanipulatorwithtwoeye-to-handcameras
tracking one feature point of the circular target trajectory moving at ω = 0.90 rad/s.
Various VFF algorithms for λ are implemented with the switching MBFGS-DB with
k
υ = 0.3.
230
Task Space
 
EE
target
1
0.9
0.8
z Init Pos
0.7
0.6
0.5
0.6
0.4 0.4
0.2 0.2
 
y 0
x
(a) FFF
Task Space Task Space
   
EE EE
1 target 1 target
0.9 0.9
Init Pos
0.8 0.8
z Init Pos z
0.7 0.7
0.6 0.6
0.5 0.5
0.6 0.6
0.4 0.4 0.4 0.4
  0.2 0.2   0.2 0.2
y 0 y
x x
(b) VS-ARLS (c) GN-VFF-RLS
Task Space Task Space
   
EE EE
0.9 target 0.9 target
0.85
0.8
0.8 Init Pos
0.75
z z 0.7
0.7 Init Pos
0.65
0.6 0.6
0.55
0.5 0.5
0.5 50.05.450.04.35 0.20.250.30.35 0.5 50.05.450.04.35 0.2 0.3 0.4
y x y x
(d) DAFF (e) Alt
Figure 6.39: The task space view showing one target point for clarity (the other
views are similar) for the RRR manipulator with two eye-to-hand cameras using the
switching MBFGS-DB with various VFF algorithms for λ and υ = 0.3. The robot
k
is tracking one feature point of a circular target trajectory moving at ω = 0.90 rad/s.
231
Error Norm
150
pixels)100
m (
or
or N 50
Err
0
0 5 10 15 20 25 30
Time (s)
Forgetting Factor
2
1
l
0
−1
0 5 10 15 20 25 30
Time (s)
(a) FFF
Error Norm Error Norm
150 150
pixels)100 pixels)100
m ( m (
or or
or N 50 or N 50
Err Err
0 0
0 5 10 15 20 25 30 0 5 10 15 20 25 30
Time (s) Time (s)
Forgetting Factor Forgetting Factor
1 0.851
0.9
0.8 0.8505
l l
0.7
0.6 0.85
0 5 10 15 20 25 30 0 5 10 15 20 25 30
Time (s) Time (s)
(b) VS-ARLS (c) GN-VFF-RLS
Error Norm Error Norm
60 80
pixels)40 pixels)60
orm ( orm (40
or N20 or N20
Err Err
0 0
0 5 10 15 20 25 30 0 5 10 15 20 25 30
Time (s) Time (s)
Forgetting Factor Forgetting Factor
1 1
0.8
0.8
0.6
l l
0.6
0.4
0.2 0.4
0 5 10 15 20 25 30 0 5 10 15 20 25 30
Time (s) Time (s)
(d) DAFF (e) Alt
Figure 6.40: The error norm (top) and the forgetting factor λ (bottom) for the
k
RRR manipulator with two eye-to-hand cameras using the switching MBFGS-DB
with various VFF algorithms for λ and υ = 0.3. The forgetting factor λ The robot
k k
is tracking one feature point of a circular target trajectory moving at ω = 0.90 rad/s.
232
error for high noise levels so λ = 0.98 is used for all methods. Due to the small
max
lower bound of λ used in the DAFF method for the no noise case, the range of
λ ∈ [0.50,0.98] is employed. For noisy target and EE measurements the switching
k
criterion is adjusted to υ = 0.5 to avoid divergence. NP-Jacobian approximations are
still utilized for all algorithms. Figure 6.41 and Figure 6.42 show the camera space
view and the task space view respectively. The RMS error and t are summarized in
s
Table 6.37.
Table 6.37: The RMS error and the settling time comparison for VFF schemes using
the RRR robot with two eye-to-hand cameras tracking one feature point of a circular
target moving at ω = 0.9 rad/s. The switching criterion υ = 0.5 is used when ±1
2
pixel uniform quantization noise is added to the target and EE feature points.
Although the RMS error values of all algorithms in Table 6.37, and as seen on
camera space in Figure 6.41, are not signiﬁcantly diﬀerent, the EE motion substan-
tially deviates from the desired target plane in the ±z direction as shown in Figure
233
Camera Space
100  
90
80
70
60
50
X
40
Init Pos
30
20
EE Cam1
10 EE Cam2
Target Cam1
0 Target Cam2
 
0 20 40 60 80 100
Y
(a) FFF
Camera Space Camera Space
80   90  
70 80
60 70
50 60
X40 X50
30 Init Pos 40
20 30 Init Pos
EE Cam1 EE Cam1
10 EE Cam2 20 EE Cam2
Target Cam1 Target Cam1
0 Target Cam2 10 Target Cam2
   
−20 0 20 40 60 80 −20 0 20 40 60 80
Y Y
(b) VS-ARLS (c) GN-VFF-RLS
Camera Space Camera Space
55 EEEE  CCaamm12  55 EEEE  CCaamm 12
50 Target Cam1 50 Target Cam1
Target Cam2 Target Cam2
45 45
40 40
35 35
X30 X30
25 25
20 20
15 Init Pos 15
Init Pos
10 10
   
−20 −10 0 10 20 30 40 −20 −10 0 10 20 30 40
Y Y
(d) DAFF (e) Alt
Figure6.41: ThecameraspaceoftheRRRmanipulatorwithtwoeye-to-handcameras
tracking one feature point of a circular target trajectory moving at ω = 0.90 rad/s.
Various VFF algorithms for λ are implemented with the switching MBFGS-DB with
k
υ = 0.5 for which ±1 pixel uniform quantization noise is added to the target and EE
2
feature points.
234
Task Space
 
Init Pos
1
0.9
0.8
z0.7
0.6
0.5 0.6
0.4 EE 0.4
target 0.2
0.3   0
0 0.2 0.4 y
x
(a) FFF
Task Space Task Space
   
EE
target
1
1
0.9
Init Pos 0.9
0.8 Init Pos
0.8
z0.7
z0.7
0.6
0.6
0.5
0.5
0.6 EE 0.4 0.30.4
0.4 target 0.3 0.6 0.2
0.2 0.4 0.1
  0.2 0.1   0.2 0
y x y x
(b) VS-ARLS (c) GN-VFF-RLS
Task Space Task Space
   
EE
0.9 EtaErget 0.9 target
0.85 0.85
0.8 0.8
0.75 0.75
0.7 0.7
z0.65 Init Pos z0.65 Init Pos
0.6 0.6
0.55 0.55
0.5 0.5
0.45 0.45
0.6 0.6
0.5 0.4 0.5 0.4
  0.4 0.3   0.4 0.3
0.2 0.2
y x y x
(d) DAFF (e) Alt
Figure 6.42: The task space view showing one camera and one target point for clarity
(the other view is similar) for the RRR manipulator with two eye-to-hand cameras
usingtheswitchingMBFGS-DBwithvariousVFFalgorithmsforλ andυ = 0.5. The
k
robot is tracking one feature point of a circular target trajectory moving at ω = 0.90
rad/s for which ±1 pixel uniform quantization noise is added to the target and EE
2
feature points.
235
6.42. However, the image errors f are in a range of ±1 pixel. This result indicates
k
that the switching MBFGS-DB algorithm does not amplify the noise since uniform
±1 pixel noise is added to both target and EE feature points. The signiﬁcant z
2
direction deviation is due to the fact that the two cameras are nearly parallel and
primarily provide information for X-Y plane tracking.
Alternatively, the cameras are re-arranged so their optical axes are perpendicular,
one optical axis is pointed into the z direction and the other one is pointed into the
−x direction, as shown in Figure 6.45. The cameras are located by the homogeneous
matrices in an arrangement similar to [25],
 
1 0 0 0.4453
 
 
0 1 0 0.5307
T =   (6.15)
1  
0 0 1 −2 
 
 
0 0 0 1
 
1 0 0 0.4453
 
 
0 0 −1 2.5307
T =   (6.16)
2  
0 1 0 0.5 
 
 
0 0 0 1
.
Even though the RMS errors in Table 6.38 are not noticeably improved over Ta-
ble 6.37, the errors in the EE motion in the Cartesian space plane of motion are
signiﬁcantly minimized as seen in Figure 6.44. More cameras may be added and in-
vestigated to improve tracking error, which is beyond the scope of this study.
The eﬀects of additional system noise
To investigate the eﬀects of system noise, ±1 mm noise is added to the EE location in
additionto±1 pixeluniformnoiseaddedtotheEEandtargetfeaturepoints. Initially
2
the nearly parallel camera arrangement in (6.2) and (6.3) are used for tracking. A
236
Camera Space
 
150
Init Pos
100
X
50
0 EE Cam1
EE Cam2
Target Cam1
Target Cam2
−50 
−100 −50 0 50 100 150
Y
(a) FFF
Camera Space Camera Space
   
120
160
100 140
Init Pos
120
80
100 Init Pos
60 80
X X 60
40
40
20
20
0 EE Cam1 0 EE Cam1
EE Cam2 −20 EE Cam2
−20 Target Cam1 Target Cam1
Target Cam2 −40 Target Cam2
   
−100 −50 0 50 −100 −50 0 50 100 150
Y Y
(b) VS-ARLS (c) GN-VFF-RLS
Camera Space Camera Space
   
100
100
Init Pos 80 Init Pos
80
60
60
X X
40
40
20
20
EE Cam1 EE Cam1
EE Cam2 0 EE Cam2
0 Target Cam1 Target Cam1
Target Cam2 Target Cam2
  −20 
−100 −80 −60 −40 −20 0 20 40 −120 −100 −80 −60 −40 −20 0 20 40
Y Y
(d) DAFF (e) Alt
Figure6.43: ThecameraspaceoftheRRRmanipulatorwithtwoeye-to-handcameras
perpendicularly arranged tracking one feature point of the circular target trajectory
moving at ω = 0.90 rad/s. Various VFF algorithms for λ are implemented into the
k
switching MBFGS-DB with υ = 0.5 for which ±1 pixel uniform quantization noise is
2
added to the target and EE feature points.
237
Task Space
 
1
0.9
0.8
z Init Pos
0.7
0.6
EE
target
0.5
0.6 0.4
0.4 0.2 0.2
  0 −0.2 0
−0.4
y x
(a) FFF
Task Space
  Task Space
 
1
Init Pos
1
0.9
0.9
0.8
z EE z0.8 Init Pos
target
0.7 0.7
0.6 0.6 EE
0.5 target 0.4
00..56  0.5 0.4 0.3 0.2 0.1 0.2 0.4 0.6  0.4 0.2 0 y −0.2 −0.4 0 0.2x
y x
(b) VS-ARLS (c) GN-VFF-RLS
Task Space Task Space
   
0.95 1 EE
0.95 target
0.9
0.9
0.85
0.85
0.8
Init Pos 0.8
0.75
z
0.7 z0.75 Init Pos
EE 0.7
0.65
target 0.65
0.6
0.6
0.55
0.55
0.5
0.6 0.5
  0.4 0.1 0.2 0.3 0.4 0.6  0.5 0.4 0.3 0.2 0.3 0.4
y x y x
(d) DAFF (e) Alt
Figure 6.44: The task space view showing one camera and one target point for clarity
(the camera view is similar) for the RRR manipulator with two eye-to-hand cameras
perpendicularly arranged using the switching MBFGS-DB with various VFF algo-
rithms for λ and υ = 0.5. The robot is tracking one feature point of a circular target
k
trajectory moving at ω = 0.90 rad/s for which ±1 pixel uniform quantization noise
2
is added to the target and EE feature points.
238
Table 6.38: RMS error and the settling time comparison for VFF schemes using
the RRR robot with two eye-to-hand cameras perpendicularly arranged. The target
moves in a circular trajectory with an angular speed of ω = 0.9 rad/s. ±1 pixel
2
uniform quantization noise is added to the target and EE feature points.
summary of the RMS error and t is shown in Table 6.39. In comparison with Table
s
6.37 where only measurement noise is added, there is little aﬀect on RMS error value
and t . The camera space view is shown in Figure 6.46 while the EE deviates from
s
the desired target plane shown in Figure 6.47 similar to adding measurement noise
only.
When the perpendicular camera arrangement of (6.15) and (6.16) is also used,
there is a similar improvement as the measurement noise only case. A summary of
the RMS error and t is in Table 6.40. Only the task space view is shown in Figure
s
6.48 due to the similarity of results.
239
Figure 6.45: A perpendicular camera arrangement where one camera is pointed in
the z direction while the other camera is pointed into the −x direction is used with
the RRR robot for noise compensation.
Conclusion
The switching MBFGS with the DAFF algorithm yields the fastest convergence with
desirable RMS tracking error as compared to the other VFF algorithms when the
±1 pixel uniform measurement noise is added to the target and robot feature points
2
and ±1 mm uniform system noise is added to the EE location. However, with the
nearly-parallel camera arrangement, the EE motion substantially deviates from the
desired target plane for all algorithms. This problem is signiﬁcantly improved when
the perpendicular camera arrangement is used.
For the nearly parallel camera arrangement, only X-Y plane tracking informa-
tion is available thus the EE considerably deviates in the z direction. Rearranging
the cameras so that their optical axes are perpendicular signiﬁcantly diminishes EE
deviation in the z direction in the presence of measurement and system noise.
240
Camera Space
 
70
60
50
X
40
30 Init Pos
20 EE Cam1
EE Cam2
Target Cam1
10
Target Cam2
 
−20 −10 0 10 20 30 40 50 60 70
Y
(a) FFF
Camera Space Camera Space
60   70 EE Cam1  
EE Cam2
60 Target Cam1
50 Target Cam2
50
40
40
X30 X
30
20 Init Pos 20
10 EE Cam1 10
EE Cam2 Init Pos
Target Cam1
Target Cam2 0
0   
−20 −10 0 10 20 30 40 50 −20 −10 0 10 20 30 40 50 60 70
Y Y
(b) VS-ARLS (c) GN-VFF-RLS
Camera Space Camera Space
  55 EE Cam1 
55 EE Cam2
50 Target Cam1
50 Target Cam2
45
45
40 40
35 35
X30 X30
25 25
Init Pos
20 20
15 EE Cam1 15
10 ETaEr gCeatm C2am1 10 Init Pos
5 Target Cam2
   
−20 −10 0 10 20 30 40 50 −20 −10 0 10 20 30 40
Y Y
(d) DAFF (e) Alt
Figure6.46: ThecameraspaceoftheRRRmanipulatorwithtwoeye-to-handcameras
tracking one feature point of a circular target trajectory moving at ω = 0.90 rad/s.
Various VFF algorithms for λ are implemented with the switching MBFGS-DB with
k
υ = 0.5 for which ±1 mm noise is added to the EE location in addition to ±1 pixel
2
uniform quantization noise added to the target and EE feature points
241
Task Space
 
1
0.9
0.8 EE
target
Init Pos
z0.7
0.6
0.5
0.6 0.4
  0.4 0.2
0.2
y x
(a) FFF
Task Space Task Space
   
EE
target 1 EE
0.9 target
Init Pos 0.9
0.8
0.8 Init Pos
0.7
z z0.7
0.6
0.6
0.5
0.5
0.4
0.6 0.6
0.4
  0.4 0.2 0.3 0.4   0.4 0.2 0.2 0.3
y x y x
(b) VS-ARLS (c) GN-VFF-RLS
Task Space Task Space
   
0.9
0.9
0.85 Init Pos EtaErget 0.85 Init Pos EE
0.8 target
0.8
0.75 0.75
0.7 0.7
z0.65 z0.65
0.6 0.6
0.55 0.55
0.5 0.5
0.45 0.45
0.4
0.6 0.6
  0.4 0.3 0.4  0.5 0.4 0.3 0.4
0.2 0.2
y x y x
(d) DAFF (e) Alt
Figure 6.47: The task space view showing one camera and one target point for clarity
(the other view is similar) for the RRR manipulator with two eye-to-hand cameras
using the switching MBFGS-DB with various VFF algorithms for λ and υ = 0.5.
k
The robot is tracking one feature point of a circular target trajectory moving at
ω = 0.90 rad/s for which ±1 mm noise is added to the EE location in addition to ±1
2
pixel uniform quantization noise added to the target and EE feature points.
242
Task Space
 
1
0.9
Init Pos
z0.8
0.7
0.6 EE
target
0.5
0.6
0.4 0.2 0.4
0 0.2
  −0.2 −0.4 0
y x
(a) FFF
Task Space
  Task Space
 
1
0.95
1
0.9
0.85 Init Pos 0.9 Init Pos
0.8 0.8
z
z0.75
0.7
0.7 EE
0.65 target 0.6 EE
0.6 0.5 target
0.55 0.6
0.4
0.5 0.2 0.4
0.6  0.4 0.2 0.1 0.2 0.3 0.4   0y −0.2 −0.4 0 x 0.2
y x
(b) VS-ARLS (c) GN-VFF-RLS
Task Space Task Space
   
1
0.95
0.9 0.9
0.85
0.8 Init Pos 0.8 Init Pos
z0.75 z
0.7 0.7
EE
0.65
EE target
0.6 target 0.6
0.55
0.5 0.5
0.6 0.6
  0.4 0.2 0.3 0.4   0.4 0.2 0.3 0.4
y x y x
(d) DAFF (e) Alt
Figure 6.48: The task space view showing one camera and one target point for clar-
ity (the camera views are similar) for the RRR manipulator with two eye-to-hand
cameras perpendicularly arranged using the switching MBFGS-DB with various VFF
algorithms for λ and υ = 0.5. The robot is tracking one feature point of a circular
k
target trajectory moving at ω = 0.90 rad/s for which ±1 mm noise is added to the
EE location in addition to ±1 pixel uniform quantization noise added to the target
2
and EE feature points.
243
Table 6.39: The RMS error and the settling time comparison for VFF schemes using
the RRR robot with two eye-to-hand cameras tracking one feature point of a circular
target moving at ω = 0.9 rad/s. The switching criterion υ = 0.5 is used when ±1
mm noise is added to the EE location in addition to ±1 pixel uniform quantization
2
noise added to the target and EE feature points.
6.5.2.2 The PUMA 560 Robot
Circular Trajectory
The PUMA 560 with one eye-in-hand camera tracks four feature points moving in
the circular path as described in Section 6.5.1. The parameters listed in Table 6.35
are used for each VFF algorithm.
The testing setup is similar to Section 6.3.4 is used where the target consists
of four feature points at the vertices of a 50 mm square. The starting robot joint
angles are θ = [15.73◦,132.5◦,−135.6◦,−4.27◦,−108.75◦,14.27◦]T for all tests in this
0
section. To make the end-eﬀector and target trajectories visually distinct they are
244
Table 6.40: The RMS error and the settling time comparison for VFF schemes using
the RRR robot with two eye-to-hand cameras tracking one feature point of a circular
target moving at ω = 0.9 rad/s. The switching criterion υ = 0.5 is used when ±1
mm noise is added to the EE location in addition to ±1 pixel uniform quantization
2
noise added to the target and EE feature points.
oﬀset by a constant vector [−393.7,19.9,142]T mm. The end-eﬀector camera has a
10 mm focal length and is coincident with the ﬁnal frame of the robot. The sampling
time is h = 50 ms. The initial Jacobian is estimated by successively perturbing each
t
joint by a small angle.
The camera space view, the task space view, and the RMS error norm are plotted
in Figure 6.49, Figure 6.50, and Figure 6.51 respectively. λ is also shown in Figure
k
6.51. The RMS error and t are summarized in Table 6.41.
s
From Table 6.41 all methods oﬀer approximately the same RMS error and t for
s
circular trajectory tracking when no noise is added to the target feature points.
Tostudyhoweachalgorithmdealswithfastertracking,thetargetspeedisdoubled
245
camera space
200 Target
150
X
100
Init Pos
50
0 50 100 150 200
Y
(a) FFF
camera space camera space
Target
180 180
160 160
Target
140 140
X X
120 120
100 100
80 80
60 Init Pos 60 Init Pos
20 40 60 80 100 120 140 160 180 20 40 60 80 100 120 140 160 180
Y Y
(b) VS-ARLS (c) GN-VFF-RLS
camera space camera space
180
180 Target
Target
160
160
140
140
120
X X120
100 100
80 80
60 Init Pos 60 Init Pos
0 20 40 60 80 100 120 140 160 20 40 60 80 100 120 140 160 180
Y Y
(d) DAFF (e) Alt
Figure 6.49: The camera space of the PUMA 560 manipulator with the eye-in-hand
camera tracking four feature points of the circular target trajectory moving at ω =
0.45 rad/s. VFF algorithms for λ calculation are implemented into the switching
k
MBFGS-DB with υ = 0.3. No additional noise is added.
246
Task Space
 
0.7
0.6
z0.5
0.4 0.5
0.4
0.3
0.2
−0.05 0.1
−−00. 1.1−50.2 −0.1 0 x
y
(a) FFF
Task Space Task Space
   
0.7 0.7
0.6 0.6
z0.5 z0.5
0.4
0.4 0.5 0.5
0.4 0.4
0.3 0.3
0.2 0.2
−0.05 0.1 0 0.1
−−00 .1.1−50.2 −0.1 0 x  −0.1−0.2 −0.1 0 x
y y
(b) VS-ARLS (c) GN-VFF-RLS
Task Space Task Space
   
0.7 0.7
0.6 0.6
z0.5 Init Pos z0.5 Init Pos
0.4 0.5 0.4 0.5
0.4 0.4
0.3 0.3
0.2 0.2
−0.05 0.1 −0.05 0.1
−−00. 1.1−50.2 −0.1 0 x −−00. 1.1−50.2 −0.1 0 x
y y
(d) DAFF (e) Alt
Figure 6.50: The task space view showing one camera and one target point for clarity
(the other views are similar) of the PUMA 560 manipulator with the eye-in-hand
camera tracking four feature points of the circular target trajectory moving at ω =
0.45 rad/s. VFF algorithms for λ calculation are implemented into the switching
k
MBFGS-DB with υ = 0.3. No additional noise is added.
247
Error Norm
150
pixels)100
m (
or
or N 50
Err
0
0 10 20 30 40 50
Time (s)
Forgetting Factor
2
1
l
0
−1
0 10 20 30 40 50
Time (s)
(a) FFF
Error Norm Error Norm
150 150
pixels)100 pixels)100
m ( m (
or or
or N 50 or N 50
Err Err
0 0
0 10 20 30 40 50 0 10 20 30 40 50
Time (s) Time (s)
Forgetting Factor Forgetting Factor
1 1
0.9 0.95
0.8 0.9
l l
0.7 0.85
0.6 0.8
0 10 20 30 40 50 0 10 20 30 40 50
Time (s) Time (s)
(b) VS-ARLS (c) GN-VFF-RLS
Error Norm Error Norm
150 150
pixels)100 pixels)100
m ( m (
or or
or N 50 or N 50
Err Err
0 0
0 10 20 30 40 50 0 10 20 30 40 50
Time (s) Time (s)
Forgetting Factor Forgetting Factor
1 0.9
0.8 0.8
0.6 0.7
l l
0.4 0.6
0.2 0.5
0 10 20 30 40 50 0 10 20 30 40 50
Time (s) Time (s)
(d) DAFF (e) Alt
Figure 6.51: The error norm of the PUMA 560 manipulator with an eye-in-hand
camera tracking four feature points of the circular target trajectory moving at ω =
0.45 rad/s. VFF algorithms for λ calculation are implemented into the switching
k
MBFGS-DB with υ = 0.3. No additional noise is added.
248
Table 6.41: The RMS error and the settling time comparison for VFF schemes using
the PUMA 560 robot with an eye-in-hand camera tracking four feature points of a
circular target moving at ω = 0.45 rad/s. The switching criterion is υ = 0.3 and no
additional noise is added.
to, ω = 0.9 rad/s. The RMS tracking error and t are summarized in Table 6.42.
s
Table 6.42: The RMS error and the settling time comparison for VFF schemes using
the PUMA 560 robot with an eye-in-hand camera tracking four feature points of
a circular target moving at a faster angular speed ω = 0.9 rad/s. The switching
criterion is υ = 0.3 and no additional noise is added.
249
Althoughtheperformanceofthesealgorithmsaresimilar, theDAFFmethodgives
the smallest RMS error and settling time.
The eﬀects of measurement noise
Uniform quantization noise of ±1 pixel is added to the target feature points requir-
ing that the parameters in Table 6.35 are updated to those in Table 6.43 to avoid
divergence. The total added noise in the RRR case is ±1 pixel (±1 pixel added to
2
target and EE feature points). Since for the eye-in-hand case noise can only added
to the target feature points, ±1 pixel is added. The switching criterion υ = 0.5 is
used for all algorithms. However, the GN-VFF-RLS algorithm diverges for all ranges
of λ tested so it is not included. The camera space view, the task space view, and
the RMS error with λ plots are shown in Figure 6.52, Figure 6.53, and Figure 6.54
k
respectively. The RMS error and t is summarized in Table 6.43.
s
Table 6.43: The RMS error and the settling time comparison for VFF schemes using
the PUMA 560 robot with an eye-in-hand camera tracking four feature points of a
circular target moving at the angular speed ω = 0.45 rad/s. The switching criterion
is υ = 0.5. Uniform quantization noise of ±1 pixel is added to the target feature
points.
250
camera space camera space
220 240
Target Target
200 220
180 200
160 180
160
140
X X
140
120
120
100
100
80
80
60
Init Pos 60 Init Pos
0 50 100 150 200 0 50 100 150 200
Y Y
(a) FFF (b) VS-ARLS
camera space camera space
200
Target
180
160
150 140 Target
X X120
100 100
80
Init Pos 60 Init Pos
50
20 40 60 80 100 120 140 160 180 200 0 20 40 60 80 100 120 140 160
Y Y
(c) DAFF (d) Alt
Figure 6.52: The camera space of the PUMA 560 manipulator with an eye-in-hand
camera tracking four feature points of the circular target trajectory moving at ω =
0.45 rad/s. Various VFF algorithms for λ calculation are implemented into the
k
switching MBFGS-DB with υ = 0.5. Uniform quantization noise of ±1 pixel is added
to the target feature points.
The DAFF and the Alt algorithms generate similar results as seen on Figure 6.52
and Figure 6.53. From Figure 6.54 the calculated λ values are similar though the
k
DAFF algorithm yields more variation of λ with respect to the image error norm
k
(cid:107)f (cid:107). For the eye-in-hand case the image error of each feature point f varies within
k k
±5 pixels which is greater than expected. This indicates that the eye-in-hand case is
more sensitive to noise disturbance as compared to the eye-to-hand cameras, possibly
due to the fact that only one camera is used in the eye-in-hand case. However, the
251
Task Space Task Space
   
t
0.7
0.7
0.6
0.6 0.5
z
z0.5 Init Pos 0.4 Init Pos
0.3
0.4 0.5 0.6
0.4
0.3 0.4
0.2 0
−0.05 0.1 −0.1 0.2
−y−0 0.1.1−50.2 −0.1 0 x   y−0.2−0.3 0 x
(a) FFF (b) VS-ARLS
Task Space Task Space
   
0.7 0.7
0.6 0.6
z0.5 Init Pos z0.5 Init Pos
0.4 0.5 0.4 0.5
0.4 0.4
0.3 0.3
0.2 0.2
−0.05 0.1 −0.05 0.1
−−0 0.1.1−50.2 −0.1 0 x −−0 0.1.1−5−00.2.25 −0.1 0 x
y y
(c) DAFF (d) Alt
Figure 6.53: The task space view showing one target point for clarity (the others
are similar) for the PUMA 560 manipulator with an eye-in-hand camera using the
switching MBFGS-DB with various VFF algorithms for λ calculation and υ = 0.5.
k
The robot is tracking four feature points of a circular target trajectory moving at
ω = 0.45 rad/s. Uniform quantization noise of ±1 pixel is added to the target feature
points.
252
Error Norm Error Norm
150 150
pixels)100 pixels)100
m ( m (
or or
or N 50 or N 50
Err Err
0 0
0 10 20 30 40 50 0 10 20 30 40 50
Time (s) Time (s)
Forgetting Factor Forgetting Factor
2 0.98
0.96
1
0.94
l l
0
0.92
−1 0.9
0 10 20 30 40 50 0 10 20 30 40 50
Time (s) Time (s)
(a) FFF (b) VS-ARLS
Error Norm Error Norm
150 150
pixels)100 pixels)100
m ( m (
or or
or N 50 or N 50
Err Err
0 0
0 10 20 30 40 50 0 10 20 30 40 50
Time (s) Time (s)
Forgetting Factor Forgetting Factor
1 1
0.95 0.9
0.9 0.8
l l
0.85 0.7
0.8
0 10 20 30 40 50 0 10 20 30 40 50
Time (s) Time (s)
(c) DAFF (d) Alt
Figure 6.54: The error norm (top) and the forgetting factor λ (bottom) for the
k
PUMA 560 manipulator with an eye-in-hand camera using the switching MBFGS-
DB with various VFF algorithms for λ and υ = 0.5. The robot is tracking four
k
feature points of a circular target trajectory moving at ω = 0.45 rad/s. Uniform
quantization noise of ±1 pixel is added to the target feature points.
253
motion of the EE is more accurate in term of maintaining the EE within the desired
target plane.
A multiple camera case is also investigated for noise compensation. However, it is
not feasible to arrange two eye-in-hand cameras perpendicular to one another. Con-
sequently two nearly-parallel eye-in-hand cameras are used. Although a study of the
number of cameras and arrangements on aﬀecting tracking performance are beyond
the focus of this research, a brief study of two eye-to-hand cameras is investigated.
Two eye-in-hand cameras
Two eye-in-hand cameras are used with the PUMA 560 robot. Each camera tracking
four feature points of a circular target trajectory moving at ω = 0.45 rad/s. The
cameras are placed ±150 mm from the origin along the x axis of the EE frame. The
optical axes are tilted by ±10◦ about the y axis of the EE frame. The switching
MBFGS-DB with various VFF algorithms is tested with uniform quantization noise
of ±1 pixel added to the target feature points. The RMS error and t are summarized
s
in Table 6.44 whereas the task space views showing one camera and one target point
are shown in Figure 6.55. The switching criterion is υ = 0.5 for all tests.
The DAFF and the Alt give similar performances that are better than the other
algorithms. One interesting observation is that although the RMS value of the VS-
ARLS algorithm in Table 6.44 is not much higher than the DAFF or the Alt results,
the EE motion does not follow the desired trajectory as seen in Figure 6.55b. Even
though the DAFF and the Alt algorithms using two eye-in-hand cameras gives a
small RMS value improvement over one eye-in-hand case (Table 6.43), they provide
smoother tracking as shown in Figure 6.56.
Square Trajectory
A more diﬃcult square trajectory is used to evaluate each VFF scheme for corner
velocity discontinuities that introduce transient behavior.
254
Task Space Task Space
   
0.7
0.6 0.7
0.5 0.6
z0.4 Init Pos z0.5
0.3
0.4 Init Pos
0.2
0.1 0.6
0.2
0.6 0.4
0.2 0.4 0 0.2
  0 −0.2 0 0.2   −0.2 0
y x y x
(a) FFF (b) VS-ARLS
Task Space Task Space
   
0.7 0.7
0.6 0.6
z0.5 Init Pos z0.5 Init Pos
0.4 0.5 0.4 0.5
0.4 0.4
0.3 0.3
0.2 0.2
−0.05 0.1 −0.05 0.1
−−0 0.1.1−50.2 −0.1 0 x −−0 0.1.1−50.2 −0.1 0 x
y y
(c) DAFF (d) Alt
Figure 6.55: The task space view showing one target point for clarity (the others
are similar) for the PUMA 560 manipulator with two eye-in-hand cameras using the
switching MBFGS-DB with various VFF algorithms for λ and υ = 0.5. Each camera
k
istrackingfourfeaturepointsofacirculartargettrajectorymovingatω = 0.45rad/s.
Uniform quantization noise of ±1 pixel is added to the target feature points.
255
Task Space Task Space
0.75 0.75
0.7 0.7
0.65 0.65
0.6 0.6
0.55 0.55
z z
0.5 0.5
0.45 0.45
0.4 0.4
0.35 0.35
   
−0.2−0.15−0.1−0.05 −0.2−0.15−0.1−0.05
y y
(a) DAFF - Two Cameras (b) DAFF - One Camera
Task Space Task Space
   
0.75 0.75
0.7 I 0.7
0.65 0.65
0.6 0.6
0.55 0.55
z z
0.5 0.5
0.45 0.45
0.4 0.4
0.35 0.35
   
−0.2−0.15−0.1−0.05 −0.25−0.2−0.15−0.1−0.05
y y
(c) Alt - Two Cameras (d) Alt - One Camera
Figure 6.56: The task space in YZ view showing one target point comparison between
the one and two eye-in-hand cameras used for the PUMA 560 manipulator using the
switching MBFGS-DB with the DAFF and Alt algorithms (υ = 0.5) with uniform
quantization noise of ±1 pixel added to the target feature points. Each camera is
tracking four feature points of a circular target trajectory moving at ω = 0.45 rad/s.
256
Table 6.44: The RMS error and the settling time comparison for VFF schemes using
the PUMA 560 robot with two eye-in-hand cameras, each tracking four feature points
of a circular target moving at the angular speed ω = 0.45 rad/s. The switching
criterion υ = 0.5. Uniform quantization noise of ±1 pixel is added to the target
feature points.
The trajectory follows a 200 mm square at 50 mm/s. The target starts from the
upper left corner and moves clockwise on the Y-Z plane. One eye-in-hand camera is
used.
No noise added
The parameter values in Table 6.35 are used for each VFF algorithm. The task space
view showing one target point and the image error norm with a plot of λ are shown
k
in Figure 6.57 and Figure 6.58 respectively. The RMS tracking error and the settling
time t are given in Table 6.45. The switching criterion υ = 0.3 is used for all tests.
s
The error norm plots in Figure 6.58 show that the feature points converge to the
desired locations and are perturbed as the target turns the corners. Along the sides of
257
thesquaretrajectorythesystemexhibitsasteady-stateconvergence. Thisphenomena
is due to the nature of the Broyden estimator that only updates the Jacobian in the
ˆ
“direction” of the trajectory. Therefore, the current Jacobian J cannot adequately
k
describe the system where a discontinuity occurs until additional path information
is received. In this situation, the forgetting factor λ should be reduced so that the
k
current Jacobian (and the Hessian) calculation relies more on current information
rather than averaging a number of past values. Once steady-state tracking along the
edges is recovered, the forgetting factor λ is expected to restore its previous value for
k
steady-state tracking. Only the DAFF method yields the expected behavior of λ as
k
shown in Figure 6.58d and results in the lowest RMS values of the average transient
errors occurring at each corner as shown in Figure 6.57. Furthermore, the DAFF
algorithm has an RMS steady-state error (the linear path along the square sides) and
t similar to the FFF and the Alt algorithms which is better than the VS-ARLS and
s
the GN-VFF-RLS.
The eﬀects of additional system noise
To investigate the eﬀects of system noise, ±1 mm uniform quantization noise is added
to the EE location in addition to ±1 pixel uniform quantization noise added to the
target feature points.
From Table 6.46 the DAFF algorithm gives the best RMS tracking error and the
settling time. Though other algorithms yield similar EE trajectories, the settling
times are much longer. The DAFF and the Alt algorithms also yield the best re-
peatability of convergence. The eye-in-hand camera appears sensitive to noise. The
average image error f of each feature point oscillates within ±5 pixels even though
k
only ±1 pixel uniform noise is added to the target features. The oscillation f range
k
appears to be approximately the same with uniform quantization ±1 mm noise added
to the EE location in addition to uniform quantization noise of ±1 pixel added to the
258
Task Space
 
0.75
0.7
0.65
0.6
0.55
z
0.5
0.45
0.4
0.35
0.3 
−0.2−0.15−0.1−0.05 0 0.05
y
(a) FFF
Task Space Task Space
 
0. 0.75
t
0 0.7
0. 0.65
0 0.6
0. 0.55
z z
0 0.5
0. 0.45
0 0.4
0. 0.35
0.3  0.3 
−0.2 −0.1 0 0.1 −0.2 −0.1 0
y y
(b) VS-ARLS (c) GN-VFF-RLS
Task Space Task Space
   
0.75 0.75
t
0.7 0.7
0.65 0.65
0.6 0.6
0.55 0.55
z z
0.5 0.5
0.45 0.45
0.4 0.4
0.35 0.35
0.3  0.3 
−0.2 −0.1 0 −0.2−0.15−0.1−0.05 0 0.05
y y
(d) DAFF (e) Alt
Figure 6.57: The task space view showing one target point for clarity (the others
are similar) for the PUMA 560 manipulator with an eye-in-hand camera using the
switching MBFGS-DB with various VFF algorithms for λ and υ = 0.3. The robot is
k
tracking four feature points of a square target trajectory moving at a speed 50 mm/s.
No additional noise is added.
259
Error Norm
150
pixels)100
m (
or
or N 50
Err
0
0 10 20 30 40 50
Time (s)
Forgetting Factor
2
1
l
0
−1
0 10 20 30 40 50
Time (s)
(a) FFF
Error Norm Error Norm
150 150
pixels)100 pixels)100
m ( m (
or or
or N 50 or N 50
Err Err
0 0
0 10 20 30 40 50 0 10 20 30 40 50
Time (s) Time (s)
Forgetting Factor Forgetting Factor
1 1
0.9 0.95
0.8 0.9
l l
0.7 0.85
0.6 0.8
0 10 20 30 40 50 0 10 20 30 40 50
Time (s) Time (s)
(b) VS-ARLS (c) GN-VFF-RLS
Error Norm Error Norm
150 150
pixels)100 pixels)100
m ( m (
or or
or N 50 or N 50
Err Err
0 0
0 10 20 30 40 50 0 10 20 30 40 50
Time (s) Time (s)
Forgetting Factor Forgetting Factor
1 0.9
0.8 0.8
0.6 0.7
l l
0.4 0.6
0.2 0.5
0 10 20 30 40 50 0 10 20 30 40 50
Time (s) Time (s)
(d) DAFF (e) Alt
Figure 6.58: The error norm (top) and the forgetting factor λ (bottom) for the
k
PUMA 560 manipulator with an eye-in-hand camera using the switching MBFGS-
DB with various VFF algorithms for λ and υ = 0.3. The robot is tracking four
k
feature points of a square target trajectory moving at a speed 50 mm/s. No noise is
added.
260
Task Space
0.75  
0.7
0.65
0.6
0.55
z
0.5
0.45
0.4
0.35
0.3 
−0.2 −0.1 0 0.1
y
(a) FFF
Task Space Task Space
   
0.75 0.75
0.7 0.7
0.65 0.65
0.6 0.6
0.55 0.55
z z
0.5 0.5
0.45 0.45
0.4 0.4
0.35 0.35
0.3  0.3 
−0.2−0.15−0.1−0.05 0 0.05 −0.2 −0.1 0 0.1
y y
(b) VS-ARLS (c) GN-VFF-RLS
Task Space Task Space
 
0.75 0.75
0.7 0.7In
0.65 0.65
0.6 0.6
0.55 0.55
z z
0.5 0.5
0.45 0.45
0.4 0.4
0.35 0.35
0.3  0.3 
−0.2 −0.1 0 −0.2 −0.1 0 0.1
y y
(d) DAFF (e) Alt
Figure 6.59: The task space view showing one target point for clarity (the others
are similar) for the PUMA 560 manipulator with an eye-in-hand camera using the
switching MBFGS-DB with various VFF algorithms for λ and υ = 0.3. The robot is
k
tracking four feature points of a square target trajectory moving at a speed 50 mm/s.
±1 mm uniform quantization noise is added to the EE location in addition to uniform
quantization noise of ±1 pixel added to the target feature points.
261
Error Norm
150
pixels)100
m (
or
or N 50
Err
0
0 10 20 30 40 50
Time (s)
Forgetting Factor
2
1
l
0
−1
0 10 20 30 40 50
Time (s)
(a) FFF
Error Norm Error Norm
150 150
pixels)100 pixels)100
m ( m (
or or
or N 50 or N 50
Err Err
0 0
0 10 20 30 40 50 0 10 20 30 40 50
Time (s) Time (s)
Forgetting Factor Forgetting Factor
1 1
0.98 0.98
l l
0.96 0.96
0.94 0.94
0 10 20 30 40 50 0 10 20 30 40 50
Time (s) Time (s)
(b) VS-ARLS (c) GN-VFF-RLS
Error Norm Error Norm
150 150
pixels)100 pixels)100
m ( m (
or or
or N 50 or N 50
Err Err
0 0
0 10 20 30 40 50 0 10 20 30 40 50
Time (s) Time (s)
Forgetting Factor Forgetting Factor
1 1
0.95 0.9
0.9 0.8
l l
0.85 0.7
0.8
0 10 20 30 40 50 0 10 20 30 40 50
Time (s) Time (s)
(d) DAFF (e) Alt
Figure 6.60: The error norm (top) and the forgetting factor λ (bottom) for the
k
PUMA 560 manipulator with an eye-in-hand camera using the switching MBFGS-DB
with various VFF algorithms for λ and υ = 0.3. The robot is tracking four feature
k
points of a square target trajectory moving at a speed 50 mm/s. ±1 mm uniform
quantization noise is added to the EE location in addition to uniform quantization
noise of ±1 pixel added to the target feature points.
262
Table6.45: TheRMSerrorandthesettlingtimecomparisonforvariousVFFschemes
using the PUMA 560 robot with an eye-in-hand camera tracking four feature points
of a square target moving at the speed 50 mm/s. The switching criterion υ = 0.3.
No additional noise is added.
target feature points. As a result, the two eye-in-hand camera case is investigated.
Two eye-in-hand cameras
Since the DAFF and Alt algorithms yield the fastest convergence time with similar
RMS errors compared to the other algorithms in Table 6.46, only the DAFF and Alt
schemes are used for the two eye-in-hand camera case. Uniform quantization ±1 mm
noise is added to the EE location in additional to uniform quantization noise of ±1
pixel added to the target feature points. Table 6.47 summaries the RMS error and
t . Figure 6.61 shows the task space view, the average error norm, and the λ of the
s k
DAFF and the Alt algorithms.
The DAFF algorithm again yields slightly smaller RMS error for both cameras.
263
Task Space Error Norm
  200
0.07.57 t pixels)150
0.65 Norm (100
or  50
0.6 Err
0
0.55 0 10 20 30 40 50
z Time (s)
Forgetting Factor
0.5
1
0.45 0.95
0.4 0.9
l
0.35 0.85
0.3  0.8
−0.2 −0.1 0 0 10 20 30 40 50
y Time (s)
(a) DAFF (b) DAFF
Task Space Error Norm
0.75   200
0.7 t pixels)150
0.65 orm (100
N
or  50
0.6 Err
0
0.55 0 10 20 30 40 50
z Time (s)
Forgetting Factor
0.5
1
0.45 0.9
0.4 0.8
l
0.35 0.7
0.3 
−0.2 −0.1 0 0 10 20 30 40 50
y Time (s)
(c) Alt (d) Alt
Figure 6.61: The task space view showing one camera and one target point (left
column), the error norm and λ (right column) of the PUMA 560 manipulator with
k
two eye-in-hand cameras using the switching MBFGS-DB with the DAFF and the Alt
algorithms with υ = 0.3. Each camera tracks four feature points of a square target
trajectory moving at a speed 50 mm/s. Uniform quantization ±1 mm noise is added
to the EE location in addition to uniform quantization noise of ±1 pixel added to the
target feature points.
264
Table 6.46: The RMS error and the settling time comparison of various VFF schemes
using the PUMA 560 robot with an eye-in-hand camera tracking four feature points
of a square target moving at the speed 50 mm/s. The switching criterion υ = 0.3 is
used with ±1 mm uniform quantization noise added to the EE location in addition
to uniform quantization noise of ±1 pixel added to the target feature points.
The EE motion of two eye-in-hand camera case in Figure 6.60 provides a smoother
trajectory as compared to the one eye-in-hand camera case in Figure 6.59.
6.5.3 Comparison between the settling time t vs. the cycle time t
s cyc
In comparison of the settling time t and the cycle time t required to complete one
s cyc
cycle of each trajectory, a summary of these quantities are shown in Table 6.48 for
diﬀerenttrajectoriesandtargetspeeds. SincethesamplingtimeT = 25msisrequired
to achieve tracking a fast cycloidal trajectory in (6.6), to conﬁne the diﬀerence to only
target speeds T = 25 ms is used for all tests. The switching MBFGS-DB with DAFF
265
Table 6.47: The RMS error and the settling time comparison of the DAFF and the
Alt schemes using the PUMA 560 robot with two eye-in-hand cameras, each tracking
four feature points of a square target moving at a speed 50 mm/s. The switching
criterion is υ = 0.3.Uniform quantization ±1 mm noise is added to the EE location in
addition to uniform quantization noise of ±1 pixel added to the target feature points.
scheme is used with υ = 0.3 for all cases except the fast cycloidal trajectory in (6.6)
which uses υ = 1.3 to avoid divergence.
The settling time t is nearly constant for a variety of target speeds and trajecto-
s
ries. Though visual guided servoing is a nonlinear system, the robot joint angles θ
k
ˆ ˆ
are solved by the Jacobian J and the Hessian H that are approximated using an
k k
aﬃne model of the system. Thus this system can be somewhat described as a linear
dynamic system in which the homogeneous solution is dependent on physical proper-
ties of the system, while the particular solution is based on system inputs. Since the
homogeneous solution determines the transient behavior the settling time t remains
s
nearly constant.
6.5.4 Conclusion
The RRR robot with two eye-to-hand cameras, and the PUMA 560 with one and
two eye-in-hand cameras are used to evaluate tracking performance of the switching
MBFGS-DB with a variety of VFF methods for adaptively calculating λ . For the
k
266
Table6.48: Thecycletime(t )andthesettlingtime(t )comparisonoftheswitching
cyc s
MBFGS-DB with DAFF method for tracking various trajectories with varying target
speed using υ selected to ensure convergence.
RRRrobotcase, theDAFFalgorithmprovidesthefastestconvergencewiththesmall-
est RMS error tracking for most cases. However, tracking performance is degraded in
the presence of measurement and system noise. The EE motion in Cartesian space
signiﬁcantly deviates out of the desired target plane though the RMS errors on the
image space are not substantial. This problem can be improved if the cameras are
rearranged so that both X-Y and Y-Z tracking planes can be seen by each camera.
The DAFF and Alt algorithms yield similar results that outperform other VFF
algorithms for the PUMA 560 robot with an eye-in-hand camera tracking four feature
points of a circular trajectory. DAFF oﬀers slightly lower RMS errors and settling
267
times, especially for a faster angular speed and in the presence of added noise. How-
ever, the eye-in-hand PUMA 560 is more sensitive to noise than the RRR robot with
the two eye-to-hand cameras. A brief study using two eye-in-hand cameras shows a
potential for improving noise compensation with smoother EE motion.
For the square trajectory, the DAFF algorithm also oﬀers better RMS errors and
settlingtimesascomparedtootherVFFalgorithms. Inaddition, itprovidesasmaller
RMS transient error due to velocity discontinuities at the corners. In the presence of
measurement and system noise, the DAFF algorithm yields a better RMS tracking
error as compared to the Alt method. The two eye-in-hand cameras also help improve
the RMS error while generating a smoother EE motion in the task space.
6.6 Performance Evaluation of the Switching MBFGS-DB
with various VFF algorithm and with/without LMA
Even though the LMA shows insigniﬁcant improvement over the switching MBFGS-
DB without the LMA in Section 6.4, those cases only use a ﬁxed forgetting fac-
tor without noise. The DAFF and the Alt algorithms are used with the switching
MBFGS-DB and adaptive λ schemes to test the LMA in the presence of noise. Since
k
the DGN-PBM algorithm uses the FFF originally, the FFF is also used with the
MBFGS-DB to evaluate the LMA.
In this section the same PUMA 560 robot with an eye-in-hand camera is used
for tracking the cycloidal trajectory in (6.5) with uniform quantization noise of ±1
pixel added to the target feature points. The starting robot joint angles are θ =
0
[15.73◦,132.5◦,−135.6◦,−4.27◦,−108.75◦,14.27◦]T for all tests. Due to the trajectory
complexity, using a 6 degrees-of-freedom robot, and using one eye-in-hand camera,
this is the most diﬃcult case, especially in the presence of the measurement noise. A
sampling time T = 15 ms is used to facilitate convergence. The switching criterion
υ = 0.3, the range of λ ∈ [0.85,1], and τ = 0.1 are used for the switching MBFGS-
k
DB with the DAFF algorithm whereas λ is alternated between λ = 0.7 and
k low
268
λ = 0.98 for the Alt algorithm and λ = 0.98 is applied for the FFF algorithm.
high
For convenience the switching MBFGS-DB with the DAFF, the FFF, or the Alt
algorithms are referred as the MBFGS-DB-DAFF, MBFGS-DB-FFF, and MBFGS-
DB-Alt algorithms respectively. To validate the feasibility of the switching MBFGS,
the DGN-PBM is also implemented with the DAFF, FFF, and Alt to calculate λ .
k
Table6.49: TheRMSerrorandthesettlingtimecomparisonoftheswitchingMBFGS-
DB algorithm with/without LMA and a variety of the VFF algorithms. The PUMA
560 robot with an eye-in-hand camera is used for tracking four feature points of a
cycloidal target. The switching criterion υ = 0.3 is used with uniform quantization
noise of ±1 pixel added to the target feature points.
Table 6.49 and Table 6.50 show summaries of the RMS tracking error and the
settling t for the switching MBFGS-DB and the DGN-PBM with various VFF al-
s
gorithms and with/without the LMA respectively. For the switching MBFGS-DB
algorithm the DAFF without the LMA gives the best RMS tracking error and the
settlingtimeasshowninTable6.49. AlthoughtheEEtrajectoriesinthecameraspace
are similar for all algorithms in which the EE initially moves away from the desired
target, the EE motion of the DAFF algorithm with/without LMA gives a smaller
deviation from the desired target points as seen in Figure 6.62. The EE motion in
the task space of the DAFF with/without LMA is similar to the Alt with/without
269
camera space camera space
250
250 Target
Target
200
200
150 150
X X
100 100
50
50
0 Init Pos Init Pos
−100 −50 0 50 100 150 200 −100 −50 0 50 100 150 200
Y Y
(a) FFF LMA (b) FFF No LMA
camera space camera space
220
Target 220
200
200
180
180
160 Target
160
140
140
120
X X120
100
100
80 80
60 60
40 40
20 Init Pos 20 Init Pos
−100 −50 0 50 100 150 −100 −50 0 50 100 150
Y Y
(c) DAFF LMA (d) DAFF No LMA
camera space camera space
220
Target Target
200 200
180
160
150
140
X120 X
100 100
80
60 50
40
Init Pos Init Pos
20
0
−100 −50 0 50 100 150 −100 −50 0 50 100 150
Y Y
(e) Alt LMA (f) Alt No LMA
Figure 6.62: The camera space of the PUMA 560 manipulator with an eye-in-hand
camera using the switching MBFGS-DB with various VFF algorithms implemented
with the LMA (left column) and without the LMA (right column). The robot is
tracking four feature points of a cycloidal trajectory. Uniform quantization noise of
±1 pixel is added to the target feature points.
270
Task Space Task Space
   
0.8
0.8
0.7 Init Pos
0.7
0.6
0.6
0.5
z z0.5
0.4
0.4
0.3 EE
0.3
0.2
0.2
0.1
  0.2 0 −0.2 −0.4 0 0.2 0.4 0.6 0 .2 0 −0.2 −0.4 −0.1 0 0.1 0.2 0.3 0.4 0.5
y x y x
(a) FFF LMA (b) FFF No LMA
Task Space Task Space
   
0.8 Ini 0.8
0.7 0.7 s
0.6 0.6
z0.5 z0.5
0.4 0.4
EE
0.3 0.3 target
0.2 0.2
  0 −0.2 −0.4 −0.1 0 0.1 0.2 0.3 0.4 0.5 0.2  0 −0.2 −0.4 0 0.2 0.4 0.6
y x y x
(c) DAFF LMA (d) DAFF No LMA
Task Space Task Space
   
0.8 Init Pos
0.8
0.7 0.7
0.6 0.6
z0.5 z0.5 Init Pos
0.4
0.4
0.3
0.3
0.2
0.2 EE
0 target 0.4 0.6
  0 −0.2 −0.4 0 0.2 0.4 0.6   −0.2 −0.4 0 0.2
y x y x
(e) Alt LMA (f) Alt No LMA
Figure 6.63: The task space view showing one target point for clarity (the others
are similar) for the PUMA 560 manipulator with an eye-in-hand camera using the
switching MBFGS-DB with various VFF algorithms implemented with the LMA (left
column) and without the LMA (right column). The robot is tracking four feature
points of a cycloidal trajectory. Uniform quantization noise of ±1 pixel is added to
the target feature points.
271
Error Norm Error Norm
300 300
pixels)200 pixels)200
m ( m (
or or
or N100 or N100
Err Err
0 0
0 5 10 15 20 25 30 0 5 10 15 20 25 30
Time (s) Time (s)
Forgetting Factor Forgetting Factor
2 2
1 1
l l
0 0
−1 −1
0 5 10 15 20 25 30 0 5 10 15 20 25 30
Time (s) Time (s)
(a) FFF LMA (b) FFF No LMA
Error Norm Error Norm
300 300
pixels)200 pixels)200
m ( m (
or or
or N100 or N100
Err Err
0 0
0 5 10 15 20 25 30 0 5 10 15 20 25 30
Time (s) Time (s)
Forgetting Factor Forgetting Factor
1 1
0.95
0.5 0.9
l l
0.85
0 0.8
0 5 10 15 20 25 30 0 5 10 15 20 25 30
Time (s) Time (s)
(c) DAFF LMA (d) DAFF No LMA
Error Norm Error Norm
300 300
pixels)200 pixels)200
m ( m (
or or
or N100 or N100
Err Err
0 0
0 5 10 15 20 25 30 0 5 10 15 20 25 30
Time (s) Time (s)
Forgetting Factor Forgetting Factor
1 1
0.9 0.9
0.8 0.8
l l
0.7 0.7
0 5 10 15 20 25 30 0 5 10 15 20 25 30
Time (s) Time (s)
(e) Alt LMA (f) Alt No LMA
Figure 6.64: The error norm and λ plots of the PUMA 560 manipulator with an
k
eye-in-hand camera using the switching MBFGS-DB for various VFF algorithms im-
plemented with the LMA (left column) and without the LMA (right column). The
robot is tracking four feature points of a cycloidal target trajectory. Uniform quanti-
zation noise of ±1 pixel is added to the target feature points.
272
camera space camera space
400 300 Target
Target
300
200
200
100 100
X 0 X 0
−100 Init Pos
−100 Init Pos
−200
−200
−300
−400 −300
−800 −600 −400 −200 0 200 400 −700 −600 −500 −400 −300 −200 −100 0 100 200
Y Y
(a) FFF LMA (b) FFF No LMA
camera space camera space
250 Target
250
200 Target
200
150
150
X X
100
100
50
50
0 Init Pos
0 Init Pos
−200 −150 −100 −50 0 50 100 150 −200 −150 −100 −50 0 50 100 150
Y Y
(c) DAFF LMA (d) DAFF No LMA
camera space camera space
250
Target Target
200
200
150
150
X X
100
100
50
50
Init Pos
Init Pos 0
0
−150 −100 −50 0 50 100 150 −150 −100 −50 0 50 100 150
Y Y
(e) Alt LMA (f) Alt No LMA
Figure 6.65: The camera space of the PUMA 560 manipulator with the eye-in-hand
camera using the DGN-PBM for various VFF algorithms implemented with the LMA
(leftcolumn)andwithouttheLMA(rightcolumn). Therobotistrackingfourfeature
points of a cycloidal trajectory. Uniform quantization noise of ±1 pixel is added to
the target feature points.
273
Task Space Task Space
   
EE
0.7 target 0.8 Init Pos
0.7
0.6
Init Pos
0.5 0.6
0.4 0.5
z z
0.3 0.4 EE
target
0.2 0.3
0.1
0.2
  0 −0.2 −0.4 0 0.2 0.4 0.6   0 −0.2 −0.4 0 0.2 0.4 0.6
y x y x
(a) FFF LMA (b) FFF No LMA
Task Space Task Space
   
0.8 I 0.8
0.7 0.7
0.6 0.6
s
z0.5 z0.5
0.4 0.4
0.3 EE 0.3
target
0.2 0.2
0.2  0 −0.2 −0.4 −0.10 0.1 0.2 0.3 0.4 0.5   0 −0.2 −0.4 −0.1 0 0.1 0.2 0.3 0.4 0.5
y x y x
(c) DAFF LMA (d) DAFF No LMA
Task Space Task Space
   
0.8 Init Pos 0.8
0.7 0.7
0.6 0.6
Init Pos
z0.5 z0.5
0.4 0.4
0.3 EtaErget 0.3 EtaErget
0.2 0.2
0.2
  0 −0.2 −0.4 −0.1 0 0.1 0.2 0.3 0.4 0.5   0 −0.2 −0.4 −0.1 0 0.1 0.2 0.3 0.4 0.5
y x y x
(e) Alt LMA (f) Alt No LMA
Figure 6.66: The task space view showing one target point for clarity (the others
are similar) for the PUMA 560 manipulator with an eye-in-hand camera using the
DGN-PBM for various VFF algorithms implemented with the LMA (left column)
and without the LMA (right column). The robot is tracking four feature points of a
cycloidal trajectory. Uniform quantization noise of ±1 pixel is added to the target
feature points.
274
Error Norm Error Norm
1000 1000
pixels) pixels)
orm ( 500 orm ( 500
N N
or  or 
Err Err
0 0
0 5 10 15 20 25 30 0 5 10 15 20 25 30
Time (s) Time (s)
Forgetting Factor Forgetting Factor
2 2
1 1
l l
0 0
−1 −1
0 5 10 15 20 25 30 0 5 10 15 20 25 30
Time (s) Time (s)
(a) FFF LMA (b) FFF No LMA
Error Norm Error Norm
400 400
pixels)300 pixels)300
orm (200 orm (200
N N
or 100 or 100
Err Err
0 0
0 5 10 15 20 25 30 0 5 10 15 20 25 30
Time (s) Time (s)
Forgetting Factor Forgetting Factor
1 1
0.95
0.5 0.9
l l
0.85
0 0.8
0 5 10 15 20 25 30 0 5 10 15 20 25 30
Time (s) Time (s)
(c) DAFF LMA (d) DAFF No LMA
Error Norm Error Norm
300 300
pixels)200 pixels)200
m ( m (
or or
or N100 or N100
Err Err
0 0
0 5 10 15 20 25 30 0 5 10 15 20 25 30
Time (s) Time (s)
Forgetting Factor Forgetting Factor
1 1
0.9 0.9
0.8 0.8
l l
0.7 0.7
0 5 10 15 20 25 30 0 5 10 15 20 25 30
Time (s) Time (s)
(e) Alt LMA (f) Alt No LMA
Figure 6.67: The error norm and λ plots of the PUMA 560 manipulator with an eye-
k
in-hand camera using the DGN-PBM for various VFF algorithms implemented with
the LMA (left column) and without the LMA (right column). The robot is tracking
four feature points of a cycloidal target trajectory. Uniform quantization noise of ±1
pixel is added to the target feature points.
275
Table 6.50: The RMS error and the settling time comparison of the DGN-PBM
algorithm with/without LMA and a variety of the VFF algorithms. The PUMA 560
robotwithaneye-in-handcameraisusedfortrackingfourfeaturepointsofacycloidal
target. The switching criterion υ = 0.3 is used with uniform quantization noise of ±1
pixel added to the target feature points.
LMA. However, Figure 6.63 shows that the DAFF without LMA yields the most di-
rect path from the initial robot position to reach the desired trajectory and is best
able to follow the target. The λ calculated from the DAFF algorithm is adaptively
k
changed with respect to the error norm (cid:107)f (cid:107) but the DAFF without LMA is more
k
sensitive to (cid:107)f (cid:107) compared to the LMA as shown in Figure 6.64.
k
For the DGN-PBM algorithm with various VFF algorithms the EE trajectories
as seen in the camera space move signiﬁcantly away from the target, shown in Figure
6.65, compared to the switching MBFGS-DB algorithm. The DGN-PBM with FFF
algorithm with/without LMA yields an undesirable motion of the EE moving from
its initial position to the desired target. Though the Alt without LMA gives better
tracking on the Y-Z plane, its motion from the initial robot conﬁguration is not as
direct as the DAFF with/without LMA as seen on Figure 6.66. Figure 6.67 shows the
average error norm and the λ plot of various VFF algorithms with/without LMA
k
that are similar to the switching MBFGS-DB algorithm. The DAFF without LMA
276
yields λ that is more sensitive the image error norm (cid:107)f (cid:107) than with the LMA.
k k
6.6.1 Conclusion
ForallVFFalgorithms,boththeMBFGS-DBandtheDGN-PBMwithoutLMAoﬀers
betterEEtrajectorythantheLMA.TheDAFFalgorithmoﬀersthebestperformance
for both the switch MBFGS-DB and the DGN-PBM algorithms and the LMA has
littleeﬀectontheperformanceofDAFF.Overall, theLMAalgorithmonlymarginally
improves tracking performance of a complex trajectory in the presence of noise.
To improve noise compensation more cameras can be added similar to Section
6.5.2.2. An alternative is to combine an eye-to-hand with an eye-in-hand camera,
which is beyond scope of this study.
6.7 Summary
This chapter simulates the proposed switching algorithms with VFF schemes for
large residual tracking. They are also studied with and without implementation of
the LMA for avoiding ill-conditioning of the Hessian approximation. A summary of
the algorithms proposed to improve on the dynamic quasi-Gauss Newton algorithms
is presented in Table 6.1.
The objective is to establish a basic understanding of the proposed algorithms to
improve tracking performance. They are compared with the original DBM-RLS and
the DGN-PBM algorithms using a ﬁxed forgetting factor. Although only a represen-
tative number of simulations are tested, they reveal the potential of the presented
switching schemes with VFF to improving tracking performance with a variety of
manipulator DOF, camera conﬁgurations, and trajectories.
Section 6.1 presents overviews of the organization of this chapter. A summary
of the robot systems, the camera systems, and assumptions used for simulations are
reviewed in Section 6.2.
In Section 6.3 a 3 DOF and a 6 DOF robot with a variety target trajectories
277
ˆ
are used for large residual tracking. The proposed residual S approximations are
k
reviewed in Figure 6.4. In this section the eﬀect of noise is deferred and a ﬁxed
forgetting factor λ is used.
ForRRRrobotwithtwoeye-to-handcamerastrackingacirculartrajectorytarget,
the switching DFN-BFGS-DB and the MBFGS-DB algorithms are the most eﬀective
methods. The results are further improved if the NP-Jacobian approximation is
utilized. A heuristic selection of the switching criterion υ demonstrates better RMS
tracking error and settling time as compared to other existing algorithms (Scheme 1
and 2).
Then a Puma 560 manipulator with an eye-in-hand camera tracking is used with
a variety of target trajectories. For a circular trajectory with the fastest angular
speed the switching DFN-BFGS-DB and MBFGS-DB outperform the other switching
algorithms. However, the switching MBFGS-DB algorithm yields the smallest RMS
error with better stability. For the helical trajectory, the switching MBFGS-DB
algorithm provides the best result for the fastest speed.
In Section 6.4 the switching algorithms are implemented with the LMA but with
a ﬁxed λ and no noise. First, the RRR robot with two eye-to-hand cameras tracking
a circular trajectory are used for simulations. Generally, without LMA yields faster
convergence but higher RMS errors for all switching algorithms. For various starting
robot locations, including LMA only shows slightly improvement.
Second, for the PUMA 560 robot using an eye-in-hand camera tracking a circular
trajectory all switching algorithms with LMA yield slightly faster convergence with a
trade-oﬀ of slightly increased RMS errors. For diﬀerent robot starting positions and
trajectories, the LMA only marginally improves on convergence and tracking stability
for a more complex cycloidal trajectory.
In Section 6.5 diﬀerent VFF algorithms implemented with the switching algo-
rithms are investigated.
278
FortheRRRrobotwithacirculartrajectoryinthepresenceofnoise,theswitching
MBFGS with the DAFF algorithm yields the fastest convergence and RMS tracking
errors. However, the EE motion substantially deviates from the target plane for all
algorithms. Alternatively, a perpendicular camera arrangement discussed in Section
6.5 signiﬁcantly minimizes the out of plane the EE motions.
ForthePUMA560robotwithacirculartrajectorytheDAFFoﬀersslightlybetter
RMS error and t , especially for a faster angular speed and in the presence of noise.
s
For a square trajectory, the DAFF algorithm gives the best RMS steady-state and
RMS transient tracking errors as the target turns the corners resulted in the velocity
discontinuities. In the presence of noise, the DAFF algorithm consistently oﬀers the
best RMS tracking error. A brief study of using two eye-in-hand cameras shows
a potential for slightly improving RMS errors and smoother EE trajectories in the
presence of measurement and system noise.
In Section 6.6 presents the eﬀect of the LMA implemented with the switching
MBFGS and the DGN-PBM for various VFF algorithms using the PUMA 560 robot
tracking a complex cycloidal trajectory. In the presence of noise, the DAFF algorithm
gives the most desirable performance when implemented with either the switching
MBFGS-DB or the DGN-PBM algorithm in regardless of LMA inclusion. For all
cases, the switching MBFGS-DB-DAFF without the LMA generates the smallest
RMSerrorandthefastestconvergence. TheLMAalgorithmonlymarginallyimproves
tracking performance of a complex trajectory with the presence of noise. A similar
two eye-in-hand cameras may be used for noise compensation.
6.7.1 Conclusion
Consideringthevariousrobotdegrees-of-freedom, cameraconﬁgurations, trajectories,
and target speeds the switching MBFGS-DB algorithm with the DAFF method for
adaptively calculating λ most consistently outperforms the other proposed switching
k
279
and VFF algorithms. As compared to the original DGN-PBM algorithm with a
ﬁxed forgetting factor, the switching MBFGS-DAFF algorithm improves tracking
performance for large residual problems while the DAFF algorithm signiﬁcantly oﬀers
better tracking accuracy with fast convergence, especially in the presence of noise.
AlthoughtheLMAseemstomarginallyimprovetrackingperformanceinthepresence
of noise, this is only a limited case being studied and a more thoroughly investigation
should be pursued. Multiple cameras and camera arrangements signiﬁcantly improve
tracking performance, especially in the presence of noise. These simulation results
indicate the eﬀectiveness of the switching MBFGS-DB algorithm with the DAFF
scheme to improve tracking performance for large residual problems in the presence
of noise.
280
CHAPTER VII
CONCLUDING REMARKS
This study investigates visual servoing with adaptive forgetting factor algorithms
for large residual problems. Various novel residual approximations are introduced,
namely the dynamic BFGS (DBFGS), the modiﬁed BFGS (MBFGS), and the dy-
namic full Newton method with BFGS (DFN-BFGS) algorithms. Since residual ap-
proximation is utilized only when a large error occurs, or a switching algorithm
is introduced that is a combination of the (full) Newton method and the dynamic
quasi-Gauss-Newton algorithm in [57, 59]. Unlike other approaches in [17, 49], the
algorithm includes or excludes the residual approximation based on a heuristically
selected switching criterion υ.
The switching algorithm performance is dependent on a proper selection of a for-
gettingfactorλ . Consequently, anoveladaptiveforgettingfactorcalledtheDynamic
k
Adaptive Forgetting Factor (DAFF) is developed which is a heuristic approach to ap-
proximate λ with respect to the image error norm (cid:107)f (cid:107). Compared to a number
k k
of existing Variable Forgetting Factor (VFF) algorithms from adaptive ﬁltering area,
the DAFF method is shown to consistently provide the best RMS tracking errors and
convergence times in the presence of noise.
For a variety of robot DOF, camera systems, and trajectories investigated in
simulation,theswitchingMBFGS-DBwithDAFFalgorithmisshowntooﬀersuperior
tracking performance for large residual tracking problems, especially in the presence
of noise.
281
7.1 Contributions
This study built on the work by Piepmeier et al. [57, 59], Fu et al. [25], and Hao et al.
[29]. Piepmeier et al. introduced dynamic quasi-Gauss-Newton algorithms with two
implementations, with or without partitioning for Broyden’s method (the DBM-RLS
and the DGN-PBM algorithms respectively), that are shown to provide stable and
convergent tracking in uncalibrated visual servoing. However, they are limited to
only the zero- or small-residual cases where the Gauss-Newton method is applicable.
Consequently, Fu et al. introduce a residual approximation integrated with the DGN-
PBM algorithm with a trust region and the LMA to track a static target for large
residual problems. This work pointed the way to the development of the MBFGS
and DBFGS residual approximations. Hao et al. propose an algorithm to adaptively
calculate λ to be integrated with the DGN-PBM algorithm. Simulation results
k
show a potential to improve tracking performance motivating the DAFF method
development. While the proposed algorithm relates to the aforementioned work, the
switching MBFGS-DB with DAFF algorithm is distinct from that work due to the
following attributes:
• The switching MBFGS-DB with DAFF algorithm is provides stable uncali-
brated visual servoing tracking for large residual problems with a moving target
that had not been previously addressed.
• The DAFF algorithm eﬀectively adapts λ with respect to the image error norm
k
(cid:107)f (cid:107) and results in signiﬁcant RMS error improvement in the presence of noise
k
for large residual problems.
In addition this thesis make the speciﬁc contributions that diﬀerentiate it from
the previous work:
1. A theoretical development of the DBFGS and the MBFGS algorithms to recur-
ˆ
sively approximate residual S term.
k
282
• The implementation of the Broyden-Fletcher-Goldfarb-Shanno (BFGS) al-
ˆ
gorithmtoapproximatetheresidualS withadynamicquasi-Gauss-Newton
k
method resulted in the DFN-BFGS algorithm for large residual problems.
• The the DBFGS and the MBFGS methods for approximating the residual
ˆ
S are derived.
k
• Convergence analysis of the MBFGS in analogy to the BFGS algorithm in
[8] is presented.
2. A fundamental basis for applying a switching algorithm for large residual track-
ing problems.
ˆ
• A switching method combining a residual S approximation with the dy-
k
namic quasi-Gauss-Newton algorithms with or without partitioning for
Broyden’s method is developed. To determine a proper switching mecha-
nism, a switching criterion is heuristically selected.
• Various switching algorithms including the switching MBFGS-DB, the
switching DFN-BFGS-DB, and the switching DBFGS-DB algorithms are
investigated.
• Implementations of Scheme 1 and Scheme 2, alternatively combining the
dynamic quasi-Newton and dynamic quasi-Gauss-Newton methods, for
large residual problems are investigated.
• Implementation of the residual approximation presented in NL2SOL [17,
25] with the proposed switching method (the switching Fu-DB) for large
residual tracking problem is studied.
3. A fundamental development of the novel DAFF algorithm to adaptively calcu-
late λ
k
• A novel DAFF method to heuristically select λ is developed.
k
283
• Implementation of the VS-ARLS, the GN-VFF-RLS, and the VFF algo-
rithms (originally presented in an adaptive ﬁltering context) with the pro-
posed switching algorithms are investigated for large residual problems.
4. Simulation validation of the proposed switching algorithms with DAFF method
• The switching MBFGS-DB algorithm is found to eﬀectively improve RMS
tracking error and settling time t compared to the DBM-RLS and the
s
DGN-PBM algorithms originally applied with a ﬁxed forgetting factor for
large residual problems.
• Implementation of the LMA with the various switching algorithms and
VFF schemes shows only little improvement.
• The DAFF method is found to outperform the other existing VFF algo-
rithms in the presence of noise by oﬀering the best RMS tracking errors,
convergence times, and stability.
To put the above contributions into context, a summary of this thesis is presented
in Section 7.2.
7.2 Summary
Chapter 1 discusses the motivation that leads to the objective of this research, the
literature review of uncalibrated visual servoing, and organization of this study.
Chapter 2 reviews the theoretical background of Newton and quasi-Newton meth-
ods for solving unconstrained optimization problems. Since in this study visual ser-
voing is formulated as a data driven nonlinear optimization problem, a quasi-Newton
methodisusedforﬁndingasolution. AvarietyofNewtonandquasi-Newtonmethods
and techniques are used to improve various diﬃculties present in the methods.
Chapter 3 presents a dynamic Broyden’s method to estimate a compound Jaco-
bian proposed by Piepmeier et al. [57, 59, 60]. The important contribution of these
284
algorithms is their novel development of an uncalibrated visual servoing algorithm
using a robot manipulator to track a moving target without an a priori model of
either the robot or the camera. The algorithm is used to generate robot joint com-
mands via a dynamic quasi-Newton method that solves a nonlinear least squares
problem. This chapter reviews the fundamental development of the dynamic Broy-
den’s method using recursive least-squares estimation (DBM-RLS) for a stationary
camera and the dynamic Gauss-Newton algorithm with partitioned Broyden’s method
(DGN-PBM) for an eye-in-hand camera. A few major limitations of these algorithms
are discussed including a) initial large errors, b) utilizing a ﬁxed forgetting factor, c)
ill-conditioned Jacobian matrix. This thesis addresses a) and b) in Chapter 4 and
Chapter 5 respectively. A brief study of the LMA for solving c) is investigated in
Chapter 6.
Chapter 4 presents derivations of the DBFGS, the DFN-BFGS, and the MBFGS
for approximating the residual S for large residual problems. A major disadvantage
of the DBM-RLS and the DGN-PBM algorithms are their applicability to the zero-
or small-residual cases. This is the nature of the Gauss-Newton based algorithm that
neglects the residual S in the Hessian H matrix. For large residual problems, the
k
residual S is not negligible. Despite the fact that the residual S is usually diﬃcult
k k
to analytically determine, various algorithms are used to solve large-residual cases.
Since the goal is to approximate the Hessian matrix, one solution is to approximate
the whole Hessian (the DBFGS algorithm) and the other solution is to approximate
the residual Sˆ (the MBFGS and the DFN-BFGS algorithms) by assuming that JTJ
k k k
is already available. The derivation of the DBFGS algorithm is analogous to the
ˆ
BFGS derivation for the whole Hessian approximation H . The major signiﬁcance of
k
the DBFGS is due to the inclusion of the time-dependent term, ∂fkh , in the secant
∂t t
ˆ
equation used to approximate H . Unlike the DBFGS algorithm, the DFN-BFGS
k
ˆ
and MBFGS methods attempt to only approximate the residual S . The DFN-BFGS
k
285
ˆ
method is derived by applying the BFGS algorithm to estimate the residual S , while
k
the MBFGS algorithm is derived by modifying a denominator of a term in the DFN-
BFGS formula. This modiﬁcation basically enforces the curvature information of the
ˆ
function F into the residual S approximation. In addition, for the case that S is
k k k
relatively large compared to the term JTJ , the MBFGS method is the same as the
k k
DFN-BFGS method. Otherwise, the MBFGS method generates distinct results from
the unmodiﬁed BFGS method.
Since the DBFGS and the DFN-BFGS algorithms use the BFGS method, which
provides superlinear convergence under reasonable assumptions, a convergence proof
is only required to validate the MBFGS algorithm. The convergence analysis of the
MBFGSalgorithmisstudiedinanalogytotheconvergenceanalysisofBroyden’sclass
formula presented in [8]. The novel MBFGS algorithm assumably yields superlinear
convergence if the speciﬁed assumptions hold.
A hybrid between the DGN-PBM algorithm and a proposed residual approxima-
tion is developed and is referred to as the switching method. The switching method
is a heuristic approach to switch from using the full quasi-Newton method (inclusion
ˆ ˆ ˆ
of S into H where S is estimated using a proposed residual approximation) to the
k k k
ˆ
quasi-Gauss-Newton method (neglect S or the DGN-PBM algorithm). Switching
k
occurs if the image error norm (cid:107)f (cid:107) is less than the switching criterion υ, which is
k
heuristically selected. The switching methods presented for residual approximation
schemes are the switching DBFGS-DB, the MBFGS-DB, and the DFN-BFGS-DB
algorithms.
Chapter 5 discusses the derivation of the DAFF algorithm, a heuristic method for
adaptive λ calculation. The selection of λ is critically inﬂuences tracking perfor-
k k
mance so λ must be properly selected. As a result, various existing variable forget-
k
ting factor (VFF) algorithms, widely studied in RLS adaptive ﬁltering, are discussed.
However, these algorithms are complex, require a number of constant selections, and
286
do not appear eﬀective for uncalibrated visual servoing, hence, the DAFF method is
developed.
Due to the diﬃculty in obtaining λ analytically, a heuristic method is explored.
k
By observation, the image error is typically large in the transient state, especially
at the beginning of the tracking process, and becomes relatively small during steady
state. Since the inverse of 1−λ roughly represents memory, it can be hypothesized
that the forgetting factor λ should be small (less memory) when the image error is
large during transience. On the contrary, λ should get closer to unity (more memory)
when the image error becomes relatively small in steady-state tracking. Thus, the
image error norm (cid:107)f (cid:107) and λ are somewhat inversely related. This behavior of λ
k k k
is in analogy to a step response of a ﬁrst-order diﬀerential system. An analogous
transfer function for which the input function is the image error norm and the output
function is the inverse of the memory is developed that ultimately leads to the DAFF
algorithm.
Chapter6ﬁrstdiscussestheproposedswitchingalgorithms,theswitchingMBFGS-
DB, DBFGS-DB, and DFN-BFGS-DB algorithms, on improving tracking perfor-
mance for large residual problems in simulation. A RRR robot with two eye-to-hand
cameras and a PUMA 560 robot with an eye-in-hand camera tracking a variety target
trajectories are used. For all tests the starting robot position is located far away from
the desired target to ensure a initial large error, no noise is added, and a ﬁxed λ is
k
used. The results are then compared with the DBM-RLS and the DGN-PBM algo-
rithms. The switching DFN-BFGS-DB and the MBFGS-DB algorithms are the most
eﬀective methods with NP-Jacobian approximation for the RRR robot case. How-
ever, for the PUMA 560 robot case the switching MBFGS-DB algorithm provides the
best results in terms of RMS errors, t , and stability for a complex trajectory or a
s
fast target speed.
287
The diﬀerent VFF algorithms presented in Chapter 5 are investigated to vali-
date tracking improvement. Due to parameter selection required for each algorithm,
their variation is investigated with the PUMA 560 robot using an eye-in-hand cam-
era tracking a circular trajectory. The performance of each VFF algorithm is in fact
insensitive to the variation of parameters so the tracking performance of each VFF
algorithm can be reasonably compared. The switching MBFGS with the DAFF al-
gorithm consistently yields the fastest convergence and the smallest RMS tracking
errors in the presence of measurement and system noise for both the RRR robot
with two eye-to-hand cameras and the PUMA 560 with an eye-in-hand camera. This
consistency is also true for a variety of trajectories and target speeds. However, the
EE motions substantially deviate from the desired target planes for the RRR robot
case. This problem can be minimized if the cameras are arranged perpendicularly.
Although the PUMA 560 robot case does not have much of a deviation problem, it
is more sensitive to the noise disturbance compared to the RRR robot case. Since
the perpendicular camera arrangement is not applicable for the eye-in-hand case, two
nearly paralleled eye-in-hand cameras are used. This camera arrangement generates
smoother EE trajectories.
The eﬀect of the MBFGS-DB and the DGN-PBM with various VFF algorithms
on two implementations, with or without the LMA, is studied. The DAFF gives the
best performance as compared to other VFF algorithms for both MBFGS-DB and the
DGN-PBM and the LMA has little aﬀect on DAFF performance. In fact the LMA
algorithm only marginally improves tracking performance for all tested cases. The
switching MBFGS-DB-DAFF without the LMA generates the smallest RMS error
and the fastest convergence.
In summary, the switching MBFGS-DB algorithm with the DAFF method con-
sistently yields the best results for a variety of robot degrees-of-freedom, camera
288
conﬁgurations, trajectories, and target speeds. The DAFF algorithm is shown to sig-
niﬁcantly oﬀer the best overall tracking accuracy and convergence, especially in the
presence of noise. The number of cameras and the camera arrangement are shown to
signiﬁcantly aﬀect noise compensation. Although the cases studied in this situation
are limited, these results validate the eﬀectiveness of the switching MBFGS-DB al-
gorithm with the DAFF scheme to improve tracking performance for large residual
problems in the presence of noise.
7.3 Future Work
Although the switching MBFGS-DB algorithm with the DAFF method is shown to
improve tracking performance, there exists a few issues on further improving the
eﬀectiveness of this novel algorithm.
ˆ
One issue is to further improve the Jacobian approximation J . The proposed
k
ˆ ˆ
residual S approximations are derived with an assumption that J is available and
k k
ˆ
approximately represents the actual Jacobian J . Since J is used to approximate
k k
ˆ ˆ
S , this quantity is critical and directly aﬀects how well S is approximated. Two
k k
promising methods have been proposed by Farahmand et al. [22]. In the K-nearest
neighborhood method Jacobians are calculated from sensor data using a recursive
least squares method. It is also estimated from a database of previously stored Jaco-
bians which are “nearest” to it in conﬁguration space which are used for a weighted
interpolation. Using heuristics the best estimate is taken and a decision is made if
the stored Jacobian should be updated. In the second method the tip location data
is stored as the robot moves in the workspace. To determine the Jacobian at any
given state, a hyperplane is ﬁt to the stored location data. Good results have been
reported for both methods using an industrial robot.
In the presence of noise tracking performance signiﬁcantly degrades. The higher
289
DOF robot with an eye-in-hand case is shown to be very sensitive to noise distur-
bances. Though the switching MBFGS-DB algorithm with the DAFF method oﬀers
the best RMS error and settling time, the EE motion oscillates at least in the range of
the added noise in the best cases, i.e., the RRR robot with two eye-to-hand cameras.
As a result, a noise ﬁltering algorithm such as a Kalman ﬁlter may be implemented,
which is routinely used in a variety applications such as adaptive ﬁlters, system iden-
tiﬁcation, or sensor fusion. In fact the RLS algorithm can be cast as a special case
of the Kalman ﬁltering [32] and the relationship between them is discussed in [32].
Since the switching MBFGS-DB algorithm with the DAFF method utilizes the dy-
ˆ
namic Broyden’s method to recursively approximate J , there exists a possibility to
k
ˆ
augment the Kalman ﬁlter into the Jacobian J approximation.
k
Due to the potential of using multiple cameras for noise compensation, multiple
cameras and camera arrangements can be further investigated to optimally improve
tracking. Since the perpendicular camera arrangement for the RRR robot cases con-
siderablyminimizestheEEdeviationoutofthetargetplane, oneormoreeye-to-hand
cameras may be added to the eye-in-hand PUMA 560 case to improve tracking per-
formance.
Experimental veriﬁcation of the switching MBFGS-DB algorithm with the DAFF
method is required for a practical validation. This study does not address singularity
avoidance or the situation where the target exits the robot workspace or camera view
and must be considered for experimental realization.
The switching MBFGS-DB algorithm with the DAFF method signiﬁcantly im-
proves on diﬃculties encountered in large residual tracking problems. This work is
the ﬁrst successfully developed uncalibrated visual guided control to handle large
residual problems for moving target tracking with fast convergence and desirable
accuracy.
290
REFERENCES
[1] Agheksanterian, A., “Line search methods in unconstrained optimization: A
new inexact method.” UMBC An Honors University in Maryland http://www.
math.umbc.edu/~aa5/articles/fall2006.pdf, October 18 2006.
[2] Bartlett, M. S., “An inverse matrix adjustment arising in discriminant anal-
ysis,” The Annals of Mathematical Statistics, vol. 22, no. 1, pp. 107–111, 1951.
[3] Betts, J. T., “Solving the nonlinear least squares problem: Application of
a general method,” Journal of Optimization Theory and Applications, vol. 18,
pp. 469–483, April 1976.
[4] Bilen, H., Hocaoglu, E., Ozgur, M., and Sabanovic, A., “A compara-
tive study of conventional visual servoing schemes in microsystem applications,”
in Proceedings of the 2007 IEEE/RSJ International Conference on Intelligent
Robots and Systems, (San Diego, CA, USA), pp. 1308–1313, Oct 29 - Nov 2
2007.
[5] Bonkovic, M., Hace, A., and Jezernik, K., “Population-based uncalibrated
visual servoing,” Transactions on Mechatronics, IEEE/ASME, vol. 13, no. 3,
pp. 393–397, 2008.
[6] Broyden, C. G., “Quasi-newton methods and their application to function
minimization,” Mathematics of Computation, vol. 21, pp. 368–381, 1967.
[7] Broyden, C. G., Dennis, J. E., and More´, J. J., “On the local and super-
linear convergence of quasi-newton methods,” IMA Journal of Applied Mathe-
matics, vol. 12, no. 3, pp. 223–245, 1973.
[8] Byrd, R. H., Nocedal, J., and Yuan, Y. X., “Global convergence of a class
of quasi-newton methods on convex problems,” SIAM Journal on Numerical
Analysis, vol. 24, no. 5, pp. 1171–1190, 1987.
[9] Conn, A. R., Gould, N. I. M., and Toint, P. L., Trust-Region Methods.
MPS-SIAM Series on Optimization, Philadelphia: SIAM, 2000.
[10] Corke, P. I., “A robotics toolbox for matlab,” IEEE Robotics and Automation
Magazine, vol. 3, no. 1, pp. 24–32, 1996.
[11] Corke, P., “Machine vision toolbox,” IEEE Robotics and Automation Maga-
zine, vol. 12, pp. 16–25, Nov. 2005.
[12] Davidon, W. C., “Variance algorithm for minimization,” The Computer Jour-
nal, vol. 10, no. 4, pp. 406–410, 1968.
291
[13] Davidon, W. C., “Optimally conditioned optimization algorithms without line
searches,” Mathematical Programming, vol. 9, no. 1, pp. 1–30, 1975.
[14] Dementhon, D. and Davis, L., “Model-based object pose in 25 lines of code,”
International Journal of Computer Vision, vol. 15, pp. 123–141, June 1995.
[15] Dennis, Jr., J. E., “Some computational techniques for the nonlinear least
squares problem,” in Numerical Solution of Systems of Non-linear Algebraic
Equations(Hall, G. D. B.andA, C., eds.), pp.157–183, NewYork: Academic
Press, 1973.
[16] Dennis, Jr., J. E., Gay, D. M., and Welsch, R. E., “An adaptive nonlinear
least squares algorithm,” tech. rep., NBER, August 1977.
[17] Dennis, Jr., J. E., Gay, D. M., and Welsch, R. E., “An adaptive non-
linear least-squares algorithm,” ACM Transactions on Mathematical Software
(TOMS), vol. 7, pp. 348–368, September 1981a.
[18] Dennis, Jr., J. E. and More´, J. J., “A characterization of superlinear con-
vergence and its application to quasi-newton methods,” Mathematics of Compu-
tation, vol. 28, pp. 549–560, April 1974.
[19] Dennis, Jr., J. E. and Schnabel, R. B., Numerical methods for uncon-
strained optimization and nonlinear equation (classics in applied mathematics).
Philadelphia: SIAM, 1996.
[20] Dennis, J. E., J., Gay, D. M., and Welsch, R. E., “Algorithm 573: Nl2sol -
anadaptivenonlinearleast-squaresalgorithm[e4],” ACM Transactions on Math-
ematical Software (TOMS), vol. 7, pp. 369–383, September 1981b.
[21] Dixon, L. C. W., “Variable metric algorithms: Necessary and suﬃcient condi-
tions for identical behavior on nonquadratic functions,” Journal of Optimization
Theory and Applications, vol. 10, pp. 34–40, July 1972.
[22] Farahmand, A. M., A., S., and Jagersand, M., “Global visual-motor esti-
mation for uncalibrated visual servoing,” in Proceedings of the 2007 IEEE/RSJ
International Conference on Intelligent Robots and Systems, (San Diego, CA,
USA), pp. 1969–74, 2007.
[23] Fletcher, R., Practical methods of optimization, Second Edition. John Wiley
& Sons, 1987.
[24] Franklin, G. F. and Powell, J. D., Digital Control of Dynamic Systems.
Philippines: Addison-Wesley, 1981.
[25] Fu, Q., Zhang, Z., and Shi, J., “Uncalibrated visual servoing using more
precise model,” in 2008 IEEE Conference on Robotics, Automation, and Mecha-
tronics, (Chengdu, China), pp. 916–921, 2008.
292
[26] Gill, P. E. and Murray, W., “Numerically stable methods for quadratic
programming,” Mathematical Programming, vol. 14, pp. 349–372, 1978.
[27] Gill, P. E., Michael, and Leonard, M. W., “Reduced-hessian quasi-
newton methods for unconstrained optimization,” SIAM Journal on Optimiza-
tion, vol. 12, no. 1, pp. 209–237, 2001.
[28] Griewank, A. and Toint, P. L., “Local convergence analysis of partitioned
quasi-newton updates,” Numerische Mathematik, vol. 39, October 1982.
[29] Hao, M., Deuflhard, P., Sun, Z., and Fujii, M., “Model-free uncalibrated
visual servoing using recursive least squares,” Journal of Computers, vol. 3,
pp. 42–50, November 2008.
[30] Hao, M., Sun, Z., Fujii, M., andSong, W., “Uncalibratedeye-in-handvisual
servoing using recursive least squares,” in Systems, Man and Cybernetics, 2007.
ISIC. IEEE International Conference on, (Montreal, QC, Canada), pp. 64–69,
October 7-10 2007.
[31] Harville, D. A., Matrix Algebra From a Statistician’s Perspective. New York:
Springer, corrected ed., 2008.
[32] Haykin, S., Adaptive ﬁlter theory. Englewood Cliﬀs, NJ: Prentice-Hall, 1996.
[33] Hill, J.andPark, W. T., “Realtimecontrolofarobotwithamobilecamera,”
in Proceedings of the 9th ISIR, pp. 233–246, March 1979.
[34] Hosoda, K. and Asada, M., “Versatile visual servoing without knowledge of
true jacobian,” in IEEE/RSJ/GI International Conference on Intelligent Robots
and Systems, (Munich, Germany), pp. 186–193, 1994.
[35] Hosoda, K., Igarashi, K., and Asada, M., “Adaptive hybrid control for
visual servoing and force servoing in an unknown environment,” IEEE Robotics
and Automation Magazine, vol. 5, no. 4, pp. 39–43, 1998.
[36] Hutchinson, S.,Hager, G. D.,andCorke, P. I.,“Atutorialonvisualservo
control,” IEEE Transactions on Robotics and Automation, vol. 12, pp. 651–670,
October 1996.
[37] Jagersand, M., Fuentes, O., and Nelson, R., “Experimental evaluation of
uncalibrated visual servoing fro recision manipulation,” in Proceedings of Inter-
national Conference on Robotics and Automation, (Albuquerque,NM),pp.2874–
80, 1997.
[38] Kim, G. W. and Lee, B. H., “Adaptive regulation of robot joint velocity in
uncalibrated visual servoing,” in Proceedings of the 2004 IEEE International
Conference on Robotics & Automation, (New Orleans, LA), pp. 739–744, 2004.
293
[39] Kim, G. W. and Lee, B. H., “Target tracking using the eﬃcient estimation of
the image jacobian with large residual,” Robotica, vol. 24, pp. 325–327, 2006.
[40] Kim, G. W., Lee, B. H., and Kim, M. S., “Uncalibrated visual servoing
technique using large residual,” in Proceedings of the 2003 IEEE International
Conference on Robotics & Automation, (Taipei, Taiwan), pp. 3315–3320, 2003.
[41] Leung, S.-H. and So, C. F., “Gradient-based variable forgetting factor rls
algorithm in time-varying environments,” IEEE Transactions on Signal Process-
ing, vol. 53, no. 8, pp. 3141–3150, 2005.
[42] Levenberg, K., “A method for the solution of certain non-linear problems in
least squares,” The Quarterly of Applied Mathematics, vol. 2, pp. 164–168, 1944.
[43] Lourakis, M. I. A., “A brief description of the levenberg-marquardt algorithm
implemented by levmar. foundation for research and technology,” 2005.
[44] Lv, X. and Huang, X., “Fuzzy adaptive kalman ﬁltering based estimation
of image jacobian for uncalibrated visual servoing,” in Proceeding of the 2006
IEEE/RSJ International Conference on intelligent Robots and Systems, (Beijing,
Chaina), pp. 2167–2172, Oct 9-15 2006.
[45] Marquardt, D., “An algorithm for least-squares estimation of nonlinear pa-
rameters,” SIAM Journal on Applied Mathematics, vol. 11, pp. 431–441, 1963.
[46] Miura, K., Hashimoto, K., Gangloff, J., and Mathelin, M. d., “Visual
servoing without jacobian using modiﬁed simplex optimization,” in Proceeding of
the 2003 IEEE International Conference on Robotics and Automation, pp. 3315–
3320, September 2005.
[47] More´, J. J., “The levenberg-marquardt algorithm: Implementation and the-
ory,” Lecture Notes in Mathematics, vol. 630, pp. 105–116, 1978.
[48] Nazareth, J. L., “A hybrid least squares method,” tech. rep., Argonne Na-
tional Laboratory, 1975.
[49] Nazareth, L., “Some recent approaches to solving large residual nonlinear
least squares problems,” SIAM Review, vol. 22, no. 1, pp. 1–11, 1980.
[50] Nocedal, J. and Wright, S. J., Numerical optimization. New York, NY:
Springer, 1999.
[51] Oren, S. S., “Self-scaling variable metric algorithms without line search for
unconstrained minimization,” Mathematics of Computation, vol. 27, no. 124,
pp. 873–885, 1973.
[52] Ozgur, E. and Unel, M., “Positioning the trajectory following tasks in mi-
crosystems using model free visual servoing,” in The 33rd Annual Conference of
the IEEE Industrial Electronics Society (IECON),(Taipei,Taiwan),pp.886–891,
Nov 5-8 2007.
294
[53] Paleologu, C., Benesty, J., and Ciochina˘, S., “A robust variable for-
getting factor recursive least-squares algorithm for system identiﬁcation,” IEEE
Signal Processing Letters, vol. 15, pp. 597–600, 2008.
[54] Park, D. J. and Jun, B. E., “Self-perturbing rls algorithm with fast tracking
capability,” Electronics Letters, vol. 28, pp. 558–559, March 12 1992.
[55] Park, D. J., Jun, B. E., and Kim, J. H., “Fast tracking rls algorithm using
novel variable forgetting factor with unity zone,” Electronics Letters, vol. 27,
no. 23, pp. 2150–2151, 1991.
[56] Pearson, J., “Variable metric methods of minimization,” Computer Journal,
vol. 12, pp. 171–178, 1969.
[57] Piepmeier, J. A., A Dynamic quasi-Newton method for model independent
visual servoing. PhD thesis, Georgia Institute of Technology, 1999.
[58] Piepmeier, J. A., “Experimental results for uncalibrated eye-in-hand visual
servoing,” in IEEE Southeastern Symposium on System Theory, (Morgantown,
WV), pp. 335–339, 2003.
[59] Piepmeier, J. A. and Lipkin, H., “Uncalibrated eye-in-hand visual servoing,”
The International Journal of Robotics Research, vol. 22, pp. 805–819, 2003.
[60] Piepmeier, J. A., McMurray, G. V., and Lipkin, H., “Uncalibrated dy-
namic visual servoing,” IEEE Transactions on Robotics and Automation, vol. 20,
pp. 143–147, Feb. 2004.
[61] Powell, M. J. D., “A new algorithm for unconstrained optimization,” in Non-
linear Programming (Rosen, J. B., Mangasarian, O. L., and Ritter, K.,
eds.), pp. 31–65, New York: Academic Press, 1970.
[62] Powell, M. J. D., “Some global convergence properties of a variable met-
ric algorithm for minimization without exact line searches,” in Nonlinear Pro-
gramming, SIAM-AMS Proceedings (Cottle, R. W. and Lemke, C., eds.),
Philadelphia: Scociety for Industrial and Applied Mathematics, 1976.
[63] Qian, J. and Su, J., “Online estimation of image jacobian matrix by kalman-
bucyﬁlterforuncalibratedstereovisionfeedback,”inProceedings ICRA’02IEEE
International conference on Robotics and Automation, vol. 1, pp. 562–567, Aug
2002.
[64] Ralis, S. J., B., V., and Nelson, B. J., “Micropositioning of a weekly cal-
ibrated microassembly system using coarse-to-ﬁne visual servoing strategies,”
IEEE Transactions on Electronics Packing Manufacturing, vol. 23, pp. 123–131,
Apr 2000.
295
[65] Rennie, J. D. M., “Relating the trace and frobenius matrix norms.” http:
//people.csail.mit.edu/jrennie/writing/traceFrobenius.pdf,August31
2005.
[66] Ritter, K., “Local and superlinear convergence of a class of variable metric
methods,” Computing, vol. 23, pp. 287–297, 1979.
[67] Seber, G. A. F. and Wild, C. J., Nonlinear Regression. Wiley series in
probability and mathematical statics, New York, US: John Wiley & Sons, 1989.
[68] Sherman, J. and Morrison, W. J., “Adjustment of an inverse matrix corre-
sponding to a change in one element of a given matrix,” The Annals of Mathe-
matical Statistics, vol. 21, no. 1, pp. 124–127, 1950.
[69] Slock, D. T. M. and Kailath, T., “Fast transversal ﬁlters with data se-
quence weighting,” IEEE Transactions on Acoustics, Speech and Signal Process-
ing, vol. 37, no. 3, pp. 346–359, 1989.
[70] So, C. F., Ng, S. C., and Leung, S. H., “Gradient based variable forgetting
factor rls algorithm,” Signal Processing, vol. 83, pp. 1163–1175, 2003.
[71] Song, S., Lim, J.-S., Baek, S., and Sung, K.-M., “Gauss newton variable
forgetting factor recursive least squares for time varying parameter tracking,”
Electronics Letters, vol. 36, no. 11, pp. 988–990, 2000.
[72] Stachurski, A., “Superlinear convergence of broyden’s bounded θ-class of
methods,” Mathematical Programming, vol. 20, pp. 196–212, December 1981.
[73] Steele, J., The Cauchy-Schwarz Master Class: An Introduction to the Art
of Mathematical Inequalities (Maa Problem Books Series.). Cambridge, United
Kingdom: Cambridge University Press, 2004.
[74] Stoer, J., “On the convergence rate of imperfect minimization algorithms in
broyden’s beta-class,” Mathematical Programming, vol. 9, pp. 313–335, 1975.
[75] Strang, G., Linear algebra and its applications. Philadelphia, PA:
Brooks/Cole, third edition ed., 1988.
[76] Vanden Berghen, I. F., “Trust region algorithms.” Kranf Site http://www.
applied-mathematics.net/index.html.
[77] Vanden Berghen, I. F., CONDOR: a constrained, non-linear, derivative-free
parallel optimizer for continuous, high computing load, noisy objective functions.
Phd thesis, University of Brussels, 2004.
[78] Wang, H.andH., L. Y., “Dynamicvisualservoingofrobotsusinguncalibrated
eye-in-handvisualfeedback,”inProceedings of the 2006 IEEE/RSJ International
Conference on Intelligent Robots and Systems, (Beijing, China), pp. 3797–3802,
Oct 9 -15 2006.
296
[79] Weiss, L. E., Sanderson, A. C., and Neuman, C. P., “Dynamic sensor-
based control of robots with visual feedback,” IEEE Journal of Robotics and
Automation, vol. RA-3, pp. 404–417, October 1987.
[80] Wilson, W. J., Hulls, C. C. W., and Bell, G. S., “Relative end-eﬀector
control using cartesian position-based visual servoing,” IEEE Transactions on
Robotics and Automation, vol. 12, pp. 684–696, Oct 1996.
297
VITA
Jomkwun Munnae was born in Phetchaburi, a province in the central of Thailand. In
March 1997 she graduated from Satriwittaya School in Bangkok, Thailand. She was
awarded a Thai scholarship to pursue higher education in the United States in April
1997. After spending one year at Dana Hall School in Wellesley, MA, she attended
the University of Wisconsin at Madison for her Bachelor’s degree in Mechanical Engi-
neering. After graduating in 2002, she pursued her graduate study and was awarded
a M.S. Mechanical Engineering degree from the Georgia Institute of Technology in
May of 2004. There she developed her interests in robotics control. She worked as a
graduateresearchassistantattheATASLaboratory, aunitoftheGeorgiaTechnology
Research Institute, providing engineering solutions to a variety of industries across
the nation. This experience bridged her academic experience with solving real-world
technical problems.
298
